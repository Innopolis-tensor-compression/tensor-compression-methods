{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:24.843742Z",
     "start_time": "2024-10-09T01:15:24.795918Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorly as tl\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.method_loggers import MethodLogger\n",
    "from src.utils.method_runners import MethodRunner\n",
    "from src.utils.metrics_calculators import MetricCalculatorFactory\n",
    "from src.utils.tensor_handlers import normalize_frames\n",
    "from src.utils.trackers import GPUTorchMemoryTracker, RAMMemoryTracker, TimeTracker\n",
    "from src.utils.video_controller import download_youtube_video, extract_frames, save_frames_as_video\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "%load_ext memory_profiler\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:24.941811Z",
     "start_time": "2024-10-09T01:15:24.910558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.014705Z",
     "start_time": "2024-10-09T01:15:24.983392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_device = tf.config.list_physical_devices(\"GPU\")[0].name\n",
    "tf_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.100637Z",
     "start_time": "2024-10-09T01:15:25.064755Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=eSKe2Vx-rpY\"\n",
    "proxy_url = os.getenv(\"PROXY_URL\")\n",
    "cache_dir = \"../.cache/youtube\"\n",
    "\n",
    "log_file_path = \"../.cache/method_logs.json\"\n",
    "\n",
    "method_logs_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check how functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.205623Z",
     "start_time": "2024-10-09T01:15:25.159974Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео уже загружено и закешировано: ../.cache/youtube/eSKe2Vx-rpY.mp4\n"
     ]
    }
   ],
   "source": [
    "video_path = download_youtube_video(video_url, cache_dir=cache_dir, proxy_url=proxy_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.429202Z",
     "start_time": "2024-10-09T01:15:25.281226Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_frames, original_fps, frame_size = extract_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.475350Z",
     "start_time": "2024-10-09T01:15:25.442965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 360, 202, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.542291Z",
     "start_time": "2024-10-09T01:15:25.506968Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# processed_video_frames = process_frames(video_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check original video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.599751Z",
     "start_time": "2024-10-09T01:15:25.570317Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_frames_as_video(processed_video_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Implementations of Decompositions methods"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some packages which can decompose some dense type of tensors, from [this](https://arxiv.org/pdf/2103.13756) paper\n",
    "\n",
    "\n",
    "Decomposition methods which used:\n",
    "1. Canonical Polyadic Decomposition as PARAllel FACtors analysis (aka PARAFAC aka CPD aka CP)\n",
    "2. Tucker Decomposition\n",
    "3. Tensor Train\n",
    "4. some variants of its (Other)\n",
    "\n",
    "Tensor types:\n",
    "1. Dense (D)\n",
    "2. Sparse (S)\n",
    "3. BlockSparse (BS)\n",
    "4. Symmetric\n",
    "5. Supersymmetric\n",
    "\n",
    "Target system:\n",
    "1. CPU (C)\n",
    "2. GPU(G)\n",
    "3. Distributed Memory (D)\n",
    "\n",
    "\n",
    "\n",
    "| Method name                                                                             | Decomposition methods implemented | Tensor Type | Platform | Language         | Git | PyPI | Want to check | Checked     |\n",
    "|-----------------------------------------------------------------------------------------|-----------------------------------|------------|----------|------------------|------|------|--------------|-------------|\n",
    "| [AdaTM](https://github.com/hpcgarage/AdaTM)                                             | CP                                | S          | C        | C                | +    | ?    |              |             |\n",
    "| [BTAS](https://github.com/ValeevGroup/BTAS)                                             | CP, Tucker                        | nan        | C        | C++              | +    | ?    |              |             |\n",
    "| [CP-CALS](https://github.com/HPAC/CP-CALS)                                              | CP, Other                         | D          | C, G     | C++, Mat         | +    |      | +            |             |\n",
    "| [CSTF](https://github.com/ZacBlanco/cstf)                                               | Other                             | S          | D        | Scala            | +    | ?    |              |             |\n",
    "| [D-Tucker](https://datalab.snu.ac.kr/dtucker/resources/DTucker-v1.0.tar.gz)             | Tucker, Other                     | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [DFacTo](http://www.joonheechoi.com/research.)                                          | CP                                | S          | C, D     | C++              |      | ?    |              |             |\n",
    "| [EXATN](https://github.com/ORNL-QCI/exatn)                                              | TensorTrain                       | D          | C, D, G  | C++, Py          | +    |      | +            |             |\n",
    "| [Genten](https://gitlab.com/tensors/genten)                                             | CP                                | D, S       | C, G     | C++              | +    |      | +            |             |\n",
    "| GigaTensor                                                                              | CP                                | D          | C        | C++, Python      |      | ?    |              |             |\n",
    "| [ITensor](https://github.com/ITensor/ITensor)                                           | TensorTrain                       | D, BS      | C, G     | C++, Julia       | +    |      | +            |             |\n",
    "| [multiway](https://cran.r-project.org/web/packages/multiway/index.html)                 | CP, Tucker, Other                 | D          | C        | R                |      | ?    |              |             |\n",
    "| [N-way toolbox](http://www.models.life.ku.dk/nwaytoolbox/download)                      | CP, Tucker, Other                 | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [ParCube](https://www.cs.ucr.edu/~epapalex/src/parCube.zip)                             | CP                                | S          | C        | Matlab           |      | ?    |              |             |\n",
    "| [ParTensor](https://github.com/neurocom/partensor-toolbox)                              | CP                                | D          | C, G     | C++              | +    |      | +            |             |\n",
    "| [ParTI!](https://github.com/hpcgarage/ParTI)                                            | CP, Tucker                        | S          | C, G     | C, CUDA, Mat     | +    | ?    |              |             |\n",
    "| [PLANC](https://github.com/ramkikannan/planc)                                           | CP                                | S          | C, D     | C++              | +    | ?    |              |             |\n",
    "| [PLS toolbox](https://eigenvector.com/software/pls-toolbox/)                            | CP          , Tucker              | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [Pytensor](https://code.google.com/archive/p/pytensor/source/default/source)            | Tucker                            | D, S       | C        | Python           |      | ?    |              |             |\n",
    "| [rTensor](https://github.com/jamesyili/rTensor)                                         | CP, Tucker, Other                 | D          | C        | R                | +    |      | +            |             |\n",
    "| [rTensor (randomized)](https://github.com/erichson/rTensor)                             | CP                                | D          | C        | Python           | +    |      | +       +    |             |\n",
    "| [scikit-tensor](https://github.com/mnick/scikit-tensor)                                 | CP, Tucker, Other                 | D, S       | C        | Python           | +    | +    | +    +   +   | too old     |\n",
    "| [Scikit-TT](https://github.com/PGelss/scikit_tt)                                        | TensorTrain                       | D          | C        | Python           | +    |      |     +   +    |             |\n",
    "| [SPALS](https://github.com/dehuacheng/SpAls)                                            | CP                                | S          | C        | C++              | +    | ?    |              |             |\n",
    "| [SPARTan](https://github.com/kperros/SPARTan)                                           | Other                             | S          | C        | Matlab           | +    | ?    |              |             |\n",
    "| [SPLATT](https://github.com/ShadenSmith/splatt)                                         | CP                                | S          | C, D     | C, C++, Oct, Mat | +    | ?    |              |             |\n",
    "| [SuSMoST](https://susmost.com/downloads.html)                                           | TensorTrain, Other                | D          | C        | Python           |      | ?    |              |             |\n",
    "| [T3F](https://github.com/Bihaqo/t3f)                                                    | TensorTrain                       | D          | C, G     | Python           | +    | +    | +    + +     | in progress |\n",
    "| [TDALAB](https://github.com/andrewssobral/TDALAB)                                       | CP                                | D, S       | C        | Python, Matlab   | +    |      | +         +  |             |\n",
    "| [TeNPy](https://github.com/tenpy/tenpy)                                        | TensorTrain                       | D          | C        | Python           | +    | +    | +      + +   | in progress |\n",
    "| [Tensor Fox](https://github.com/felipebottega/Tensor-Fox)                               | CP                                | D, S       | C        | Python, Matlab   | +    | +    | +    + +     | ?           |\n",
    "| [Tensor package](http://www.gipsa-lab.fr/~pierre.comon/TensorPackage/tensorPackage.html) | CP                                | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [Tensor Toolbox](https://gitlab.com/tensors/tensor_toolbox)                             | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |             |\n",
    "| [tensor_decomposition](https://github.com/cyclops-community/tensor_decomposition)       | CP, Tucker                        | D          | C, D     | Python           | +    |      | +        +   |             |\n",
    "| [TensorBox](https://github.com/phananhhuy/TensorBox)                                    | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |             |\n",
    "| [TensorD](https://github.com/Large-Scale-Tensor-Decomposition/tensorD)                  | CP, Tucker                        | D          | C, G     | Python           | ?    | ?    |              |             |\n",
    "| [TensorLab](https://www.tensorlab.net)                                                  | CP, Tucker, Other                 | D, S       | C        | Matlab           |      | ?    |              |             |\n",
    "| [TensorLab+](https://www.tensorlabplus.net)                                             | CP, Other                         | D, S       | C        | Matlab           |      | ?    |              |             |\n",
    "| [TensorLy](https://github.com/tensorly/tensorly)                                        | CP, Tucker, TensorTrain, Other    | D          | C, G     | Python           | +    | +    | +       + +  | in progress |\n",
    "| [Three-Way](https://github.com/cran/ThreeWay)                                           | CP, Tucker                        | D          | C        | R                | +    |      | +            |             |\n",
    "| [TNR](https://github.com/ycyuustc/matlab)                                               | Other                             | D          | C        | Matlab           | +    |      | +            |             |\n",
    "| [TT-Toolbox](https://github.com/oseledets/TT-Toolbox)                                   | TensorTrain                       | D          | C, D, G  | Matlab, Python   | +    |      | +       +    |             |\n",
    "| [xerus](https://git.hemio.de/xerus/xerus/)                                              | TensorTrain                       | D, S       | C        | C++              | +    |      | +            |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TensorLy"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.649921Z",
     "start_time": "2024-10-09T01:15:25.621516Z"
    }
   },
   "outputs": [],
   "source": [
    "# {‘numpy’, ‘mxnet’, ‘pytorch’, ‘tensorflow’, ‘cupy’}\n",
    "# backend variants for tensorly\n",
    "# tl.set_backend('pytorch')\n",
    "# with tl.backend_context(‘pytorch’): ... pass\n",
    "\n",
    "# video_frames_cuda = tl.tensor(video_frames.copy()).to(device)\n",
    "# video_frames_cuda = tl.tensor(video_frames.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.700171Z",
     "start_time": "2024-10-09T01:15:25.671774Z"
    }
   },
   "outputs": [],
   "source": [
    "# video_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tucker (tl.decomposition.tucker)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.757994Z",
     "start_time": "2024-10-09T01:15:25.727525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truncated_svd', 'symeig_svd', 'randomized_svd']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.SVD_FUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.816413Z",
     "start_time": "2024-10-09T01:15:25.785893Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_param = (video_frames.shape[0] // 2, video_frames.shape[1], video_frames.shape[2], video_frames.shape[3])\n",
    "\n",
    "n_iter_max_param = 100\n",
    "\n",
    "svd_params = [\"truncated_svd\", \"symeig_svd\", \"randomized_svd\"]\n",
    "\n",
    "init_params = [\"svd\", \"random\"]\n",
    "\n",
    "backend_params = [\"pytorch\", \"numpy\"]\n",
    "\n",
    "random_state_param = 42\n",
    "\n",
    "total_iterations = len(list(product(svd_params, init_params, backend_params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Implementation"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T01:15:25.913234Z",
     "start_time": "2024-10-09T01:15:25.850131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл ../.cache/method_logs.json не найден.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:   0%|          | 0/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mПропущена итерация: логи уже существуют для \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     24\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:688\u001b[0m, in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    686\u001b[0m _lazy_init()\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "logs = MethodLogger.load_logs_from_file(log_file_path)\n",
    "\n",
    "for backend, svd_func, init_method in tqdm(product(backend_params, svd_params, init_params), desc=\"Проверка набора параметров\", total=total_iterations):\n",
    "    method_name = f\"TensorLy_Tucker_{backend}_{svd_func}_{init_method}\"\n",
    "\n",
    "    if logs:\n",
    "        existing_log = next(\n",
    "            (\n",
    "                log\n",
    "                for log in logs\n",
    "                if log[\"method_name\"] == method_name\n",
    "                and log[\"method_args\"].get(\"init\") == init_method\n",
    "                and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if existing_log:\n",
    "            print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "            continue\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    try:\n",
    "        with tl.backend_context(backend):\n",
    "            if backend == \"pytorch\":\n",
    "                tensor_param = tl.tensor(video_frames.copy()).to(torch_device)\n",
    "            elif backend == \"numpy\" or backend is None:\n",
    "                tensor_param = tl.tensor(video_frames.copy())\n",
    "\n",
    "            method_runner = MethodRunner(\n",
    "                func=tl.decomposition.tucker,\n",
    "                gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                ram_memory_tracker=RAMMemoryTracker(),\n",
    "                time_tracker=TimeTracker(),\n",
    "            )\n",
    "\n",
    "            method_logger = MethodLogger(\n",
    "                method_name=method_name,\n",
    "                method_input_tensor=tensor_param,\n",
    "                qualitative_metrics={\n",
    "                    \"Language\": \"Python\",\n",
    "                    \"Library\": \"TensorLy\",\n",
    "                    \"TensorLy backend\": f\"{backend}\",\n",
    "                    \"Tensor type\": \"Dense\",\n",
    "                    \"Platform\": \"CPU, GPU\",\n",
    "                    \"Decomposition method\": \"Tucker\",\n",
    "                },\n",
    "                method_args={\n",
    "                    \"tensor\": tensor_param,\n",
    "                    \"rank\": rank_param,\n",
    "                    \"n_iter_max\": n_iter_max_param,\n",
    "                    \"init\": init_method,\n",
    "                    \"svd\": svd_func,\n",
    "                    \"random_state\": random_state_param,\n",
    "                },\n",
    "                runner=method_runner,\n",
    "            )\n",
    "\n",
    "        core, factors = method_runner.method_result\n",
    "\n",
    "        if backend == \"pytorch\":\n",
    "            tensor_param = tl.tensor(tensor_param.cpu())\n",
    "            core = tl.tensor(core.cpu())\n",
    "            for index, factor in enumerate(factors):\n",
    "                factors[index] = tl.tensor(factor.cpu())\n",
    "\n",
    "        reconstruct_frames_from_tensorly_tt_factors = tl.tucker_tensor.tucker_to_tensor((core, factors))\n",
    "\n",
    "        frobenius_error_calculator, compression_ratio_calculator = MetricCalculatorFactory.create_calculators(\n",
    "            f\"{method_logger.qualitative_metrics['Library']}_{method_logger.qualitative_metrics['Decomposition method']}\"\n",
    "        )\n",
    "\n",
    "        method_logger.quantitative_metrics[\"compression_ratio\"] = [\n",
    "            compression_ratio_calculator.calculate(original_tensor=tensor_param, core=core, factors=factors)\n",
    "        ]\n",
    "\n",
    "        method_logger.quantitative_metrics[\"frobenius_error\"] = [\n",
    "            frobenius_error_calculator.calculate(original_tensor=tensor_param, reconstructed_frames=reconstruct_frames_from_tensorly_tt_factors)\n",
    "        ]\n",
    "\n",
    "        method_logger.save_logs_to_file(is_test=False)\n",
    "\n",
    "        reconstructed_frames = []\n",
    "\n",
    "        reconstructed_frames = [normalize_frames(frame) for frame in reconstruct_frames_from_tensorly_tt_factors]\n",
    "\n",
    "        save_frames_as_video(name=method_logger.name, frames=reconstructed_frames, fps=original_fps, frame_size=frame_size)\n",
    "    except (torch.cuda.OutOfMemoryError, MemoryError) as e:\n",
    "        print(f\"Пропущена итерация из-за недостатка памяти: {backend}, {svd_func}, {init_method}. Ошибка: {e!s}\")\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train - MPS (tensorly.decomposition.tensor_train)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.563086200Z",
     "start_time": "2024-10-02T16:33:12.562682Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_param = [1, 500, 302, 500, 1]\n",
    "\n",
    "svd_params = [\"truncated_svd\", \"symeig_svd\", \"randomized_svd\"]\n",
    "\n",
    "backend_params = [\"pytorch\", \"numpy\"]\n",
    "\n",
    "total_iterations = len(list(product(backend_params, svd_params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Implementation"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.565085700Z",
     "start_time": "2024-10-02T20:38:14.416549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загруженные логи:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущена итерация: логи уже существуют для TensorLy_TensorTrain_pytorch_truncated_svd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:03<?, ?it/s]\u001b[A\n",
      "Проверка набора параметров:  33%|███▎      | 2/6 [00:03<00:06,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущена итерация из-за недостатка памяти: pytorch, symeig_svd. Ошибка: CUDA out of memory. Tried to allocate 177.30 GiB. GPU 0 has a total capacity of 11.00 GiB of which 8.82 GiB is free. Of the allocated memory 740.47 MiB is allocated by PyTorch, and 365.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Пропущена итерация: логи уже существуют для TensorLy_TensorTrain_pytorch_randomized_svd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Эксперимент набора параметров:  20%|██        | 1/5 [01:32<06:09, 92.35s/it]\u001b[A\n",
      "Эксперимент набора параметров:  40%|████      | 2/5 [03:00<04:29, 89.98s/it]\u001b[A\n",
      "Эксперимент набора параметров:  60%|██████    | 3/5 [04:28<02:57, 88.77s/it]\u001b[A\n",
      "Эксперимент набора параметров:  80%|████████  | 4/5 [05:58<01:29, 89.36s/it]\u001b[A\n",
      "Эксперимент набора параметров: 100%|██████████| 5/5 [07:24<00:00, 88.95s/it]\u001b[A\n",
      "Проверка набора параметров:  67%|██████▋   | 4/6 [07:32<04:25, 132.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео сохранено как ../.cache/output_videos/TensorLy_TensorTrain_numpy_truncated_svd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Проверка набора параметров:  83%|████████▎ | 5/6 [07:32<01:33, 93.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущена итерация из-за недостатка памяти: numpy, symeig_svd. Ошибка: Unable to allocate 44.3 GiB for an array with shape (218160, 218160) and data type uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Эксперимент набора параметров:  20%|██        | 1/5 [13:23<53:33, 803.29s/it]\u001b[A\n",
      "Эксперимент набора параметров:  40%|████      | 2/5 [26:59<40:32, 810.92s/it]\u001b[A\n",
      "Эксперимент набора параметров:  60%|██████    | 3/5 [40:36<27:06, 813.45s/it]\u001b[A\n",
      "Эксперимент набора параметров:  80%|████████  | 4/5 [53:57<13:28, 808.87s/it]\u001b[A\n",
      "Эксперимент набора параметров: 100%|██████████| 5/5 [1:07:43<00:00, 812.69s/it]\u001b[A\n",
      "Проверка набора параметров: 100%|██████████| 6/6 [1:15:22<00:00, 753.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео сохранено как ../.cache/output_videos/TensorLy_TensorTrain_numpy_randomized_svd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logs = load_logs_from_file(log_file_path)\n",
    "#\n",
    "# for backend, svd_func in tqdm(product(backend_params, svd_params), desc=\"Проверка набора параметров\", total=total_iterations):\n",
    "#     method_name = f\"TensorLy_TensorTrain_{backend}_{svd_func}\"\n",
    "#\n",
    "#     if logs:\n",
    "#         existing_log = next(\n",
    "#             (\n",
    "#                 log\n",
    "#                 for log in logs\n",
    "#                 if log[\"method_name\"] == method_name\n",
    "#                 and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "#                 and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "#             ),\n",
    "#             None,\n",
    "#         )\n",
    "#         if existing_log:\n",
    "#             print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "#             continue\n",
    "#\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     torch.cuda.synchronize()\n",
    "#\n",
    "#     try:\n",
    "#         with tl.backend_context(backend):\n",
    "#             if backend == \"pytorch\":\n",
    "#                 tensor_param = tl.tensor(video_frames.copy()).to(torch_device)\n",
    "#             elif backend == \"numpy\" or backend is None:\n",
    "#                 tensor_param = tl.tensor(video_frames.copy())\n",
    "#\n",
    "#             method_logger = MethodLogger(\n",
    "#                 method_name=method_name,\n",
    "#                 backend_name=backend,\n",
    "#                 method_input_tensor=tensor_param,\n",
    "#                 qualitative_metrics={\n",
    "#                     \"Language\": \"Python\",\n",
    "#                     \"Library\": \"TensorLy\",\n",
    "#                     \"TensorLy backend\": f\"{backend}\",\n",
    "#                     \"Tensor type\": \"Dense\",\n",
    "#                     \"Platform\": \"CPU, GPU\",\n",
    "#                     \"Decomposition method\": \"TensorTrain\",\n",
    "#                 },\n",
    "#                 method_args={\n",
    "#                     \"input_tensor\": tensor_param,\n",
    "#                     \"rank\": rank_param,\n",
    "#                     \"svd\": svd_func,\n",
    "#                 },\n",
    "#                 func=tl.decomposition.tensor_train,\n",
    "#             )\n",
    "#\n",
    "#         method_logs_list.append(method_logger)\n",
    "#\n",
    "#         tt_factors = method_logger.method_result\n",
    "#         factors_numpy = []\n",
    "#\n",
    "#         if backend == \"pytorch\":\n",
    "#             tensor_param = tl.tensor(tensor_param.cpu())\n",
    "#             for tt_factor in tt_factors:\n",
    "#                 factors_numpy.append(tt_factor.cpu())\n",
    "#         elif backend == \"numpy\":\n",
    "#             factors_numpy = tt_factors\n",
    "#\n",
    "#         reconstruct_frames_from_tensorly_tt_factors = tl.tt_to_tensor(factors_numpy)\n",
    "#\n",
    "#         method_logger.quantitative_metrics[\"compression_ratio\"] = 100.0 * get_tensors_size(*factors_numpy) / get_tensors_size(tensor_param)\n",
    "#\n",
    "#         method_logger.quantitative_metrics[\"frobenius_error\"] = (\n",
    "#             100.0 * tl.norm(reconstruct_frames_from_tensorly_tt_factors - tensor_param) / tl.norm(tensor_param)\n",
    "#         ).item()\n",
    "#\n",
    "#         save_logs_to_file(method_logs=method_logger)\n",
    "#\n",
    "#         reconstructed_frames = []\n",
    "#\n",
    "#         for i in range(len(reconstruct_frames_from_tensorly_tt_factors)):\n",
    "#             reconstructed_frames.append(normalize_frames(reconstruct_frames_from_tensorly_tt_factors[i]))\n",
    "#\n",
    "#         save_frames_as_video(name=method_logger.name, frames=reconstructed_frames, fps=original_fps, frame_size=frame_size)\n",
    "#\n",
    "#     except (torch.cuda.OutOfMemoryError, MemoryError) as e:\n",
    "#         print(f\"Пропущена итерация из-за недостатка памяти: {backend}, {svd_func}. Ошибка: {e!s}\")\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#         torch.cuda.synchronize()\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## T3F"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.565085700Z",
     "start_time": "2024-10-02T22:47:50.805438Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor_param = video_frames.copy().astype(np.float32)\n",
    "\n",
    "rank_param = [1, 500, 302, 500, 1]\n",
    "\n",
    "backend_param = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Implementation"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.565085700Z",
     "start_time": "2024-10-02T23:00:20.622859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эксперимент набора параметров: 100%|██████████| 5/5 [03:33<00:00, 42.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео сохранено как ../.cache/output_videos/T3F_TensorTrain.mp4\n"
     ]
    }
   ],
   "source": [
    "# logs = load_logs_from_file(log_file_path)\n",
    "#\n",
    "# method_name = \"T3F_TensorTrain\"\n",
    "#\n",
    "# if logs:\n",
    "#     existing_log = next((log for log in logs if log[\"method_name\"] == method_name), None)\n",
    "#     if existing_log:\n",
    "#         error_message = f\"Пропущена итерация: логи уже существуют для {method_name}\"\n",
    "#         raise error_message\n",
    "#\n",
    "# gc.collect()\n",
    "#\n",
    "# method_logger = MethodLogger(\n",
    "#     method_name=method_name,\n",
    "#     backend_name=backend_param,\n",
    "#     method_input_tensor=tensor_param,\n",
    "#     qualitative_metrics={\n",
    "#         \"Language\": \"Python\",\n",
    "#         \"Library\": \"T3F\",\n",
    "#         \"T3F backend\": f\"{backend_param}\",\n",
    "#         \"Tensor type\": \"Dense\",\n",
    "#         \"Platform\": \"CPU, GPU\",\n",
    "#         \"Decomposition method\": \"TensorTrain\",\n",
    "#     },\n",
    "#     method_args={\n",
    "#         \"tens\": tensor_param,\n",
    "#         \"max_tt_rank\": rank_param,\n",
    "#     },\n",
    "#     func=t3f.to_tt_tensor,\n",
    "# )\n",
    "#\n",
    "# method_logs_list.append(method_logger)\n",
    "#\n",
    "# tt_factors = method_logger.method_result\n",
    "#\n",
    "# reconstruct_frames_from_t3f_tt_factors = t3f.full(tt_factors)\n",
    "#\n",
    "# method_logger.quantitative_metrics[\"compression_ratio\"] = 100.0 * get_tensors_size(*tt_factors.tt_cores) / get_tensors_size(tensor_param)\n",
    "#\n",
    "# method_logger.quantitative_metrics[\"frobenius_error\"] = (\n",
    "#     100.0 * np.linalg.norm(reconstruct_frames_from_t3f_tt_factors - tensor_param) / np.linalg.norm(tensor_param)\n",
    "# )\n",
    "#\n",
    "# save_logs_to_file(method_logs=method_logger)\n",
    "#\n",
    "# reconstructed_frames = []\n",
    "#\n",
    "# for i in range(len(reconstruct_frames_from_t3f_tt_factors)):\n",
    "#     reconstructed_frames.append(normalize_frames(reconstruct_frames_from_t3f_tt_factors[i]))\n",
    "#\n",
    "# save_frames_as_video(name=method_logger.name, frames=reconstructed_frames, fps=original_fps, frame_size=frame_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TeNPy"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.566085400Z",
     "start_time": "2024-10-03T00:15:40.286018Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensor_param = video_frames.copy().astype(np.float32)\n",
    "#\n",
    "# # Размерность физического индекса\n",
    "# d = tensor_param.shape[-1]  # в вашем случае это 3\n",
    "#\n",
    "# # Создаем объект LegCharge\n",
    "# leg = LegCharge.from_trivial(d)\n",
    "#\n",
    "# # Создаем объекты Site для каждого физического индекса, кроме последнего\n",
    "# sites = [Site(leg) for _ in range(tensor_param.ndim - 1)]\n",
    "#\n",
    "# rank_param = [1, 500, 302, 500, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Implementation"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.566085400Z",
     "start_time": "2024-10-03T00:15:49.865401Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'has_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mps \u001b[38;5;241m=\u001b[39m \u001b[43mMPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m reconstructed_tensor \u001b[38;5;241m=\u001b[39m mps\u001b[38;5;241m.\u001b[39mto_full_tensor()\n",
      "File \u001b[1;32mE:\\__git_projects\\tensor-compression-methods\\.venv\\Lib\\site-packages\\tenpy\\networks\\mps.py:2039\u001b[0m, in \u001b[0;36mMPS.from_full\u001b[1;34m(cls, sites, psi, form, cutoff, normalize, bc, outer_S)\u001b[0m\n\u001b[0;32m   2037\u001b[0m S_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m (L \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2038\u001b[0m norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;28;01melse\u001b[39;00m npc\u001b[38;5;241m.\u001b[39mnorm(psi)\n\u001b[1;32m-> 2039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpsi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_label\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   2040\u001b[0m     psi \u001b[38;5;241m=\u001b[39m psi\u001b[38;5;241m.\u001b[39madd_trivial_leg(\u001b[38;5;241m0\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL\u001b[39m\u001b[38;5;124m'\u001b[39m, qconj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m bc \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinite\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m psi\u001b[38;5;241m.\u001b[39mget_leg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mind_len \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'has_label'"
     ]
    }
   ],
   "source": [
    "# mps = MPS.from_full(sites=sites, psi=tensor_param, normalize=False)\n",
    "#\n",
    "# reconstructed_tensor = mps.to_full_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T22:30:40.566085400Z",
     "start_time": "2024-10-02T23:55:07.923523Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эксперимент набора параметров:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown type of a",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m---> 19\u001b[0m method_logs \u001b[38;5;241m=\u001b[39m \u001b[43mMethodLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_input_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqualitative_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLibrary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTeNPy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensor type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDense\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlatform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCPU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDecomposition method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorTrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msites\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnormalize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_full\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m method_logs_list\u001b[38;5;241m.\u001b[39mappend(method_logs)\n\u001b[0;32m     39\u001b[0m tt_factors \u001b[38;5;241m=\u001b[39m method_logs\u001b[38;5;241m.\u001b[39mmethod_result\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36mMethodLogger.__init__\u001b[1;34m(self, method_name, method_input_tensor, qualitative_metrics, func, method_args)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod_input_tensor \u001b[38;5;241m=\u001b[39m method_input_tensor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m func\n\u001b[1;32m---> 13\u001b[0m gpu_allocated_mem_usages, gpu_cached_mem_usages, ram_mem_usages, durations, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_method_with_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod_result \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantitative_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_allocated_mem_usage\u001b[39m\u001b[38;5;124m'\u001b[39m: gpu_allocated_mem_usages,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_cached_mem_usages\u001b[39m\u001b[38;5;124m'\u001b[39m: gpu_cached_mem_usages,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mram_mem_usage\u001b[39m\u001b[38;5;124m'\u001b[39m: ram_mem_usages,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: durations,\n\u001b[0;32m     22\u001b[0m }\n",
      "Cell \u001b[1;32mIn[4], line 62\u001b[0m, in \u001b[0;36mMethodLogger._run_method_with_tracking\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gpu_allocated_memory_used, gpu_cached_memory_used, ram_memory_used, duration, result\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(MethodLogger\u001b[38;5;241m.\u001b[39mexperiments_count), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЭксперимент набора параметров\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 62\u001b[0m     gpu_allocated_memory_used, gpu_cached_memory_used, ram_memory_used, duration, result \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     gpu_allocated_mem_usages\u001b[38;5;241m.\u001b[39mappend(gpu_allocated_memory_used)\n\u001b[0;32m     65\u001b[0m     gpu_cached_mem_usages\u001b[38;5;241m.\u001b[39mappend(gpu_cached_memory_used)\n",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m, in \u001b[0;36mMethodLogger._run_method_with_tracking.<locals>.wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m gpu_cached_memory_before \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_reserved()\n\u001b[0;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 42\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[0;32m     45\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mE:\\__git_projects\\tensor-compression-methods\\.venv\\Lib\\site-packages\\tenpy\\networks\\mps.py:2038\u001b[0m, in \u001b[0;36mMPS.from_full\u001b[1;34m(cls, sites, psi, form, cutoff, normalize, bc, outer_S)\u001b[0m\n\u001b[0;32m   2036\u001b[0m B_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m L\n\u001b[0;32m   2037\u001b[0m S_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m (L \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 2038\u001b[0m norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m psi\u001b[38;5;241m.\u001b[39mhas_label(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   2040\u001b[0m     psi \u001b[38;5;241m=\u001b[39m psi\u001b[38;5;241m.\u001b[39madd_trivial_leg(\u001b[38;5;241m0\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvL\u001b[39m\u001b[38;5;124m'\u001b[39m, qconj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\__git_projects\\tensor-compression-methods\\.venv\\Lib\\site-packages\\tenpy\\linalg\\np_conserved.py:3719\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, convert_to_float)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(a\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, )), \u001b[38;5;28mord\u001b[39m)\n\u001b[0;32m   3718\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m-> 3719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43m[\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   3720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown type of a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\__git_projects\\tensor-compression-methods\\.venv\\Lib\\site-packages\\tenpy\\linalg\\np_conserved.py:3719\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(a\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, )), \u001b[38;5;28mord\u001b[39m)\n\u001b[0;32m   3718\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m-> 3719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm([\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m a] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   3720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown type of a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\__git_projects\\tensor-compression-methods\\.venv\\Lib\\site-packages\\tenpy\\linalg\\np_conserved.py:3721\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, convert_to_float)\u001b[0m\n\u001b[0;32m   3719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm([norm(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m a] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   3720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown type of a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: unknown type of a"
     ]
    }
   ],
   "source": [
    "# logs = load_logs_from_file(log_file_path)\n",
    "#\n",
    "# method_name = f\"TeNPy_TensorTrain\"\n",
    "#\n",
    "# if logs:\n",
    "#     existing_log = next(\n",
    "#         (log for log in logs if log['method_name'] == method_name),\n",
    "#         None\n",
    "#     )\n",
    "#     if existing_log:\n",
    "#         error_message = f\"Пропущена итерация: логи уже существуют для {method_name}\"\n",
    "#         raise error_message\n",
    "#\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.synchronize()\n",
    "#\n",
    "# method_logs = MethodLogger(\n",
    "#     method_name=method_name,\n",
    "#     method_input_tensor=tensor_param,\n",
    "#     qualitative_metrics={\n",
    "#         \"Language\": \"Python\",\n",
    "#         \"Library\": \"TeNPy\",\n",
    "#         \"Tensor type\": \"Dense\",\n",
    "#         \"Platform\": \"CPU\",\n",
    "#         \"Decomposition method\": \"TensorTrain\",\n",
    "#     },\n",
    "#     method_args={\n",
    "#         \"sites\": tensor_param,\n",
    "#         \"psi\": rank_param,\n",
    "#         \"normalize\": False,\n",
    "#     },\n",
    "#     func=tenpy.networks.mps.MPS.from_full\n",
    "# )\n",
    "#\n",
    "# method_logs_list.append(method_logs)\n",
    "#\n",
    "# tt_factors = method_logs.method_result\n",
    "#\n",
    "# reconstruct_frames_from_tenpy_tt_factors = tt_factors.to_full_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method_logs.quantitative_metrics['compression_ratio'] = (100.0 * get_tensors_size(*tt_factors) / get_tensors_size(tensor_param))\n",
    "\n",
    "# method_logs.quantitative_metrics['frobenius_error'] = (\n",
    "#         100.0 * np.linalg.norm(reconstruct_frames_from_tenpy_tt_factors - tensor_param) / tl.norm(\n",
    "#         tensor_param))\n",
    "#\n",
    "# save_logs_to_file(method_logs=method_logs, is_test=True)\n",
    "#\n",
    "# reconstructed_frames = []\n",
    "#\n",
    "# for i in range(len(reconstruct_frames_from_tenpy_tt_factors)):\n",
    "#     reconstructed_frames.append(normalize_frame_tensorly_tensortrain(reconstruct_frames_from_tenpy_tt_factors[i]))\n",
    "#\n",
    "# save_frames_as_video(name=method_logs.name, frames=reconstructed_frames, fps=original_fps, frame_size=frame_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
