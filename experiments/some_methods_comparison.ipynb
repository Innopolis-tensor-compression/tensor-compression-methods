{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "бенчмарк методов декомпозиции"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.320582Z",
     "start_time": "2025-06-15T19:20:26.455046Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "from src.utils.eeg_controller import get_eegbci_dataset\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"src.utils.method_loggers\",\n",
    "    \"src.utils.method_runners\",\n",
    "    \"src.utils.metrics_calculators\",\n",
    "    \"src.utils.tensor_handlers\",\n",
    "    \"src.utils.trackers\",\n",
    "    \"src.utils.video_controller\",\n",
    "    \"src.utils.optimal_rank_finders\",\n",
    "    \"src.utils.benchmark.calculate_optimized_rank_tucker\",\n",
    "    \"src.utils.benchmark.calculate_optimized_rank_tensor_train\",\n",
    "]\n",
    "\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import contextlib\n",
    "import gc\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "\n",
    "np.random.seed(42)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import t3f\n",
    "import tensorly as tl\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.eeg_controller import create_eeg_limo_data_tensor\n",
    "from src.utils.image_controller import download_image, extract_image_frames\n",
    "from src.utils.method_loggers import MethodLogger\n",
    "from src.utils.method_runners import MethodRunner\n",
    "from src.utils.optimal_rank_finders import (\n",
    "    find_optimal_rank_tensor_train_by_compression_ratio,\n",
    "    find_optimal_rank_tucker_by_compression_ratio,\n",
    ")\n",
    "from src.utils.read_logs import LogReader\n",
    "from src.utils.save_frames import SaveFramesFactory\n",
    "from src.utils.tensor_handlers import normalize_frames\n",
    "from src.utils.trackers import (\n",
    "    GPUTensorflowMemoryTracker,\n",
    "    GPUTorchMemoryTracker,\n",
    "    RAMMemoryTracker,\n",
    "    TimeTracker,\n",
    ")\n",
    "from src.utils.video_controller import download_youtube_video, extract_frames\n",
    "from src.utils.benchmark.calculate_optimized_rank_tucker import global_optimize_tucker_rank\n",
    "from src.utils.benchmark.calculate_optimized_rank_tensor_train import global_optimize_tensor_train_rank\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3106"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.458235Z",
     "start_time": "2025-06-15T19:20:27.412651Z"
    }
   },
   "source": [
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.575679Z",
     "start_time": "2025-06-15T19:20:27.529065Z"
    }
   },
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.677275Z",
     "start_time": "2025-06-15T19:20:27.627926Z"
    }
   },
   "source": [
    "tf_physical_device = tf.config.list_physical_devices(\"GPU\")[0].name\n",
    "tf_device = \":\".join(tf_physical_device.split(\":\")[1:3])\n",
    "tf_devices = [tf_device]\n",
    "tf_physical_device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Get tensors"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some params"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.754396Z",
     "start_time": "2025-06-15T19:20:27.711Z"
    }
   },
   "source": [
    "proxy_url = os.getenv(\"PROXY_URL\")\n",
    "log_file_path = \"../.cache/method_logs.json\"\n",
    "method_logs_list = []"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "## Get some tensors from different data types"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Video"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.828462Z",
     "start_time": "2025-06-15T19:20:27.785567Z"
    }
   },
   "source": [
    "cache_dir_video = \"../.cache/video\"\n",
    "\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=eSKe2Vx-rpY\",\n",
    "    \"https://www.youtube.com/watch?v=zk1mAd77Hr4\",\n",
    "    \"https://www.youtube.com/watch?v=vSLHsTh421w\",\n",
    "]\n",
    "\n",
    "videos = {}"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:27.908322Z",
     "start_time": "2025-06-15T19:20:27.863356Z"
    }
   },
   "source": [
    "video_paths = [\n",
    "    download_youtube_video(\n",
    "        video_url=video_url,\n",
    "        cache_dir=cache_dir_video.__str__(),\n",
    "        proxy_url=proxy_url,\n",
    "    )\n",
    "    for video_url in video_urls\n",
    "]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео уже загружено и закешировано: ../.cache/video/eSKe2Vx-rpY.mp4\n",
      "Видео уже загружено и закешировано: ../.cache/video/zk1mAd77Hr4.mp4\n",
      "Видео уже загружено и закешировано: ../.cache/video/vSLHsTh421w.mp4\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:28.136832Z",
     "start_time": "2025-06-15T19:20:27.960358Z"
    }
   },
   "source": [
    "for video_index, video_path in enumerate(video_paths):\n",
    "    video_frames, original_fps, frame_size = extract_frames(video_path)\n",
    "\n",
    "    videos[f\"video-{video_index}\"] = {\n",
    "        \"video_url\": video_urls[video_index],\n",
    "        \"video_path\": video_path,\n",
    "        \"original_fps\": original_fps,\n",
    "        \"frame_size\": frame_size,\n",
    "        \"frames\": video_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"video-{video_index} - {video_frames.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-0 - (220, 256, 144, 3)\n",
      "video-1 - (100, 144, 192, 3)\n",
      "video-2 - (237, 144, 256, 3)\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Image"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:28.249952Z",
     "start_time": "2025-06-15T19:20:28.199573Z"
    }
   },
   "source": [
    "cache_dir_image = \"../.cache/image\"\n",
    "\n",
    "image_urls = [\n",
    "    \"https://i.pinimg.com/564x/04/b2/68/04b26838bdd5e2ba54d0144558685bae.jpg\",\n",
    "    \"https://cdnstatic.rg.ru/crop620x412/uploads/images/187/94/47/iStock-644032024.jpg\",\n",
    "    \"https://i.sstatic.net/uQggz.png\",\n",
    "]\n",
    "\n",
    "images = {}"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:28.351965Z",
     "start_time": "2025-06-15T19:20:28.294511Z"
    }
   },
   "source": [
    "image_paths = [download_image(image_url, cache_dir_image) for image_url in image_urls]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение уже загружено и закешировано: ../.cache/image/04b26838bdd5e2ba54d0144558685bae.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/iStock-644032024.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/uQggz.png\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:28.568270Z",
     "start_time": "2025-06-15T19:20:28.494917Z"
    }
   },
   "source": [
    "for image_index, image_path in enumerate(image_paths):\n",
    "    image_frames = extract_image_frames(image_path)\n",
    "\n",
    "    images[f\"image-{image_index}\"] = {\n",
    "        \"image_url\": image_urls[image_index],\n",
    "        \"image_path\": image_path,\n",
    "        \"frames\": image_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"image-{image_index} - {image_frames.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 - (564, 564, 3)\n",
      "image-1 - (412, 620, 3)\n",
      "image-2 - (689, 1195, 3)\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:28.727577Z",
     "start_time": "2025-06-15T19:20:28.686488Z"
    }
   },
   "source": [
    "# from src.utils.save_frames import SaveFramesAsImage\n",
    "#\n",
    "# SaveFramesAsImage.save_frames('test', images['image-2']['frames'])"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### EEG"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:42.751910Z",
     "start_time": "2025-06-15T19:20:28.750631Z"
    }
   },
   "source": [
    "cache_dir_eeg = \"../.cache/eeg\"\n",
    "\n",
    "eegs = {\n",
    "    \"eeg-0\": {\"frames\": get_eegbci_dataset(cache_dir_eeg=cache_dir_eeg)},\n",
    "    \"eeg-1\": {\"frames\": create_eeg_limo_data_tensor(cache_dir_eeg=cache_dir_eeg)},\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:42.836480Z",
     "start_time": "2025-06-15T19:20:42.788952Z"
    }
   },
   "source": [
    "for index, eeg in eegs.items():\n",
    "    print(f\"{index} - {eeg['frames'].shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg-0 - (4, 12, 2, 15, 64, 1281)\n",
      "eeg-1 - (3, 1050, 2, 132, 201)\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Find optimal ranks"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Params"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:42.933480Z",
     "start_time": "2025-06-15T19:20:42.886718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio = 50.0\n",
    "frobenius_error_coef = 1.0\n",
    "compression_ratio_coef = 10.0"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tucker"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:43.007283Z",
     "start_time": "2025-06-15T19:20:42.965261Z"
    }
   },
   "source": [
    "tucker_args = {\n",
    "    \"svd\": \"truncated_svd\",\n",
    "    \"init\": \"svd\",  # random, svd\n",
    "    \"random_state\": 42,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:43.582849Z",
     "start_time": "2025-06-15T19:20:43.039170Z"
    }
   },
   "source": [
    "input_tucker_tensors = {\n",
    "    \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-0\": eegs[\"eeg-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-1\": eegs[\"eeg-1\"][\"frames\"].copy().astype(np.float32),\n",
    "}\n",
    "\n",
    "tensor_tucker_rank_mapping = {\n",
    "    \"image-0\": [252, 255, 3],\n",
    "    \"image-1\": [220, 231, 3],\n",
    "    \"image-2\": [212, 595, 3],\n",
    "    \"video-0\": [176, 205, 112, 3],\n",
    "    \"video-1\": [51, 144, 186, 3],\n",
    "    \"video-2\": [222, 110, 178, 3],\n",
    "    \"eeg-0\": [4, 12, 2, 8, 63, 1221],\n",
    "    \"eeg-1\": [3, 1050, 2, 131, 100],\n",
    "    \n",
    "    # old with custom local optimization algorithm\n",
    "    # \"image-0\": [252, 254, 3],\n",
    "    # \"image-1\": [216, 232, 3],\n",
    "    # \"image-2\": [261, 534, 3],\n",
    "    # \"video-0\": [173, 194, 120, 3],\n",
    "    # \"video-1\": [58, 143, 165, 3],\n",
    "    # \"video-2\": [219, 115, 172, 3],\n",
    "    # \"eeg-0\": [4, 12, 2, 8, 64, 1171],\n",
    "    # \"eeg-1\": [3, 1046, 1, 132, 199],\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:45.466916Z",
     "start_time": "2025-06-15T19:20:43.621272Z"
    }
   },
   "source": [
    "for tensor_name, tensor_data in input_tucker_tensors.items():\n",
    "    with tl.backend_context(\"pytorch\"):\n",
    "        try:\n",
    "            if tensor_name not in tensor_tucker_rank_mapping:\n",
    "                print(f\"Processing tensor: {tensor_name}\")\n",
    "                method = \"differential_evolution\"\n",
    "\n",
    "                try:\n",
    "                    reconstructed_tensor, weight, factors, optimal_rank, final_loss_value, optimize_result, iteration_logs = (\n",
    "                        global_optimize_tucker_rank(\n",
    "                            optimization_method=method,\n",
    "                            tensor=tensor_data,\n",
    "                            target_compression_ratio=target_compression_ratio,\n",
    "                            frobenius_error_coef=frobenius_error_coef,\n",
    "                            compression_ratio_coef=compression_ratio_coef,\n",
    "                            verbose=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    tensor_tucker_rank_mapping[tensor_name] = optimal_rank\n",
    "\n",
    "                    frobenius_error = iteration_logs[-1]['metrics']['frobenius_error'] * 100\n",
    "                    compression_ratio = iteration_logs[-1]['metrics']['compression_ratio'] * 100\n",
    "\n",
    "                    print(\n",
    "                        f\"Tensor {tensor_name}: Best Rank = {optimal_rank}. Last iter results: Frobenius Error = {frobenius_error:.4f}%, Compression Ratio = {compression_ratio:.4f}%\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with method {method}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping tensor: {tensor_name} cause rank is exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tensor {tensor_name}: {e}\")\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tensor: image-0 cause rank is exist\n",
      "Skipping tensor: image-1 cause rank is exist\n",
      "Skipping tensor: image-2 cause rank is exist\n",
      "Skipping tensor: video-0 cause rank is exist\n",
      "Skipping tensor: video-1 cause rank is exist\n",
      "Skipping tensor: video-2 cause rank is exist\n",
      "Skipping tensor: eeg-0 cause rank is exist\n",
      "Skipping tensor: eeg-1 cause rank is exist\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:45.545960Z",
     "start_time": "2025-06-15T19:20:45.498801Z"
    }
   },
   "source": [
    "for tensor_name, tensor in input_tucker_tensors.items():\n",
    "    print(tensor_name, tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 (564, 564, 3)\n",
      "image-1 (412, 620, 3)\n",
      "image-2 (689, 1195, 3)\n",
      "video-0 (220, 256, 144, 3)\n",
      "video-1 (100, 144, 192, 3)\n",
      "video-2 (237, 144, 256, 3)\n",
      "eeg-0 (4, 12, 2, 15, 64, 1281)\n",
      "eeg-1 (3, 1050, 2, 132, 201)\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:45.635967Z",
     "start_time": "2025-06-15T19:20:45.587710Z"
    }
   },
   "source": [
    "for tensor_name, rank in tensor_tucker_rank_mapping.items():\n",
    "    print(tensor_name, rank)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 [252, 255, 3]\n",
      "image-1 [220, 231, 3]\n",
      "image-2 [212, 595, 3]\n",
      "video-0 [176, 205, 112, 3]\n",
      "video-1 [51, 144, 186, 3]\n",
      "video-2 [222, 110, 178, 3]\n",
      "eeg-0 [4, 12, 2, 8, 63, 1221]\n",
      "eeg-1 [3, 1050, 2, 131, 100]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:45.718588Z",
     "start_time": "2025-06-15T19:20:45.670675Z"
    }
   },
   "source": [
    "tensor_train_args = {\"svd\": \"truncated_svd\"}"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:46.304948Z",
     "start_time": "2025-06-15T19:20:45.754054Z"
    }
   },
   "source": [
    "input_tensor_train_tensors = {\n",
    "    \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-0\": eegs[\"eeg-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-1\": eegs[\"eeg-1\"][\"frames\"].copy().astype(np.float32),\n",
    "}\n",
    "\n",
    "tensor_tensor_train_rank_mapping = {\n",
    "    \"image-0\": [1, 212, 3, 1],\n",
    "    \"image-1\": [1, 233, 2, 1],\n",
    "    \"image-2\": [1, 289, 3, 1],\n",
    "    \"video-0\": [1, 213, 222, 3, 1],\n",
    "    \"video-1\": [1, 83, 331, 3, 1],\n",
    "    \"video-2\": [1, 237, 374, 3, 1],\n",
    "    \"eeg-0\": [1, 4, 48, 96, 720, 1280, 1],\n",
    "    \"eeg-1\": [1, 3, 3150, 3152, 129, 1],\n",
    "    \n",
    "    # old\n",
    "    # \"image-0\": [1, 212, 3, 1],\n",
    "    # \"image-1\": [1, 169, 3, 1],\n",
    "    # \"image-2\": [1, 289, 3, 1],\n",
    "    # \"video-0\": [1, 220, 215, 1, 1],\n",
    "    # \"video-1\": [1, 100, 277, 3, 1],\n",
    "    # \"video-2\": [1, 237, 374, 3, 1],\n",
    "    # \"eeg-0\": [1, 4, 48, 2, 30, 1282, 1],\n",
    "}\n",
    "\n",
    "# eeg-1 - (3, 1050, 2, 132, 201)\n",
    "# 11h eeg-1 1795 | [1, 3, 1532, 217, 47, 1] | 4.095930 % | 44.831035 %"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.134354Z",
     "start_time": "2025-06-15T19:20:46.341246Z"
    }
   },
   "source": [
    "for tensor_name, tensor_data in input_tensor_train_tensors.items():\n",
    "    with tl.backend_context(\"pytorch\"):\n",
    "        try:\n",
    "            if tensor_name not in tensor_tensor_train_rank_mapping:\n",
    "                print(f\"Processing tensor: {tensor_name}\")\n",
    "                method = \"differential_evolution\"\n",
    "\n",
    "                try:\n",
    "                    reconstructed_tensor, tt_factors, optimal_rank, final_loss_value, optimize_result, iteration_logs = (\n",
    "                        global_optimize_tensor_train_rank(\n",
    "                            optimization_method=method,\n",
    "                            tensor=tensor_data,\n",
    "                            target_compression_ratio=target_compression_ratio,\n",
    "                            frobenius_error_coef=frobenius_error_coef,\n",
    "                            compression_ratio_coef=compression_ratio_coef,\n",
    "                            verbose=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    tensor_tensor_train_rank_mapping[tensor_name] = optimal_rank\n",
    "\n",
    "                    frobenius_error = iteration_logs[-1]['metrics']['frobenius_error'] * 100\n",
    "                    compression_ratio = iteration_logs[-1]['metrics']['compression_ratio'] * 100\n",
    "\n",
    "                    print(\n",
    "                        f\"Tensor {tensor_name}: Best Rank = {optimal_rank}. Last iter results: Frobenius Error = {frobenius_error:.4f}%, Compression Ratio = {compression_ratio:.4f}%\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with method {method}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping tensor: {tensor_name} cause rank is exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tensor {tensor_name}: {e}\")\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tensor: image-0 cause rank is exist\n",
      "Skipping tensor: image-1 cause rank is exist\n",
      "Skipping tensor: image-2 cause rank is exist\n",
      "Skipping tensor: video-0 cause rank is exist\n",
      "Skipping tensor: video-1 cause rank is exist\n",
      "Skipping tensor: video-2 cause rank is exist\n",
      "Skipping tensor: eeg-0 cause rank is exist\n",
      "Skipping tensor: eeg-1 cause rank is exist\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.226881Z",
     "start_time": "2025-06-15T19:20:48.175571Z"
    }
   },
   "source": [
    "for tensor_name, tensor in input_tensor_train_tensors.items():\n",
    "    print(tensor_name, tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 (564, 564, 3)\n",
      "image-1 (412, 620, 3)\n",
      "image-2 (689, 1195, 3)\n",
      "video-0 (220, 256, 144, 3)\n",
      "video-1 (100, 144, 192, 3)\n",
      "video-2 (237, 144, 256, 3)\n",
      "eeg-0 (4, 12, 2, 15, 64, 1281)\n",
      "eeg-1 (3, 1050, 2, 132, 201)\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.325842Z",
     "start_time": "2025-06-15T19:20:48.275915Z"
    }
   },
   "source": [
    "for tensor_name, rank in tensor_tensor_train_rank_mapping.items():\n",
    "    print(tensor_name, rank)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 [1, 212, 3, 1]\n",
      "image-1 [1, 233, 2, 1]\n",
      "image-2 [1, 289, 3, 1]\n",
      "video-0 [1, 213, 222, 3, 1]\n",
      "video-1 [1, 83, 331, 3, 1]\n",
      "video-2 [1, 237, 374, 3, 1]\n",
      "eeg-0 [1, 4, 48, 96, 720, 1280, 1]\n",
      "eeg-1 [1, 3, 3150, 3152, 129, 1]\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Theoretical comparison of some libraries and implementations"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some packages which can decompose some dense type of tensors, from [this](https://arxiv.org/pdf/2103.13756) paper\n",
    "\n",
    "\n",
    "Decomposition methods which used:\n",
    "1. Canonical Polyadic Decomposition as PARAllel FACtors analysis (aka PARAFAC aka CPD aka CP)\n",
    "2. Tucker Decomposition\n",
    "3. Tensor Train\n",
    "4. some variants of its (Other)\n",
    "\n",
    "Tensor types:\n",
    "1. Dense (D)\n",
    "2. Sparse (S)\n",
    "3. BlockSparse (BS)\n",
    "4. Symmetric\n",
    "5. Supersymmetric\n",
    "\n",
    "Target system:\n",
    "1. CPU (C)\n",
    "2. GPU(G)\n",
    "3. Distributed Memory (D)\n",
    "\n",
    "\n",
    "\n",
    "| Method name                                                                             | Decomposition methods implemented | Tensor Type | Platform | Language         | Git | PyPI | Want to check | Checked     |\n",
    "|-----------------------------------------------------------------------------------------|-----------------------------------|------------|----------|------------------|------|------|--------------|-------------|\n",
    "| [AdaTM](https://github.com/hpcgarage/AdaTM)                                             | CP                                | S          | C        | C                | +    | ?    |              |             |\n",
    "| [BTAS](https://github.com/ValeevGroup/BTAS)                                             | CP, Tucker                        | nan        | C        | C++              | +    | ?    |              |             |\n",
    "| [CP-CALS](https://github.com/HPAC/CP-CALS)                                              | CP, Other                         | D          | C, G     | C++, Mat         | +    |      | +            |             |\n",
    "| [CSTF](https://github.com/ZacBlanco/cstf)                                               | Other                             | S          | D        | Scala            | +    | ?    |              |             |\n",
    "| [D-Tucker](https://datalab.snu.ac.kr/dtucker/resources/DTucker-v1.0.tar.gz)             | Tucker, Other                     | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [DFacTo](http://www.joonheechoi.com/research.)                                          | CP                                | S          | C, D     | C++              |      | ?    |              |             |\n",
    "| [EXATN](https://github.com/ORNL-QCI/exatn)                                              | TensorTrain                       | D          | C, D, G  | C++, Py          | +    |      | +            |             |\n",
    "| [Genten](https://gitlab.com/tensors/genten)                                             | CP                                | D, S       | C, G     | C++              | +    |      | +            |             |\n",
    "| GigaTensor                                                                              | CP                                | D          | C        | C++, Python      |      | ?    |              |             |\n",
    "| [ITensor](https://github.com/ITensor/ITensor)                                           | TensorTrain                       | D, BS      | C, G     | C++, Julia       | +    |      | +            |             |\n",
    "| [multiway](https://cran.r-project.org/web/packages/multiway/index.html)                 | CP, Tucker, Other                 | D          | C        | R                |      | ?    |              |             |\n",
    "| [N-way toolbox](http://www.models.life.ku.dk/nwaytoolbox/download)                      | CP, Tucker, Other                 | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [ParCube](https://www.cs.ucr.edu/~epapalex/src/parCube.zip)                             | CP                                | S          | C        | Matlab           |      | ?    |              |             |\n",
    "| [ParTensor](https://github.com/neurocom/partensor-toolbox)                              | CP                                | D          | C, G     | C++              | +    |      | +            |             |\n",
    "| [ParTI!](https://github.com/hpcgarage/ParTI)                                            | CP, Tucker                        | S          | C, G     | C, CUDA, Mat     | +    | ?    |              |             |\n",
    "| [PLANC](https://github.com/ramkikannan/planc)                                           | CP                                | S          | C, D     | C++              | +    | ?    |              |             |\n",
    "| [PLS toolbox](https://eigenvector.com/software/pls-toolbox/)                            | CP          , Tucker              | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [Pytensor](https://code.google.com/archive/p/pytensor/source/default/source)            | Tucker                            | D, S       | C        | Python           |      | ?    |              |             |\n",
    "| [rTensor](https://github.com/jamesyili/rTensor)                                         | CP, Tucker, Other                 | D          | C        | R                | +    |      | +            |             |\n",
    "| [rTensor (randomized)](https://github.com/erichson/rTensor)                             | CP                                | D          | C        | Python           | +    |      | +       +    |             |\n",
    "| [scikit-tensor](https://github.com/mnick/scikit-tensor)                                 | CP, Tucker, Other                 | D, S       | C        | Python           | +    | +    | +    +   +   | too old     |\n",
    "| [Scikit-TT](https://github.com/PGelss/scikit_tt)                                        | TensorTrain                       | D          | C        | Python           | +    |      |     +   +    |             |\n",
    "| [SPALS](https://github.com/dehuacheng/SpAls)                                            | CP                                | S          | C        | C++              | +    | ?    |              |             |\n",
    "| [SPARTan](https://github.com/kperros/SPARTan)                                           | Other                             | S          | C        | Matlab           | +    | ?    |              |             |\n",
    "| [SPLATT](https://github.com/ShadenSmith/splatt)                                         | CP                                | S          | C, D     | C, C++, Oct, Mat | +    | ?    |              |             |\n",
    "| [SuSMoST](https://susmost.com/downloads.html)                                           | TensorTrain, Other                | D          | C        | Python           |      | ?    |              |             |\n",
    "| [T3F](https://github.com/Bihaqo/t3f)                                                    | TensorTrain                       | D          | C, G     | Python           | +    | +    | +    + +     | in progress |\n",
    "| [TDALAB](https://github.com/andrewssobral/TDALAB)                                       | CP                                | D, S       | C        | Python, Matlab   | +    |      | +         +  |             |\n",
    "| [TeNPy](https://github.com/tenpy/tenpy)                                        | TensorTrain                       | D          | C        | Python           | +    | +    | +      + +   | in progress |\n",
    "| [Tensor Fox](https://github.com/felipebottega/Tensor-Fox)                               | CP                                | D, S       | C        | Python, Matlab   | +    | +    | +    + +     | ?           |\n",
    "| [Tensor package](http://www.gipsa-lab.fr/~pierre.comon/TensorPackage/tensorPackage.html) | CP                                | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [Tensor Toolbox](https://gitlab.com/tensors/tensor_toolbox)                             | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |             |\n",
    "| [tensor_decomposition](https://github.com/cyclops-community/tensor_decomposition)       | CP, Tucker                        | D          | C, D     | Python           | +    |      | +        +   |             |\n",
    "| [TensorBox](https://github.com/phananhhuy/TensorBox)                                    | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |             |\n",
    "| [TensorD](https://github.com/Large-Scale-Tensor-Decomposition/tensorD)                  | CP, Tucker                        | D          | C, G     | Python           | ?    | ?    |              |             |\n",
    "| [TensorLab](https://www.tensorlab.net)                                                  | CP, Tucker, Other                 | D, S       | C        | Matlab           |      | ?    |              |             |\n",
    "| [TensorLab+](https://www.tensorlabplus.net)                                             | CP, Other                         | D, S       | C        | Matlab           |      | ?    |              |             |\n",
    "| [TensorLy](https://github.com/tensorly/tensorly)                                        | CP, Tucker, TensorTrain, Other    | D          | C, G     | Python           | +    | +    | +       + +  | in progress |\n",
    "| [Three-Way](https://github.com/cran/ThreeWay)                                           | CP, Tucker                        | D          | C        | R                | +    |      | +            |             |\n",
    "| [TNR](https://github.com/ycyuustc/matlab)                                               | Other                             | D          | C        | Matlab           | +    |      | +            |             |\n",
    "| [TT-Toolbox](https://github.com/oseledets/TT-Toolbox)                                   | TensorTrain                       | D          | C, D, G  | Matlab, Python   | +    |      | +       +    |             |\n",
    "| [xerus](https://git.hemio.de/xerus/xerus/)                                              | TensorTrain                       | D, S       | C        | C++              | +    |      | +            |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Implementations of Decompositions methods"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TensorLy"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.401291Z",
     "start_time": "2025-06-15T19:20:48.359014Z"
    }
   },
   "source": [
    "# {‘numpy’, ‘mxnet’, ‘pytorch’, ‘tensorflow’, ‘cupy’}\n",
    "# backend variants for tensorly\n",
    "# tl.set_backend('pytorch')\n",
    "# with tl.backend_context(‘pytorch’): ... pass\n",
    "\n",
    "# video_frames_cuda = tl.tensor(video_frames.copy()).to(device)\n",
    "# video_frames_cuda = tl.tensor(video_frames.copy())"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tucker (tl.decomposition.tucker)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.483762Z",
     "start_time": "2025-06-15T19:20:48.437867Z"
    }
   },
   "source": [
    "logs = LogReader.load_logs_from_file(log_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл ../.cache/method_logs.json не найден.\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.578167Z",
     "start_time": "2025-06-15T19:20:48.532355Z"
    }
   },
   "source": [
    "tl.SVD_FUNS"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truncated_svd', 'symeig_svd', 'randomized_svd']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:20:48.667311Z",
     "start_time": "2025-06-15T19:20:48.615569Z"
    }
   },
   "source": [
    "input_tensors = input_tucker_tensors\n",
    "\n",
    "tensor_rank_mapping = tensor_tucker_rank_mapping\n",
    "\n",
    "n_iter_max_param = 100\n",
    "\n",
    "svd_params = [\"truncated_svd\", \"symeig_svd\", \"randomized_svd\"]\n",
    "\n",
    "init_params = [\"svd\", \"random\"]\n",
    "\n",
    "backend_params = [\"pytorch\"]\n",
    "\n",
    "random_state_param = 42\n",
    "\n",
    "total_iterations = len(list(product(svd_params, init_params, backend_params))) * len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:21:53.621762Z",
     "start_time": "2025-06-15T19:20:48.701775Z"
    }
   },
   "source": [
    "for data_type_name_with_index, input_tensor in input_tensors.items():\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "\n",
    "    for backend, svd_func, init_method in tqdm(\n",
    "            product(backend_params, svd_params, init_params),\n",
    "            desc=\"Проверка набора параметров\",\n",
    "            total=total_iterations,\n",
    "    ):\n",
    "        library_method_name = \"TensorLy_Tucker\"\n",
    "        method_name = f\"{library_method_name}_{data_type_name_with_index}_{backend}_{svd_func}_{init_method}\"\n",
    "\n",
    "        print(f\"Current method: {method_name}\")\n",
    "\n",
    "        if logs:\n",
    "            existing_log = next(\n",
    "                (\n",
    "                    log\n",
    "                    for log in logs\n",
    "                    if log[\"method_name\"] == method_name\n",
    "                       and log[\"method_args\"].get(\"init\") == init_method\n",
    "                       and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                       and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if existing_log:\n",
    "                print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with tl.backend_context(backend):\n",
    "                if backend == \"pytorch\":\n",
    "                    tensor_param = tl.tensor(input_tensor).to(torch_device)\n",
    "                elif backend == \"numpy\" or backend is None:\n",
    "                    tensor_param = tl.tensor(input_tensor)\n",
    "\n",
    "                method_runner = MethodRunner(\n",
    "                    func=tl.decomposition.tucker,\n",
    "                    method_input_tensor=tensor_param,\n",
    "                    library_method_name=library_method_name,\n",
    "                    backend_name=backend,\n",
    "                    gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                    ram_memory_tracker=RAMMemoryTracker(),\n",
    "                    time_tracker=TimeTracker(),\n",
    "                )\n",
    "\n",
    "                method_logger = MethodLogger(\n",
    "                    method_name=method_name,\n",
    "                    qualitative_metrics={\n",
    "                        \"Language\": \"Python\",\n",
    "                        \"Library\": \"TensorLy\",\n",
    "                        \"TensorLy backend\": f\"{backend}\",\n",
    "                        \"Tensor type\": \"Dense\",\n",
    "                        \"Data type\": data_type_name_with_index,\n",
    "                        \"Platform\": \"CPU, GPU\",\n",
    "                        \"Decomposition method\": \"Tucker\",\n",
    "                    },\n",
    "                    method_args={\n",
    "                        \"tensor\": tensor_param,\n",
    "                        \"rank\": rank_param,\n",
    "                        \"n_iter_max\": n_iter_max_param,\n",
    "                        \"init\": init_method,\n",
    "                        \"svd\": svd_func,\n",
    "                        \"random_state\": random_state_param,\n",
    "                    },\n",
    "                    runner=method_runner,\n",
    "                    is_test=False,\n",
    "                )\n",
    "\n",
    "                method_logger.run_experiments()\n",
    "\n",
    "            reconstructed_tensor = method_runner.reconstructed_tensor\n",
    "\n",
    "            reconstructed_frames = []\n",
    "\n",
    "            reconstructed_tensor = reconstructed_tensor.cpu().numpy() if backend == \"pytorch\" else reconstructed_tensor\n",
    "            reconstructed_frames = np.array([normalize_frames(frame) for frame in reconstructed_tensor])\n",
    "\n",
    "            save_params_combinations = {\n",
    "                \"image\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "                \"video\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                    \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "                    \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "                    if data_type_name == \"video\"\n",
    "                    else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "                },\n",
    "                \"eeg\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "            }\n",
    "            save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "            SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)\n",
    "\n",
    "        except (torch.cuda.OutOfMemoryError, MemoryError) as e:\n",
    "            error_message = f\"Пропущена итерация из-за ошибки: {backend}, {svd_func}, {init_method}. Ошибка: {e!s}\"\n",
    "            print(error_message)\n",
    "            torch.cuda.synchronize()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            method_logger.error_message = error_message\n",
    "\n",
    "            continue\n",
    "\n",
    "        finally:\n",
    "            method_logger.save_logs_to_file(is_test=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:   0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_image-0_pytorch_truncated_svd_svd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:293: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n",
      "\n",
      "Эксперимент набора параметров:  20%|██        | 1/5 [00:03<00:12,  3.13s/it]\u001B[A\n",
      "Эксперимент набора параметров:  40%|████      | 2/5 [00:08<00:13,  4.52s/it]\u001B[A\n",
      "Эксперимент набора параметров:  60%|██████    | 3/5 [00:13<00:09,  4.82s/it]\u001B[A\n",
      "Эксперимент набора параметров:  80%|████████  | 4/5 [00:18<00:04,  4.96s/it]\u001B[A\n",
      "Эксперимент набора параметров: 100%|██████████| 5/5 [00:24<00:00,  4.82s/it]\u001B[A\n",
      "Проверка набора параметров:   2%|▏         | 1/48 [00:24<18:55, 24.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение сохранено как /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/output/TensorLy_Tucker_image-0_pytorch_truncated_svd_svd.jpg\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_truncated_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Эксперимент набора параметров:  20%|██        | 1/5 [00:07<00:31,  7.75s/it]\u001B[A\n",
      "Эксперимент набора параметров:  40%|████      | 2/5 [00:12<00:18,  6.01s/it]\u001B[A\n",
      "Эксперимент набора параметров:  60%|██████    | 3/5 [00:20<00:13,  6.71s/it]\u001B[A\n",
      "Эксперимент набора параметров:  80%|████████  | 4/5 [00:27<00:06,  6.99s/it]\u001B[A\n",
      "Эксперимент набора параметров: 100%|██████████| 5/5 [00:35<00:00,  7.12s/it]\u001B[A\n",
      "Проверка набора параметров:   4%|▍         | 2/48 [00:59<23:41, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение сохранено как /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/output/TensorLy_Tucker_image-0_pytorch_truncated_svd_random.jpg\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_symeig_svd_svd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:04<?, ?it/s]\u001B[A\n",
      "Проверка набора параметров:   4%|▍         | 2/48 [01:04<24:48, 32.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/src/utils/method_loggers.py:30\u001B[0m, in \u001B[0;36mMethodLogger.run_experiments\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m gpu_torch_memory_manager():\n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunner\u001B[38;5;241m.\u001B[39mget_metrics(library_method_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlibrary_method_name)\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/src/utils/method_runners.py:50\u001B[0m, in \u001B[0;36mMethodRunner.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_tracker\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m---> 50\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpytorch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/decomposition/_tucker.py:329\u001B[0m, in \u001B[0;36mtucker\u001B[0;34m(tensor, rank, fixed_factors, n_iter_max, init, return_errors, svd, tol, random_state, mask, verbose)\u001B[0m\n\u001B[1;32m    327\u001B[0m rank \u001B[38;5;241m=\u001B[39m validate_tucker_rank(tl\u001B[38;5;241m.\u001B[39mshape(tensor), rank\u001B[38;5;241m=\u001B[39mrank)\n\u001B[0;32m--> 329\u001B[0m (core, factors), rec_errors \u001B[38;5;241m=\u001B[39m \u001B[43mpartial_tucker\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_iter_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_iter_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m tensor \u001B[38;5;241m=\u001B[39m TuckerTensor((core, factors))\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/decomposition/_tucker.py:173\u001B[0m, in \u001B[0;36mpartial_tucker\u001B[0;34m(tensor, rank, modes, n_iter_max, init, tol, svd, random_state, verbose, mask, svd_mask_repeats)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# SVD init\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m core, factors \u001B[38;5;241m=\u001B[39m \u001B[43minitialize_tucker\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvd_mask_repeats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvd_mask_repeats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m rec_errors \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/decomposition/_tucker.py:67\u001B[0m, in \u001B[0;36minitialize_tucker\u001B[0;34m(tensor, rank, modes, random_state, init, svd, non_negative, mask, svd_mask_repeats)\u001B[0m\n\u001B[1;32m     66\u001B[0m mask_unfold \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m unfold(mask, mode)\n\u001B[0;32m---> 67\u001B[0m U, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43msvd_interface\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43munfold\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_eigenvecs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrank\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnon_negative\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_negative\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask_unfold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_iter_mask_imputation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvd_mask_repeats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m factors\u001B[38;5;241m.\u001B[39mappend(U)\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/tenalg/svd.py:427\u001B[0m, in \u001B[0;36msvd_interface\u001B[0;34m(matrix, method, n_eigenvecs, flip_sign, u_based_flip_sign, non_negative, mask, n_iter_mask_imputation, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    424\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot svd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmethod\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. However, the possible choices are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSVD_FUNS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or to pass a callable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    425\u001B[0m     )\n\u001B[0;32m--> 427\u001B[0m U, S, V \u001B[38;5;241m=\u001B[39m \u001B[43msvd_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_eigenvecs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_eigenvecs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m n_eigenvecs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/tenalg/svd.py:270\u001B[0m, in \u001B[0;36msymeig_svd\u001B[0;34m(matrix, n_eigenvecs, **kwargs)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 270\u001B[0m     S, V \u001B[38;5;241m=\u001B[39m tl\u001B[38;5;241m.\u001B[39meigh(\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    271\u001B[0m     S \u001B[38;5;241m=\u001B[39m tl\u001B[38;5;241m.\u001B[39msqrt(tl\u001B[38;5;241m.\u001B[39mclip(S, tl\u001B[38;5;241m.\u001B[39meps(S\u001B[38;5;241m.\u001B[39mdtype)))\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/backend/__init__.py:202\u001B[0m, in \u001B[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"A dynamically dispatched method\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \n\u001B[1;32m    201\u001B[0m \u001B[38;5;124;03mReturns the queried method from the currently set backend\"\"\"\u001B[39;00m\n\u001B[0;32m--> 202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_THREAD_LOCAL_DATA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__dict__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbackend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorly/backend/pytorch_backend.py:143\u001B[0m, in \u001B[0;36mPyTorchBackend.dot\u001B[0;34m(a, b)\u001B[0m\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a \u001B[38;5;241m*\u001B[39m b\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 376.95 GiB (GPU 0; 11.00 GiB total capacity; 14.50 MiB already allocated; 197.57 MiB free; 42.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[93], line 71\u001B[0m\n\u001B[1;32m     38\u001B[0m     method_runner \u001B[38;5;241m=\u001B[39m MethodRunner(\n\u001B[1;32m     39\u001B[0m         func\u001B[38;5;241m=\u001B[39mtl\u001B[38;5;241m.\u001B[39mdecomposition\u001B[38;5;241m.\u001B[39mtucker,\n\u001B[1;32m     40\u001B[0m         method_input_tensor\u001B[38;5;241m=\u001B[39mtensor_param,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m         time_tracker\u001B[38;5;241m=\u001B[39mTimeTracker(),\n\u001B[1;32m     46\u001B[0m     )\n\u001B[1;32m     48\u001B[0m     method_logger \u001B[38;5;241m=\u001B[39m MethodLogger(\n\u001B[1;32m     49\u001B[0m         method_name\u001B[38;5;241m=\u001B[39mmethod_name,\n\u001B[1;32m     50\u001B[0m         qualitative_metrics\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     68\u001B[0m         is_test\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     69\u001B[0m     )\n\u001B[0;32m---> 71\u001B[0m     \u001B[43mmethod_logger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_experiments\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m reconstructed_tensor \u001B[38;5;241m=\u001B[39m method_runner\u001B[38;5;241m.\u001B[39mreconstructed_tensor\n\u001B[1;32m     75\u001B[0m reconstructed_frames \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/src/utils/method_loggers.py:29\u001B[0m, in \u001B[0;36mMethodLogger.run_experiments\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_experiments\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(MethodLogger\u001B[38;5;241m.\u001B[39mexperiments_count \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_test \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mЭксперимент набора параметров\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 29\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgpu_torch_memory_manager\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunner\u001B[38;5;241m.\u001B[39mget_metrics(library_method_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlibrary_method_name)\n",
      "File \u001B[0;32m~/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/contextlib.py:141\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[0;34m(self, typ, value, traceback)\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    139\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, typ, value, traceback):\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    143\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:21:55.159992600Z",
     "start_time": "2025-04-22T19:09:39.509263Z"
    }
   },
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"tensor_param\",\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"n_iter_max_param\",\n",
    "    \"svd_params\",\n",
    "    \"init_params\",\n",
    "    \"backend_params\",\n",
    "    \"random_state_param\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"backend\",\n",
    "    \"svd_func\",\n",
    "    \"init_method\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"reconstructed_tensor\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "    \"frame\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1932"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train - MPS (tensorly.decomposition.tensor_train)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.785320Z",
     "start_time": "2025-04-22T19:09:39.776482Z"
    }
   },
   "source": [
    "logs = LogReader.load_logs_from_file(log_file_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.836400600Z",
     "start_time": "2025-02-23T07:45:52.795727Z"
    }
   },
   "source": [
    "# input_tensors = {\n",
    "#     \"eeg-0\": eegs[\"eeg-0\"][\"frames\"].copy().astype(np.float32),\n",
    "#     # \"eeg-1\": eegs[\"eeg-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "# }\n",
    "# \n",
    "# tensor_rank_mapping = {\n",
    "#     \"image-0\": [1, 212, 212, 1],\n",
    "#     \"image-1\": [1, 170, 212, 1],\n",
    "#     \"image-2\": [1, 290, 300, 1],\n",
    "#     \"video-0\": [1, 300, 215, 300, 1],\n",
    "#     \"video-1\": [1, 500, 278, 500, 1],\n",
    "#     \"video-2\": [1, 500, 375, 500, 1],\n",
    "#     \"eeg-0\": [1, 1000, 1750, 2000, 1750, 1000, 1],  # (4, 12, 3, 29, 64, 321)\n",
    "#     # \"eeg-1\": [1, 1000, 1750, 2000, 1750, 1000, 1],  # (4, 12, 3, 29, 64, 321)\n",
    "# }\n",
    "\n",
    "input_tensors = input_tensor_train_tensors\n",
    "\n",
    "tensor_rank_mapping = tensor_tensor_train_rank_mapping\n",
    "\n",
    "svd_params = [\"randomized_svd\", \"truncated_svd\", \"symeig_svd\"]\n",
    "\n",
    "backend_params = [\"pytorch\"] # , \"numpy\"\n",
    "\n",
    "total_iterations = len(list(product(backend_params, svd_params))) * len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for data_type_name_with_index, input_tensor in input_tensors.items():\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "\n",
    "    for backend, svd_func in tqdm(\n",
    "            product(backend_params, svd_params),\n",
    "            desc=\"Проверка набора параметров\",\n",
    "            total=total_iterations,\n",
    "    ):\n",
    "        library_method_name = \"TensorLy_TensorTrain\"\n",
    "        method_name = f\"{library_method_name}_{data_type_name_with_index}_{backend}_{svd_func}\"\n",
    "\n",
    "        print(f\"Current method: {method_name}\")\n",
    "\n",
    "        if logs:\n",
    "            existing_log = next(\n",
    "                (\n",
    "                    log\n",
    "                    for log in logs\n",
    "                    if log[\"method_name\"] == method_name\n",
    "                       and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                       and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if existing_log:\n",
    "                print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with tl.backend_context(backend):\n",
    "                if backend == \"pytorch\":\n",
    "                    tensor_param = tl.tensor(input_tensor).to(torch_device)\n",
    "                elif backend == \"numpy\" or backend is None:\n",
    "                    tensor_param = tl.tensor(input_tensor)\n",
    "\n",
    "                method_runner = MethodRunner(\n",
    "                    func=tl.decomposition.tensor_train,\n",
    "                    method_input_tensor=tensor_param,\n",
    "                    library_method_name=library_method_name,\n",
    "                    backend_name=backend,\n",
    "                    gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                    ram_memory_tracker=RAMMemoryTracker(),\n",
    "                    time_tracker=TimeTracker(),\n",
    "                )\n",
    "\n",
    "                method_logger = MethodLogger(\n",
    "                    method_name=method_name,\n",
    "                    qualitative_metrics={\n",
    "                        \"Language\": \"Python\",\n",
    "                        \"Library\": \"TensorLy\",\n",
    "                        \"TensorLy backend\": f\"{backend}\",\n",
    "                        \"Tensor type\": \"Dense\",\n",
    "                        \"Data type\": data_type_name_with_index,\n",
    "                        \"Platform\": \"CPU, GPU\",\n",
    "                        \"Decomposition method\": \"TensorTrain\",\n",
    "                    },\n",
    "                    method_args={\n",
    "                        \"input_tensor\": tensor_param,\n",
    "                        \"rank\": rank_param,\n",
    "                        \"svd\": svd_func,\n",
    "                    },\n",
    "                    runner=method_runner,\n",
    "                    is_test=False,\n",
    "                )\n",
    "\n",
    "                method_logger.run_experiments()\n",
    "\n",
    "            reconstructed_tensor_from_tt_factors = method_runner.reconstructed_tensor\n",
    "\n",
    "            reconstructed_frames = []\n",
    "\n",
    "            for tt_factor in reconstructed_tensor_from_tt_factors:\n",
    "                if backend == \"pytorch\":\n",
    "                    reconstructed_frames.append(normalize_frames(tt_factor.cpu().numpy()))\n",
    "                else:\n",
    "                    reconstructed_frames.append(normalize_frames(tt_factor))\n",
    "            reconstructed_frames = np.array(reconstructed_frames)\n",
    "\n",
    "            save_params_combinations = {\n",
    "                \"image\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "                \"video\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                    \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "                    \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "                    if data_type_name == \"video\"\n",
    "                    else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "                },\n",
    "                \"eeg\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "            }\n",
    "            save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "            SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)\n",
    "\n",
    "            # break\n",
    "\n",
    "        except (torch.cuda.OutOfMemoryError, MemoryError) as e:\n",
    "            error_message = f\"Пропущена итерация из-за ошибки: {backend}, {svd_func}. Ошибка: {e!s}\"\n",
    "            print(error_message)\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            gc.collect()\n",
    "\n",
    "            method_logger.error_message = error_message\n",
    "\n",
    "            continue\n",
    "        finally:\n",
    "            method_logger.save_logs_to_file(is_test=False)\n",
    "    # break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.851901Z",
     "start_time": "2025-02-23T08:05:56.139105Z"
    }
   },
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"svd_params\",\n",
    "    \"backend_params\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"backend\",\n",
    "    \"svd_func\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"reconstructed_tensor_from_tt_factors\",\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "    \"tt_factor\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### CANDECOMP/PARAFAC (tensorly.decomposition.parafac)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852410300Z",
     "start_time": "2025-03-09T19:44:49.788060Z"
    }
   },
   "source": "logs = LogReader.load_logs_from_file(log_file_path)",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852410300Z",
     "start_time": "2025-03-09T19:46:32.275312Z"
    }
   },
   "source": [
    "input_tensors = {\n",
    "    \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    # \"video-0\": videos['video-0']['frames'].copy().astype(np.float32),\n",
    "    # \"video-1\": videos['video-1']['frames'].copy().astype(np.float32),\n",
    "    # \"video-2\": videos['video-2']['frames'].copy().astype(np.float32),\n",
    "}\n",
    "\n",
    "tensor_rank_mapping = {\n",
    "    \"image-0\": 422,\n",
    "    \"image-1\": 370,\n",
    "    \"image-2\": 655,\n",
    "    # \"video-0\": 3500,\n",
    "    # \"video-1\": 2036,\n",
    "    # \"video-2\": 3620,\n",
    "}\n",
    "\n",
    "# backend_params = [\"pytorch\", \"numpy\"]\n",
    "backend_params = [\"pytorch\"]\n",
    "\n",
    "svd_params = [\"truncated_svd\", \"symeig_svd\", \"randomized_svd\"]\n",
    "\n",
    "init_params = [\"random\", \"svd\"]\n",
    "\n",
    "normalize_factors_params = [False, True]\n",
    "# normalize_factors_params = [False]\n",
    "\n",
    "orthogonalise_params = [False, True]\n",
    "# orthogonalise_params = [False]\n",
    "\n",
    "linesearch_params = [False, True]\n",
    "\n",
    "cvg_criterion_params = [\"abs_rec_error\", \"rec_error\"]\n",
    "\n",
    "l2_reg_params = [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "# l2_reg_params = [0]\n",
    "\n",
    "tol_params = [1e-8, 1e-5, 1e-6, 1e-7, 1e-9]\n",
    "# tol_params = [1e-8]\n",
    "\n",
    "n_iter_max_param = 100\n",
    "\n",
    "random_state_param = 42\n",
    "\n",
    "total_iterations = len(\n",
    "    list(\n",
    "        product(\n",
    "            backend_params,\n",
    "            svd_params,\n",
    "            init_params,\n",
    "            normalize_factors_params,\n",
    "            orthogonalise_params,\n",
    "            linesearch_params,\n",
    "            cvg_criterion_params,\n",
    "            l2_reg_params,\n",
    "            tol_params,\n",
    "        )\n",
    "    )\n",
    ") * len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for data_type_name_with_index, input_tensor in input_tensors.items():\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "\n",
    "    for (\n",
    "            backend,\n",
    "            normalize_factors,\n",
    "            orthogonalise,\n",
    "            linesearch,\n",
    "            cvg_criterion,\n",
    "            l2_reg,\n",
    "            tol,\n",
    "            init_method,\n",
    "            svd_func,\n",
    "    ) in tqdm(\n",
    "        product(\n",
    "            backend_params,\n",
    "            normalize_factors_params,\n",
    "            orthogonalise_params,\n",
    "            linesearch_params,\n",
    "            cvg_criterion_params,\n",
    "            l2_reg_params,\n",
    "            tol_params,\n",
    "            init_params,\n",
    "            svd_params,\n",
    "        ),\n",
    "        desc=\"Проверка набора параметров\",\n",
    "        total=total_iterations,\n",
    "    ):\n",
    "        library_method_name = \"TensorLy_CP\"\n",
    "        method_name = f\"{library_method_name}_{data_type_name_with_index}_{backend}_{svd_func}_{init_method}_{normalize_factors}_{orthogonalise}_{cvg_criterion}_{l2_reg}_{tol}\"\n",
    "\n",
    "        print(f\"Current method: {method_name}\")\n",
    "\n",
    "        if logs:\n",
    "            existing_log = next(\n",
    "                (\n",
    "                    log\n",
    "                    for log in logs\n",
    "                    if log[\"method_name\"] == method_name\n",
    "                       and log[\"method_args\"].get(\"init\") == init_method\n",
    "                       and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                       and log[\"method_args\"].get(\"normalize_factors\") == normalize_factors\n",
    "                       and log[\"method_args\"].get(\"orthogonalise\") == orthogonalise\n",
    "                       and log[\"method_args\"].get(\"cvg_criterion\") == cvg_criterion\n",
    "                       and log[\"method_args\"].get(\"l2_reg\") == l2_reg\n",
    "                       and log[\"method_args\"].get(\"tol\") == tol\n",
    "                       and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "                       and log[\"method_args\"].get(\"linesearch\") == linesearch\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if existing_log:\n",
    "                print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with tl.backend_context(backend):\n",
    "                if backend == \"pytorch\":\n",
    "                    tensor_param = tl.tensor(input_tensor).to(torch_device)\n",
    "                elif backend == \"numpy\" or backend is None:\n",
    "                    tensor_param = tl.tensor(input_tensor)\n",
    "\n",
    "                method_runner = MethodRunner(\n",
    "                    func=tl.decomposition.parafac,\n",
    "                    method_input_tensor=tensor_param,\n",
    "                    library_method_name=library_method_name,\n",
    "                    backend_name=backend,\n",
    "                    gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                    ram_memory_tracker=RAMMemoryTracker(),\n",
    "                    time_tracker=TimeTracker(),\n",
    "                )\n",
    "\n",
    "                method_logger = MethodLogger(\n",
    "                    method_name=method_name,\n",
    "                    qualitative_metrics={\n",
    "                        \"Language\": \"Python\",\n",
    "                        \"Library\": \"TensorLy\",\n",
    "                        \"TensorLy backend\": f\"{backend}\",\n",
    "                        \"Tensor type\": \"Dense\",\n",
    "                        \"Data type\": data_type_name_with_index,\n",
    "                        \"Platform\": \"CPU, GPU\",\n",
    "                        \"Decomposition method\": \"CP\",\n",
    "                    },\n",
    "                    method_args={\n",
    "                        \"tensor\": tensor_param,\n",
    "                        \"rank\": rank_param,\n",
    "                        \"n_iter_max\": n_iter_max_param,\n",
    "                        \"init\": init_method,\n",
    "                        \"svd\": svd_func,\n",
    "                        \"normalize_factors\": normalize_factors,\n",
    "                        \"orthogonalise\": orthogonalise,\n",
    "                        \"tol\": tol,\n",
    "                        \"random_state\": random_state_param,\n",
    "                        \"l2_reg\": l2_reg,\n",
    "                        \"cvg_criterion\": cvg_criterion,\n",
    "                        \"linesearch\": linesearch,\n",
    "                    },\n",
    "                    runner=method_runner,\n",
    "                    is_test=False,\n",
    "                )\n",
    "\n",
    "                method_logger.run_experiments()\n",
    "\n",
    "            reconstructed_tensor = method_runner.reconstructed_tensor\n",
    "\n",
    "            reconstructed_frames = []\n",
    "\n",
    "            reconstructed_tensor = reconstructed_tensor.cpu().numpy() if backend == \"pytorch\" else reconstructed_tensor\n",
    "            reconstructed_frames = np.array([normalize_frames(frame) for frame in reconstructed_tensor])\n",
    "\n",
    "            save_params_combinations = {\n",
    "                \"image\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "                \"video\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                    \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "                    \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "                    if data_type_name == \"video\"\n",
    "                    else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "                },\n",
    "            }\n",
    "            save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "            SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)\n",
    "\n",
    "        except (\n",
    "                torch.cuda.OutOfMemoryError,\n",
    "                MemoryError,\n",
    "                np.linalg.LinAlgError,\n",
    "                torch._C._LinAlgError,\n",
    "        ) as e:\n",
    "            error_message = f\"Пропущена итерация из-за ошибки: {backend}, {svd_func}, {init_method}, {normalize_factors}, {orthogonalise}, {tol}, {l2_reg}, {cvg_criterion}. Ошибка: {e!s}\"\n",
    "            print(error_message)\n",
    "            torch.cuda.synchronize()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            method_logger.error_message = error_message\n",
    "\n",
    "            continue\n",
    "        finally:\n",
    "            method_metrics = method_logger.save_logs_to_file(is_test=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852923400Z",
     "start_time": "2025-03-10T09:35:47.203072Z"
    }
   },
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"tensor_param\",\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"n_iter_max_param\",\n",
    "    \"svd_params\",\n",
    "    \"init_params\",\n",
    "    \"backend_params\",\n",
    "    \"random_state_param\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"backend\",\n",
    "    \"svd_func\",\n",
    "    \"init_method\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"reconstructed_tensor\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "    \"frame\",\n",
    "    \"normalize_factors_params\",\n",
    "    \"orthogonalise_params\",\n",
    "    \"cvg_criterion_params\",\n",
    "    \"l2_reg_params\",\n",
    "    \"tol_params\",\n",
    "    \"normalize_factors\",\n",
    "    \"orthogonalise\",\n",
    "    \"cvg_criterion\",\n",
    "    \"tol\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## T3F"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:14:54.229665Z",
     "start_time": "2025-06-15T19:14:54.074262Z"
    }
   },
   "source": [
    "logs = LogReader.load_logs_from_file(log_file_path)"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:14:55.238225Z",
     "start_time": "2025-06-15T19:14:55.069838Z"
    }
   },
   "source": [
    "# input_tensors = {\n",
    "#     \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "# }\n",
    "# \n",
    "# tensor_rank_mapping = {\n",
    "#     \"image-0\": [1, 212, 212, 1],\n",
    "#     \"image-1\": [1, 170, 212, 1],\n",
    "#     \"image-2\": [1, 290, 300, 1],\n",
    "#     \"video-0\": [1, 300, 215, 300, 1],\n",
    "#     \"video-1\": [1, 500, 278, 500, 1],\n",
    "#     \"video-2\": [1, 500, 375, 500, 1],\n",
    "# }\n",
    "\n",
    "input_tensors = input_tensor_train_tensors\n",
    "\n",
    "tensor_rank_mapping = tensor_tensor_train_rank_mapping\n",
    "\n",
    "backend_param = \"tensorflow\"\n",
    "\n",
    "total_iterations = len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:15:31.755527Z",
     "start_time": "2025-06-15T19:14:55.590756Z"
    }
   },
   "source": [
    "for data_type_name_with_index, input_tensor in tqdm(\n",
    "        input_tensors.items(),\n",
    "        desc=\"Проверка набора параметров\",\n",
    "        total=total_iterations,\n",
    "):\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "    tensor_param = input_tensor\n",
    "\n",
    "    library_method_name = \"T3F_TensorTrain\"\n",
    "    method_name = f\"{library_method_name}_{data_type_name_with_index}\"\n",
    "\n",
    "    print(method_name)\n",
    "\n",
    "    if logs:\n",
    "        existing_log = next((log for log in logs if log[\"method_name\"] == method_name), None)\n",
    "        if existing_log:\n",
    "            print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "            continue\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    method_runner = MethodRunner(\n",
    "        func=t3f.to_tt_tensor,\n",
    "        method_input_tensor=tensor_param,\n",
    "        library_method_name=library_method_name,\n",
    "        backend_name=backend_param,\n",
    "        gpu_memory_tracker=GPUTensorflowMemoryTracker(tf_devices=tf_devices),\n",
    "        ram_memory_tracker=RAMMemoryTracker(),\n",
    "        time_tracker=TimeTracker(),\n",
    "    )\n",
    "\n",
    "    method_logger = MethodLogger(\n",
    "        method_name=method_name,\n",
    "        qualitative_metrics={\n",
    "            \"Language\": \"Python\",\n",
    "            \"Library\": \"T3F\",\n",
    "            \"T3F backend\": f\"{backend_param}\",\n",
    "            \"Tensor type\": \"Dense\",\n",
    "            \"Data type\": data_type_name_with_index,\n",
    "            \"Platform\": \"CPU, GPU\",\n",
    "            \"Decomposition method\": \"TensorTrain\",\n",
    "        },\n",
    "        method_args={\n",
    "            \"tens\": tensor_param,\n",
    "            \"max_tt_rank\": rank_param,\n",
    "        },\n",
    "        runner=method_runner,\n",
    "        is_test=False,\n",
    "    )\n",
    "\n",
    "    method_logger.run_experiments()\n",
    "\n",
    "    reconstructed_tensor_t3f = method_runner.reconstructed_tensor\n",
    "\n",
    "    method_logger.save_logs_to_file(is_test=False)\n",
    "\n",
    "    reconstructed_frames = []\n",
    "\n",
    "    for frame in reconstructed_tensor_t3f:\n",
    "        reconstructed_frames.append(normalize_frames(frame))\n",
    "    reconstructed_frames = np.array(reconstructed_frames)\n",
    "\n",
    "    save_params_combinations = {\n",
    "        \"image\": {\"name\": method_logger.name, \"frames\": reconstructed_frames},\n",
    "        \"video\": {\n",
    "            \"name\": method_logger.name,\n",
    "            \"frames\": reconstructed_frames,\n",
    "            \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "            \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "            if data_type_name == \"video\"\n",
    "            else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "    SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3F_TensorTrain_image-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[AI0000 00:00:1750014896.982830  265932 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1750014896.983058  265932 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1750014896.983142  265932 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1750014897.007972  265932 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1750014897.009182  265932 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-06-16 00:14:57.009247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1750014897.009510  265932 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-06-16 00:14:57.010949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9594 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-06-16 00:14:57.401637: I tensorflow/core/util/cuda_solvers.cc:178] Creating GpuSolver handles for stream 0x5570239f14b0\n",
      "\n",
      "Эксперимент набора параметров:  20%|██        | 1/5 [00:05<00:21,  5.34s/it]\u001B[A\n",
      "Эксперимент набора параметров:  40%|████      | 2/5 [00:09<00:13,  4.64s/it]\u001B[A\n",
      "Эксперимент набора параметров:  60%|██████    | 3/5 [00:12<00:08,  4.02s/it]\u001B[A\n",
      "Эксперимент набора параметров:  80%|████████  | 4/5 [00:15<00:03,  3.67s/it]\u001B[A\n",
      "Эксперимент набора параметров: 100%|██████████| 5/5 [00:18<00:00,  3.78s/it]\u001B[A\n",
      "Проверка набора параметров:  12%|█▎        | 1/8 [00:20<02:26, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение сохранено как /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/output/T3F_TensorTrain_image-0.jpg\n",
      "T3F_TensorTrain_image-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Эксперимент набора параметров:  20%|██        | 1/5 [00:02<00:09,  2.40s/it]\u001B[A\n",
      "Эксперимент набора параметров:  40%|████      | 2/5 [00:04<00:06,  2.32s/it]\u001B[A\n",
      "Эксперимент набора параметров:  60%|██████    | 3/5 [00:07<00:04,  2.38s/it]\u001B[A\n",
      "Эксперимент набора параметров:  80%|████████  | 4/5 [00:07<00:01,  1.75s/it]\u001B[A\n",
      "Эксперимент набора параметров: 100%|██████████| 5/5 [00:11<00:00,  2.31s/it]\u001B[A\n",
      "Проверка набора параметров:  25%|██▌       | 2/8 [00:33<01:36, 16.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение сохранено как /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/output/T3F_TensorTrain_image-1.jpg\n",
      "T3F_TensorTrain_image-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[AException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f0601b09a10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Process MemTimer-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Эксперимент набора параметров:   0%|          | 0/5 [00:01<?, ?it/s]  File \"/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/memory_profiler.py\", line 262, in run\n",
      "    stop = self.pipe.poll(self.interval)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Проверка набора параметров:  25%|██▌       | 2/8 [00:35<01:47, 17.87s/it]  File \"/root/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11.10-linux-x86_64-gnu/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 52\u001B[0m\n\u001B[1;32m     23\u001B[0m method_runner \u001B[38;5;241m=\u001B[39m MethodRunner(\n\u001B[1;32m     24\u001B[0m     func\u001B[38;5;241m=\u001B[39mt3f\u001B[38;5;241m.\u001B[39mto_tt_tensor,\n\u001B[1;32m     25\u001B[0m     method_input_tensor\u001B[38;5;241m=\u001B[39mtensor_param,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m     time_tracker\u001B[38;5;241m=\u001B[39mTimeTracker(),\n\u001B[1;32m     31\u001B[0m )\n\u001B[1;32m     33\u001B[0m method_logger \u001B[38;5;241m=\u001B[39m MethodLogger(\n\u001B[1;32m     34\u001B[0m     method_name\u001B[38;5;241m=\u001B[39mmethod_name,\n\u001B[1;32m     35\u001B[0m     qualitative_metrics\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m     is_test\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     50\u001B[0m )\n\u001B[0;32m---> 52\u001B[0m \u001B[43mmethod_logger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_experiments\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m reconstructed_tensor_t3f \u001B[38;5;241m=\u001B[39m method_runner\u001B[38;5;241m.\u001B[39mreconstructed_tensor\n\u001B[1;32m     56\u001B[0m method_logger\u001B[38;5;241m.\u001B[39msave_logs_to_file(is_test\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/src/utils/method_loggers.py:30\u001B[0m, in \u001B[0;36mMethodLogger.run_experiments\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(MethodLogger\u001B[38;5;241m.\u001B[39mexperiments_count \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_test \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mЭксперимент набора параметров\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m gpu_torch_memory_manager():\n\u001B[0;32m---> 30\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunner\u001B[38;5;241m.\u001B[39mget_metrics(library_method_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlibrary_method_name)\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m metric_name, metric_value \u001B[38;5;129;01min\u001B[39;00m metrics\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/src/utils/method_runners.py:59\u001B[0m, in \u001B[0;36mMethodRunner.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_tracker\u001B[38;5;241m.\u001B[39mstop()\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgpu_memory_tracker\u001B[38;5;241m.\u001B[39mstop()\n\u001B[0;32m---> 59\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mram_memory_tracker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_tracker\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreconstructed_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcalculate_reconstructed_tensor(library_method_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlibrary_method_name)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpytorch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/src/utils/trackers.py:94\u001B[0m, in \u001B[0;36mRAMMemoryTracker.run_tracker\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_tracker\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mram_allocated_memory \u001B[38;5;241m=\u001B[39m \u001B[43mmemory_usage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/memory_profiler.py:379\u001B[0m, in \u001B[0;36mmemory_usage\u001B[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001B[39;00m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 379\u001B[0m     returned \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m     parent_conn\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# finish timing\u001B[39;00m\n\u001B[1;32m    381\u001B[0m     ret \u001B[38;5;241m=\u001B[39m parent_conn\u001B[38;5;241m.\u001B[39mrecv()\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/t3f/decompositions.py:141\u001B[0m, in \u001B[0;36mto_tt_tensor\u001B[0;34m(tens, max_tt_rank, epsilon, name)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Converts a given tf.Tensor to a TT-tensor of the same shape.\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    of the input tensor, if epsilon is less than 0.\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mname_scope(name):\n\u001B[0;32m--> 141\u001B[0m   tens \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m   static_shape \u001B[38;5;241m=\u001B[39m tens\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mas_list()\n\u001B[1;32m    143\u001B[0m   dynamic_shape \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mshape(tens)\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1260\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1262\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1264\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001B[0m, in \u001B[0;36mconvert_to_tensor_v2_with_dispatch\u001B[0;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m\u001B[38;5;241m.\u001B[39mtf_export(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvert_to_tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m     97\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_to_tensor_v2_with_dispatch\u001B[39m(\n\u001B[1;32m     99\u001B[0m     value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype_hint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    100\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m tensor_lib\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m    101\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001B[39;00m\n\u001B[1;32m    102\u001B[0m \n\u001B[1;32m    103\u001B[0m \u001B[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconvert_to_tensor_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype_hint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_hint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001B[0m, in \u001B[0;36mconvert_to_tensor_v2\u001B[0;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor_conversion_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_hint\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001B[0m\n\u001B[1;32m    225\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    226\u001B[0m           _add_error_prefix(\n\u001B[1;32m    227\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConversion function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconversion_func\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    231\u001B[0m               name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 234\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[1;32m    237\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001B[0m, in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constant_op  \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top\u001B[39;00m\n\u001B[1;32m     28\u001B[0m _ \u001B[38;5;241m=\u001B[39m as_ref\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconstant_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001B[0m, in \u001B[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    141\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mis_auto_dtype_conversion_enabled():\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m   bound_arguments \u001B[38;5;241m=\u001B[39m signature\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    144\u001B[0m   bound_arguments\u001B[38;5;241m.\u001B[39mapply_defaults()\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001B[0m, in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconstant\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconstant\u001B[39m(\n\u001B[1;32m    179\u001B[0m     value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConst\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    180\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[ops\u001B[38;5;241m.\u001B[39mOperation, ops\u001B[38;5;241m.\u001B[39m_EagerTensorBase]:\n\u001B[1;32m    181\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001B[39;00m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 276\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mallow_broadcast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001B[0m, in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf.constant\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    288\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001B[0;32m--> 289\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_eager_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    291\u001B[0m const_tensor \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39m_create_graph_constant(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    292\u001B[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001B[1;32m    293\u001B[0m )\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m const_tensor\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:301\u001B[0m, in \u001B[0;36m_constant_eager_impl\u001B[0;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_constant_eager_impl\u001B[39m(\n\u001B[1;32m    298\u001B[0m     ctx, value, dtype, shape, verify_shape\n\u001B[1;32m    299\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ops\u001B[38;5;241m.\u001B[39m_EagerTensorBase:\n\u001B[1;32m    300\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 301\u001B[0m   t \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_eager_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\n",
      "File \u001B[0;32m/home/johndoe_19/git-projects/tensor-methods-comparison/.venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    106\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    107\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T19:15:32.717731900Z",
     "start_time": "2024-10-21T21:36:16.517666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"backend_param\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"tensor_param\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"reconstructed_tensor_t3f\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"frame\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TeNPy (not implemented)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853399200Z",
     "start_time": "2024-10-21T21:36:17.090065Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensor_param = video_frames.copy().astype(np.float32)\n",
    "#\n",
    "# # Размерность физического индекса\n",
    "# d = tensor_param.shape[-1]  # в вашем случае это 3\n",
    "#\n",
    "# # Создаем объект LegCharge\n",
    "# leg = LegCharge.from_trivial(d)\n",
    "#\n",
    "# # Создаем объекты Site для каждого физического индекса, кроме последнего\n",
    "# sites = [Site(leg) for _ in range(tensor_param.ndim - 1)]\n",
    "#\n",
    "# rank_param = [1, 500, 302, 500, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Implementation"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853900500Z",
     "start_time": "2024-10-21T21:36:17.151098Z"
    }
   },
   "outputs": [],
   "source": [
    "# mps = MPS.from_full(sites=sites, psi=tensor_param, normalize=False)\n",
    "#\n",
    "# reconstructed_tensor = mps.to_full_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853900500Z",
     "start_time": "2024-10-21T21:36:17.491557Z"
    }
   },
   "outputs": [],
   "source": [
    "# logs = load_logs_from_file(log_file_path)\n",
    "#\n",
    "# method_name = f\"TeNPy_TensorTrain\"\n",
    "#\n",
    "# if logs:\n",
    "#     existing_log = next(\n",
    "#         (log for log in logs if log['method_name'] == method_name),\n",
    "#         None\n",
    "#     )\n",
    "#     if existing_log:\n",
    "#         error_message = f\"Пропущена итерация: логи уже существуют для {method_name}\"\n",
    "#         raise error_message\n",
    "#\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.synchronize()\n",
    "#\n",
    "# method_logs = MethodLogger(\n",
    "#     method_name=method_name,\n",
    "#     method_input_tensor=tensor_param,\n",
    "#     qualitative_metrics={\n",
    "#         \"Language\": \"Python\",\n",
    "#         \"Library\": \"TeNPy\",\n",
    "#         \"Tensor type\": \"Dense\",\n",
    "#         \"Platform\": \"CPU\",\n",
    "#         \"Decomposition method\": \"TensorTrain\",\n",
    "#     },\n",
    "#     method_args={\n",
    "#         \"sites\": tensor_param,\n",
    "#         \"psi\": rank_param,\n",
    "#         \"normalize\": False,\n",
    "#     },\n",
    "#     func=tenpy.networks.mps.MPS.from_full\n",
    "# )\n",
    "#\n",
    "# method_logs_list.append(method_logs)\n",
    "#\n",
    "# tt_factors = method_logs.method_result\n",
    "#\n",
    "# reconstruct_frames_from_tenpy_tt_factors = tt_factors.to_full_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853900500Z",
     "start_time": "2024-10-21T21:36:17.650064Z"
    }
   },
   "outputs": [],
   "source": [
    "# method_logs.quantitative_metrics['compression_ratio'] = (100.0 * get_tensors_size(*tt_factors) / get_tensors_size(tensor_param))\n",
    "\n",
    "# method_logs.quantitative_metrics['frobenius_error'] = (\n",
    "#         100.0 * np.linalg.norm(reconstruct_frames_from_tenpy_tt_factors - tensor_param) / tl.norm(\n",
    "#         tensor_param))\n",
    "#\n",
    "# save_logs_to_file(method_logs=method_logs, is_test=True)\n",
    "#\n",
    "# reconstructed_frames = []\n",
    "#\n",
    "# for i in range(len(reconstruct_frames_from_tenpy_tt_factors)):\n",
    "#     reconstructed_frames.append(normalize_frame_tensorly_tensortrain(reconstruct_frames_from_tenpy_tt_factors[i]))\n",
    "#\n",
    "# save_frames_as_video(name=method_logs.name, frames=reconstructed_frames, fps=original_fps, frame_size=frame_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
