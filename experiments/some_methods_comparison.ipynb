{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:47.470703Z",
     "start_time": "2024-09-27T14:10:47.422917Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:48.802606Z",
     "start_time": "2024-09-27T14:10:47.538706Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import time\n",
    "import tracemalloc\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import cv2\n",
    "import json5\n",
    "import numpy as np\n",
    "import psutil\n",
    "import tensorly as tl\n",
    "import yt_dlp\n",
    "from dotenv import load_dotenv\n",
    "from scipy.linalg import svd\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext memory_profiler\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Some class and methods for logging of compression metrics of some methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:48.952929Z",
     "start_time": "2024-09-27T14:10:48.947285Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MethodLogs:\n",
    "    def __init__(self, method_name: str, method_args: dict[str, Any]):\n",
    "        self.name = method_name\n",
    "        self.method_args = method_args\n",
    "        self.qualitative_metrics = {}\n",
    "        self.quantitative_metrics = {}\n",
    "        self.logs = {}\n",
    "\n",
    "\n",
    "method_logs_list = []\n",
    "\n",
    "\n",
    "def memory(*args):\n",
    "    total = 0\n",
    "    for arg in args:\n",
    "        partial = 1\n",
    "        for d in arg.shape:\n",
    "            partial *= d\n",
    "        total += partial\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_current_rss_memory(*, is_mb: bool = False) -> float:\n",
    "    process = psutil.Process(os.getpid())\n",
    "    rss_memory = process.memory_info().rss\n",
    "\n",
    "    if is_mb:\n",
    "        return rss_memory / (1024 * 1024)\n",
    "    return rss_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Download video and extract frames from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some functions to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:48.983159Z",
     "start_time": "2024-09-27T14:10:48.972813Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_progress_hook(d):\n",
    "    if d[\"status\"] == \"downloading\":\n",
    "        print(f\"Downloading: {d['_percent_str']} at {d['_speed_str']} ETA: {d['_eta_str']}\")\n",
    "    elif d[\"status\"] == \"finished\":\n",
    "        print(\"Download complete!\")\n",
    "\n",
    "\n",
    "def extract_video_id(video_url):\n",
    "    video_id_match = re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\", video_url)\n",
    "    if video_id_match:\n",
    "        return video_id_match.group(1)\n",
    "    error_message = \"Не удалось извлечь ID видео из URL\"\n",
    "    raise ValueError(error_message)\n",
    "\n",
    "\n",
    "def download_youtube_video(video_url, cache_dir=None, proxy_url=None):\n",
    "    if cache_dir:\n",
    "        Path(cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "        video_id = extract_video_id(video_url)\n",
    "        cache_video_path = Path(cache_dir) / f\"{video_id}.mp4\"\n",
    "    else:\n",
    "        cache_video_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "\n",
    "    if Path(cache_video_path).exists():\n",
    "        print(f\"Видео уже загружено и закешировано: {cache_video_path}\")\n",
    "        return cache_video_path\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"format\": \"best\",\n",
    "        \"outtmpl\": cache_video_path,\n",
    "        \"progress_hooks\": [download_progress_hook],\n",
    "    }\n",
    "\n",
    "    if proxy_url:\n",
    "        ydl_opts[\"proxy\"] = proxy_url\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "    print(f\"Видео загружено и сохранено: {cache_video_path}\")\n",
    "    return cache_video_path\n",
    "\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def process_frames(frames):\n",
    "    processed_frames = []\n",
    "\n",
    "    for frame in frames:\n",
    "        b_channel, g_channel, r_channel = cv2.split(frame)\n",
    "\n",
    "        merged_frame = cv2.merge((b_channel, g_channel, r_channel))\n",
    "\n",
    "        processed_frames.append(merged_frame)\n",
    "\n",
    "    return np.array(processed_frames)\n",
    "\n",
    "\n",
    "def show_frames_as_video(frames):\n",
    "    for frame in frames:\n",
    "        cv2.imshow(\"Downloaded Video\", frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.060321Z",
     "start_time": "2024-09-27T14:10:49.056706Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=eSKe2Vx-rpY\"\n",
    "proxy_url = os.getenv(\"PROXY_URL\")\n",
    "cache_dir = \"../.cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check how functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.130605Z",
     "start_time": "2024-09-27T14:10:49.124397Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео уже загружено и закешировано: ..\\.cache\\eSKe2Vx-rpY.mp4\n"
     ]
    }
   ],
   "source": [
    "video_path = download_youtube_video(video_url, cache_dir=cache_dir, proxy_url=proxy_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.345620Z",
     "start_time": "2024-09-27T14:10:49.176104Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_frames = extract_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.480264Z",
     "start_time": "2024-09-27T14:10:49.357431Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_video_frames = process_frames(video_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check original video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.495732Z",
     "start_time": "2024-09-27T14:10:49.491267Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check_frames_as_video(processed_video_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Implementations of Decompositions methods"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some packages which can decompose some dense type of tensors, from [this](https://arxiv.org/pdf/2103.13756) paper\n",
    "\n",
    "\n",
    "Decomposition methods which used:\n",
    "1. Canonical Polyadic Decomposition as PARAllel FACtors analysis (aka PARAFAC aka CPD aka CP)\n",
    "2. Tucker Decomposition\n",
    "3. Tensor Train\n",
    "4. some variants of its (Other)\n",
    "\n",
    "Tensor types:\n",
    "1. Dense (D)\n",
    "2. Sparse (S)\n",
    "3. BlockSparse (BS)\n",
    "4. Symmetric\n",
    "5. Supersymmetric\n",
    "\n",
    "Target system:\n",
    "1. CPU (C)\n",
    "2. GPU(G)\n",
    "3. Distributed Memory (D)\n",
    "\n",
    "\n",
    "\n",
    "| Method name                                                                             | Decomposition methods implemented | Tensor Type | Platform | Language         | Git | PyPI | Want to check | Checked |\n",
    "|-----------------------------------------------------------------------------------------|-----------------------------------|------------|----------|------------------|------|------|--------------|---------|\n",
    "| some experiment with SVD from scipy                                                     | -                                 | -          | -        | Python           | +    |      | +            | +       |\n",
    "| [AdaTM](https://github.com/hpcgarage/AdaTM)                                             | CP                                | S          | C        | C                | +    | ?    |              |         |\n",
    "| [BTAS](https://github.com/ValeevGroup/BTAS)                                             | CP, Tucker                        | nan        | C        | C++              | +    | ?    |              |         |\n",
    "| [CP-CALS](https://github.com/HPAC/CP-CALS)                                              | CP, Other                         | D          | C, G     | C++, Mat         | +    |      | +            |         |\n",
    "| [CSTF](https://github.com/ZacBlanco/cstf)                                               | Other                             | S          | D        | Scala            | +    | ?    |              |         |\n",
    "| [D-Tucker](https://datalab.snu.ac.kr/dtucker/resources/DTucker-v1.0.tar.gz)             | Tucker, Other                     | D          | C        | Matlab           |      | ?    |              |         |\n",
    "| [DFacTo](http://www.joonheechoi.com/research.)                                          | CP                                | S          | C, D     | C++              |      | ?    |              |         |\n",
    "| [EXATN](https://github.com/ORNL-QCI/exatn)                                              | TensorTrain                       | D          | C, D, G  | C++, Py          | +    |      | +            |         |\n",
    "| [Genten](https://gitlab.com/tensors/genten)                                             | CP                                | D, S       | C, G     | C++              | +    |      | +            |         |\n",
    "| GigaTensor                                                                              | CP                                | D          | C        | C++, Python      |      | ?    |              |         |\n",
    "| [ITensor](https://github.com/ITensor/ITensor)                                           | TensorTrain                       | D, BS      | C, G     | C++, Julia       | +    |      | +            |         |\n",
    "| [multiway](https://cran.r-project.org/web/packages/multiway/index.html)                 | CP, Tucker, Other                 | D          | C        | R                |      | ?    |              |         |\n",
    "| [N-way toolbox](http://www.models.life.ku.dk/nwaytoolbox/download)                      | CP, Tucker, Other                 | D          | C        | Matlab           |      | ?    |              |         |\n",
    "| [ParCube](https://www.cs.ucr.edu/~epapalex/src/parCube.zip)                             | CP                                | S          | C        | Matlab           |      | ?    |              |         |\n",
    "| [ParTensor](https://github.com/neurocom/partensor-toolbox)                              | CP                                | D          | C, G     | C++              | +    |      | +            |         |\n",
    "| [ParTI!](https://github.com/hpcgarage/ParTI)                                            | CP, Tucker                        | S          | C, G     | C, CUDA, Mat     | +    | ?    |              |         |\n",
    "| [PLANC](https://github.com/ramkikannan/planc)                                           | CP                                | S          | C, D     | C++              | +    | ?    |              |         |\n",
    "| [PLS toolbox](https://eigenvector.com/software/pls-toolbox/)                            | CP          , Tucker              | D          | C        | Matlab           |      | ?    |              |         |\n",
    "| [Pytensor](https://code.google.com/archive/p/pytensor/source/default/source)            | Tucker                            | D, S       | C        | Python           |      | ?    |              |         |\n",
    "| [rTensor](https://github.com/jamesyili/rTensor)                                         | CP, Tucker, Other                 | D          | C        | R                | +    |      | +            |         |\n",
    "| [rTensor (randomized)](https://github.com/erichson/rTensor)                             | CP                                | D          | C        | Python           | +    |      | +       +    |         |\n",
    "| [scikit-tensor](https://github.com/mnick/scikit-tensor)                                 | CP, Tucker, Other                 | D, S       | C        | Python           | +    | +    | +    +   +   |         |\n",
    "| [Scikit-TT](https://github.com/PGelss/scikit_tt)                                        | TensorTrain                       | D          | C        | Python           | +    |      |     +   +    |         |\n",
    "| [SPALS](https://github.com/dehuacheng/SpAls)                                            | CP                                | S          | C        | C++              | +    | ?    |              |         |\n",
    "| [SPARTan](https://github.com/kperros/SPARTan)                                           | Other                             | S          | C        | Matlab           | +    | ?    |              |         |\n",
    "| [SPLATT](https://github.com/ShadenSmith/splatt)                                         | CP                                | S          | C, D     | C, C++, Oct, Mat | +    | ?    |              |         |\n",
    "| [SuSMoST](https://susmost.com/downloads.html)                                           | TensorTrain, Other                | D          | C        | Python           |      | ?    |              |         |\n",
    "| [T3F](https://github.com/Bihaqo/t3f)                                                    | TensorTrain                       | D          | C, G     | Python           | +    | +    | +    + +     |         |\n",
    "| [TDALAB](https://github.com/andrewssobral/TDALAB)                                       | CP                                | D, S       | C        | Python, Matlab   | +    |      | +         +  |         |\n",
    "| [TeNPy](https://github.com/tenpy/tenpy)                                        | TensorTrain                       | D          | C        | Python           | +    | +    | +      + +   |         |\n",
    "| [Tensor Fox](https://github.com/felipebottega/Tensor-Fox)                               | CP                                | D, S       | C        | Python, Matlab   | +    | +    | +    + +     |         |\n",
    "| [Tensor package](http://www.gipsa-lab.fr/~pierre.comon/TensorPackage/tensorPackage.html) | CP                                | D          | C        | Matlab           |      | ?    |              |         |\n",
    "| [Tensor Toolbox](https://gitlab.com/tensors/tensor_toolbox)                             | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |         |\n",
    "| [tensor_decomposition](https://github.com/cyclops-community/tensor_decomposition)       | CP, Tucker                        | D          | C, D     | Python           | +    |      | +        +   |         |\n",
    "| [TensorBox](https://github.com/phananhhuy/TensorBox)                                    | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |         |\n",
    "| [TensorD](https://github.com/Large-Scale-Tensor-Decomposition/tensorD)                  | CP, Tucker                        | D          | C, G     | Python           | ?    | ?    |              |         |\n",
    "| [TensorLab](https://www.tensorlab.net)                                                  | CP, Tucker, Other                 | D, S       | C        | Matlab           |      | ?    |              |         |\n",
    "| [TensorLab+](https://www.tensorlabplus.net)                                             | CP, Other                         | D, S       | C        | Matlab           |      | ?    |              |         |\n",
    "| [TensorLy](https://github.com/tensorly/tensorly)                                        | CP, Tucker, TensorTrain, Other    | D          | C, G     | Python           | +    | +    | +       + +  |         |\n",
    "| [Three-Way](https://github.com/cran/ThreeWay)                                           | CP, Tucker                        | D          | C        | R                | +    |      | +            |         |\n",
    "| [TNR](https://github.com/ycyuustc/matlab)                                               | Other                             | D          | C        | Matlab           | +    |      | +            |         |\n",
    "| [TT-Toolbox](https://github.com/oseledets/TT-Toolbox)                                   | TensorTrain                       | D          | C, D, G  | Matlab, Python   | +    |      | +       +    |         |\n",
    "| [xerus](https://git.hemio.de/xerus/xerus/)                                              | TensorTrain                       | D, S       | C        | C++              | +    |      | +            |         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use SVD to reconstruct the video\n",
    "\n",
    "just simple implementation with SVD by scipy lib as baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Some functions to do it"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.518354Z",
     "start_time": "2024-09-27T14:10:49.507586Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_and_reconstruct_svd(video_frames, svd_rank=None):\n",
    "    started_memory = get_current_rss_memory(is_mb=True)\n",
    "\n",
    "    reconstructed_frames = []\n",
    "    compression_ratios = []\n",
    "    frobenius_errors = []\n",
    "    decomposition_times = []\n",
    "    max_memory = 0.0\n",
    "\n",
    "    for frame in tqdm(video_frames, desc=\"Applying SVD and Reconstructing\", unit=\"frame\"):\n",
    "        channels = cv2.split(frame)\n",
    "        reconstructed_channels = []\n",
    "\n",
    "        for channel in channels:\n",
    "            durations = []\n",
    "\n",
    "            for _ in range(1):\n",
    "                start = time.time()\n",
    "                u, s, v_t = svd(channel, full_matrices=True)\n",
    "                duration = time.time() - start\n",
    "                durations.append(duration)\n",
    "            duration = np.mean(durations)\n",
    "\n",
    "            if svd_rank:\n",
    "                u = u[:, :svd_rank]\n",
    "                s = s[:svd_rank]\n",
    "                v_t = v_t[:svd_rank, :]\n",
    "\n",
    "            s_matrix = np.diag(s)\n",
    "            reconstructed_channel = np.dot(u, np.dot(s_matrix, v_t))\n",
    "            reconstructed_channels.append(reconstructed_channel)\n",
    "\n",
    "            original_memory = memory(channel)\n",
    "            compressed_memory = memory(u, s_matrix, v_t)\n",
    "            compression_ratio = 100.0 * compressed_memory / original_memory\n",
    "            frobenius_error = 100.0 * np.linalg.norm(channel - reconstructed_channel) / np.linalg.norm(channel)\n",
    "\n",
    "            compression_ratios.append(compression_ratio)\n",
    "            frobenius_errors.append(frobenius_error)\n",
    "            decomposition_times.append(duration)\n",
    "\n",
    "        reconstructed_frame = cv2.merge(reconstructed_channels)\n",
    "        reconstructed_frames.append(reconstructed_frame)\n",
    "\n",
    "        max_memory = max(max_memory, get_current_rss_memory(is_mb=True) - started_memory)\n",
    "\n",
    "    metrics = {\n",
    "        \"compression_ratio_sum\": np.sum(compression_ratios),\n",
    "        \"frobenius_error_sum\": np.sum(frobenius_errors),\n",
    "        \"compression_ratio_mean\": np.mean(compression_ratios),\n",
    "        \"frobenius_error_mean\": np.mean(frobenius_errors),\n",
    "        \"decomposition_time_sum_sec\": np.sum(decomposition_times),\n",
    "        \"decomposition_time_mean_sec\": np.mean(decomposition_times),\n",
    "        \"max_memory_MiB\": max_memory,\n",
    "    }\n",
    "\n",
    "    return np.array(reconstructed_frames, dtype=np.uint8), metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:10:49.536271Z",
     "start_time": "2024-09-27T14:10:49.531791Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd_rank = 30\n",
    "\n",
    "method_logs = MethodLogs(method_name=\"SVD\", method_args={\"svd_rank\": svd_rank})\n",
    "method_logs.qualitative_metrics = {\"deps to implement\": [\"python\", \"opencv-python\", \"numpy\"]}\n",
    "\n",
    "method_logs_list.append(method_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Check how functions work"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:38.200090Z",
     "start_time": "2024-09-27T14:10:49.553196Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SVD and Reconstructing: 100%|██████████| 440/440 [00:48<00:00,  9.07frame/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "reconstruct_frames_from_svd, metrics = apply_and_reconstruct_svd(video_frames, svd_rank=svd_rank)\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "tracemalloc.stop()\n",
    "tracemalloc.clear_traces()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:38.296379Z",
     "start_time": "2024-09-27T14:11:38.284587Z"
    }
   },
   "outputs": [],
   "source": [
    "method_logs.quantitative_metrics = metrics\n",
    "method_logs.logs[\"tracemalloc_snapshot\"] = snapshot.statistics(key_type=\"lineno\", cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Check reconstructed video"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:42.115769Z",
     "start_time": "2024-09-27T14:11:38.376337Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_frames_as_video(reconstruct_frames_from_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:42.145535Z",
     "start_time": "2024-09-27T14:11:42.136784Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name - SVD\n",
      "Args of method - {'svd_rank': 30}\n",
      "{\n",
      "    \"deps to implement\": [\n",
      "        \"python\",\n",
      "        \"opencv-python\",\n",
      "        \"numpy\",\n",
      "    ],\n",
      "}\n",
      "{\n",
      "    compression_ratio_sum: 32237.62376237623,\n",
      "    frobenius_error_sum: 6735.048292403831,\n",
      "    compression_ratio_mean: 24.422442244224417,\n",
      "    frobenius_error_mean: 5.102309312427145,\n",
      "    decomposition_time_sum_sec: 46.93275809288025,\n",
      "    decomposition_time_mean_sec: 0.03555511976733352,\n",
      "    max_memory_MiB: 374.2578125,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Name - {method_logs_list[0].name}\",\n",
    "    f\"Args of method - {method_logs_list[0].method_args}\",\n",
    "    json5.dumps(method_logs_list[0].qualitative_metrics, indent=4, ensure_ascii=False),\n",
    "    json5.dumps(method_logs_list[0].quantitative_metrics, indent=4, ensure_ascii=False),\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:42.238221Z",
     "start_time": "2024-09-27T14:11:42.233305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\89123\\AppData\\Local\\Temp\\ipykernel_14868\\2159502159.py:57: size=91.5 MiB, count=3, average=30.5 MiB\n"
     ]
    }
   ],
   "source": [
    "print(method_logs_list[0].logs[\"tracemalloc_snapshot\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TensorLy"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:42.298414Z",
     "start_time": "2024-09-27T14:11:42.291533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 360, 202, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:11:42.366828Z",
     "start_time": "2024-09-27T14:11:42.362583Z"
    }
   },
   "outputs": [],
   "source": [
    "rank = (30, 100, 100, 3)\n",
    "\n",
    "method_logs = MethodLogs(method_name=\"TensorLy_tucker\", method_args={\"rank\": rank})\n",
    "method_logs.qualitative_metrics = {\"deps to implement\": [\"python\"]}\n",
    "\n",
    "method_logs_list.append(method_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:13:33.615152Z",
     "start_time": "2024-09-27T14:11:42.399365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_tl_tucker(rank):\n",
    "    start = time.time()\n",
    "    core, factors = tl.decomposition.tucker(video_frames, rank=rank)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    return core, factors, duration\n",
    "\n",
    "\n",
    "tracemalloc.start()\n",
    "core, factors, duration = check_tl_tucker(rank)\n",
    "tracemalloc.take_snapshot()\n",
    "tracemalloc.stop()\n",
    "tracemalloc.clear_traces()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:13:35.847895Z",
     "start_time": "2024-09-27T14:13:33.637747Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruct_frames_from_tensorly_tucker = tl.tucker_tensor.tucker_to_tensor((core, factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:13:36.583125Z",
     "start_time": "2024-09-27T14:13:35.874639Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"compression_ratio\": 100.0 * memory(core, *factors) / memory(video_frames),\n",
    "    \"frobenius_error\": 100.0 * np.linalg.norm(reconstruct_frames_from_tensorly_tucker - video_frames) / np.linalg.norm(video_frames),\n",
    "    \"decomposition_time_sec\": duration,\n",
    "    # \"max_memory_MiB\": max_memory,\n",
    "}\n",
    "\n",
    "method_logs.quantitative_metrics = metrics\n",
    "method_logs.logs[\"tracemalloc_snapshot\"] = snapshot.statistics(key_type=\"lineno\", cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:13:36.612490Z",
     "start_time": "2024-09-27T14:13:36.606928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name - TensorLy_tucker\n",
      "Args of method - {'rank': (30, 100, 100, 3)}\n",
      "{\n",
      "    \"deps to implement\": [\n",
      "        \"python\",\n",
      "    ],\n",
      "}\n",
      "{\n",
      "    compression_ratio: 1.0099020318698537,\n",
      "    frobenius_error: 7.250425299679551,\n",
      "    decomposition_time_sec: 111.17421627044678,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Name - {method_logs_list[1].name}\",\n",
    "    f\"Args of method - {method_logs_list[1].method_args}\",\n",
    "    json5.dumps(method_logs_list[1].qualitative_metrics, indent=4, ensure_ascii=False),\n",
    "    json5.dumps(method_logs_list[1].quantitative_metrics, indent=4, ensure_ascii=False),\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:13:37.589317Z",
     "start_time": "2024-09-27T14:13:36.697099Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstructed_frames = (reconstruct_frames_from_tensorly_tucker - np.min(reconstruct_frames_from_tensorly_tucker)) / (\n",
    "    np.max(reconstruct_frames_from_tensorly_tucker) - np.min(reconstruct_frames_from_tensorly_tucker)\n",
    ")\n",
    "\n",
    "reconstructed_frames *= 255\n",
    "reconstructed_frames = reconstructed_frames.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:16:53.622912Z",
     "start_time": "2024-09-27T14:16:39.705958Z"
    }
   },
   "outputs": [],
   "source": [
    "show_frames_as_video(reconstructed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:13:40.450255Z",
     "start_time": "2024-09-27T14:13:40.447492Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
