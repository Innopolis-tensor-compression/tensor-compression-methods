{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "бенчмарк методов декомпозиции"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:06.216897Z",
     "start_time": "2025-04-22T19:06:55.071341Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "from src.utils.eeg_controller import get_eegbci_dataset\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"src.utils.method_loggers\",\n",
    "    \"src.utils.method_runners\",\n",
    "    \"src.utils.metrics_calculators\",\n",
    "    \"src.utils.tensor_handlers\",\n",
    "    \"src.utils.trackers\",\n",
    "    \"src.utils.video_controller\",\n",
    "    \"src.utils.optimal_rank_finders\",\n",
    "    \"src.utils.benchmark.calculate_optimized_rank_tucker\",\n",
    "    \"src.utils.benchmark.calculate_optimized_rank_tensor_train\",\n",
    "]\n",
    "\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import contextlib\n",
    "import gc\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "\n",
    "np.random.seed(42)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import t3f\n",
    "import tensorly as tl\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.eeg_controller import create_eeg_limo_data_tensor\n",
    "from src.utils.image_controller import download_image, extract_image_frames\n",
    "from src.utils.method_loggers import MethodLogger\n",
    "from src.utils.method_runners import MethodRunner\n",
    "from src.utils.optimal_rank_finders import (\n",
    "    find_optimal_rank_tensor_train_by_compression_ratio,\n",
    "    find_optimal_rank_tucker_by_compression_ratio,\n",
    ")\n",
    "from src.utils.read_logs import LogReader\n",
    "from src.utils.save_frames import SaveFramesFactory\n",
    "from src.utils.tensor_handlers import normalize_frames\n",
    "from src.utils.trackers import (\n",
    "    GPUTensorflowMemoryTracker,\n",
    "    GPUTorchMemoryTracker,\n",
    "    RAMMemoryTracker,\n",
    "    TimeTracker,\n",
    ")\n",
    "from src.utils.video_controller import download_youtube_video, extract_frames\n",
    "from src.utils.benchmark.calculate_optimized_rank_tucker import global_optimize_tucker_rank\n",
    "from src.utils.benchmark.calculate_optimized_rank_tensor_train import global_optimize_tensor_train_rank\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 00:06:56.970842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 00:06:57.119765: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 00:06:57.169705: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 00:06:57.442563: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-23 00:06:59.186431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:06.340129Z",
     "start_time": "2025-04-22T19:07:06.294030Z"
    }
   },
   "source": [
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:06.410200Z",
     "start_time": "2025-04-22T19:07:06.370176Z"
    }
   },
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:07.337235Z",
     "start_time": "2025-04-22T19:07:06.915946Z"
    }
   },
   "source": [
    "tf_physical_device = tf.config.list_physical_devices(\"GPU\")[0].name\n",
    "tf_device = \":\".join(tf_physical_device.split(\":\")[1:3])\n",
    "tf_devices = [tf_device]\n",
    "tf_physical_device"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745348826.970112   24273 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1745348827.330886   24273 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1745348827.330943   24273 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Get tensors"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some params"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:07.458003Z",
     "start_time": "2025-04-22T19:07:07.420662Z"
    }
   },
   "source": [
    "proxy_url = os.getenv(\"PROXY_URL\")\n",
    "log_file_path = \"../.cache/method_logs.json\"\n",
    "method_logs_list = []"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "## Get some tensors from different data types"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Video"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:07.525634Z",
     "start_time": "2025-04-22T19:07:07.486493Z"
    }
   },
   "source": [
    "cache_dir_video = \"../.cache/video\"\n",
    "\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=eSKe2Vx-rpY\",\n",
    "    \"https://www.youtube.com/watch?v=zk1mAd77Hr4\",\n",
    "    \"https://www.youtube.com/watch?v=vSLHsTh421w\",\n",
    "]\n",
    "\n",
    "videos = {}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:07.600627Z",
     "start_time": "2025-04-22T19:07:07.557434Z"
    }
   },
   "source": [
    "video_paths = [\n",
    "    download_youtube_video(\n",
    "        video_url=video_url,\n",
    "        cache_dir=cache_dir_video.__str__(),\n",
    "        proxy_url=proxy_url,\n",
    "    )\n",
    "    for video_url in video_urls\n",
    "]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео уже загружено и закешировано: ../.cache/video/eSKe2Vx-rpY.mp4\n",
      "Видео уже загружено и закешировано: ../.cache/video/zk1mAd77Hr4.mp4\n",
      "Видео уже загружено и закешировано: ../.cache/video/vSLHsTh421w.mp4\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:07.953917Z",
     "start_time": "2025-04-22T19:07:07.696181Z"
    }
   },
   "source": [
    "for video_index, video_path in enumerate(video_paths):\n",
    "    video_frames, original_fps, frame_size = extract_frames(video_path)\n",
    "\n",
    "    videos[f\"video-{video_index}\"] = {\n",
    "        \"video_url\": video_urls[video_index],\n",
    "        \"video_path\": video_path,\n",
    "        \"original_fps\": original_fps,\n",
    "        \"frame_size\": frame_size,\n",
    "        \"frames\": video_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"video-{video_index} - {video_frames.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-0 - (220, 256, 144, 3)\n",
      "video-1 - (100, 144, 192, 3)\n",
      "video-2 - (237, 144, 256, 3)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Image"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:08.116614Z",
     "start_time": "2025-04-22T19:07:08.066751Z"
    }
   },
   "source": [
    "cache_dir_image = \"../.cache/image\"\n",
    "\n",
    "image_urls = [\n",
    "    \"https://i.pinimg.com/564x/04/b2/68/04b26838bdd5e2ba54d0144558685bae.jpg\",\n",
    "    \"https://cdnstatic.rg.ru/crop620x412/uploads/images/187/94/47/iStock-644032024.jpg\",\n",
    "    \"https://i.sstatic.net/uQggz.png\",\n",
    "]\n",
    "\n",
    "images = {}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:08.244186Z",
     "start_time": "2025-04-22T19:07:08.196948Z"
    }
   },
   "source": [
    "image_paths = [download_image(image_url, cache_dir_image) for image_url in image_urls]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение уже загружено и закешировано: ../.cache/image/04b26838bdd5e2ba54d0144558685bae.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/iStock-644032024.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/uQggz.png\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:08.376136Z",
     "start_time": "2025-04-22T19:07:08.297629Z"
    }
   },
   "source": [
    "for image_index, image_path in enumerate(image_paths):\n",
    "    image_frames = extract_image_frames(image_path)\n",
    "\n",
    "    images[f\"image-{image_index}\"] = {\n",
    "        \"image_url\": image_urls[image_index],\n",
    "        \"image_path\": image_path,\n",
    "        \"frames\": image_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"image-{image_index} - {image_frames.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 - (564, 564, 3)\n",
      "image-1 - (412, 620, 3)\n",
      "image-2 - (689, 1195, 3)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:08.466960Z",
     "start_time": "2025-04-22T19:07:08.424553Z"
    }
   },
   "source": [
    "# from src.utils.save_frames import SaveFramesAsImage\n",
    "#\n",
    "# SaveFramesAsImage.save_frames('test', images['image-2']['frames'])"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### EEG"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:27.032490Z",
     "start_time": "2025-04-22T19:07:08.495058Z"
    }
   },
   "source": [
    "cache_dir_eeg = \"../.cache/eeg\"\n",
    "\n",
    "eegs = {\n",
    "    \"eeg-0\": {\"frames\": get_eegbci_dataset(cache_dir_eeg=cache_dir_eeg)},\n",
    "    \"eeg-1\": {\"frames\": create_eeg_limo_data_tensor(cache_dir_eeg=cache_dir_eeg)},\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/johndoe_19/git-projects/tensor-methods-comparison/.cache/eeg/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 1, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 2, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 3, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 3: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 4: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 5: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 6: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 7: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 8: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 9: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 10: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 11: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 12: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 13: 15 epochs for ['T1', 'T2']\n",
      "\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1281 original time points ...\n",
      "0 bad epochs dropped\n",
      "Subject 4, Run 14: 15 epochs for ['T1', 'T2']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:27.165633Z",
     "start_time": "2025-04-22T19:07:27.116697Z"
    }
   },
   "source": [
    "for index, eeg in eegs.items():\n",
    "    print(f\"{index} - {eeg['frames'].shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg-0 - (4, 12, 2, 15, 64, 1281)\n",
      "eeg-1 - (3, 1050, 2, 132, 201)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Find optimal ranks"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Params"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:27.241049Z",
     "start_time": "2025-04-22T19:07:27.194391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio = 50.0\n",
    "frobenius_error_coef = 1.0\n",
    "compression_ratio_coef = 10.0"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tucker"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:27.335841Z",
     "start_time": "2025-04-22T19:07:27.271405Z"
    }
   },
   "source": [
    "tucker_args = {\n",
    "    \"svd\": \"truncated_svd\",\n",
    "    \"init\": \"svd\",  # random, svd\n",
    "    \"random_state\": 42,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:28.221311Z",
     "start_time": "2025-04-22T19:07:27.406270Z"
    }
   },
   "source": [
    "input_tucker_tensors = {\n",
    "    \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-0\": eegs[\"eeg-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-1\": eegs[\"eeg-1\"][\"frames\"].copy().astype(np.float32),\n",
    "}\n",
    "\n",
    "tensor_tucker_rank_mapping = {\n",
    "    \"image-0\": [252, 255, 3],\n",
    "    \"image-1\": [220, 231, 3],\n",
    "    \"image-2\": [212, 595, 3],\n",
    "    \"video-0\": [176, 205, 112, 3],\n",
    "    \"video-1\": [51, 144, 186, 3],\n",
    "    \"video-2\": [222, 110, 178, 3],\n",
    "    \"eeg-0\": [4, 12, 2, 8, 63, 1221],\n",
    "    \"eeg-1\": [3, 1050, 2, 131, 100],\n",
    "    \n",
    "    # old with custom local optimization algorithm\n",
    "    # \"image-0\": [252, 254, 3],\n",
    "    # \"image-1\": [216, 232, 3],\n",
    "    # \"image-2\": [261, 534, 3],\n",
    "    # \"video-0\": [173, 194, 120, 3],\n",
    "    # \"video-1\": [58, 143, 165, 3],\n",
    "    # \"video-2\": [219, 115, 172, 3],\n",
    "    # \"eeg-0\": [4, 12, 2, 8, 64, 1171],\n",
    "    # \"eeg-1\": [3, 1046, 1, 132, 199],\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:29.856152Z",
     "start_time": "2025-04-22T19:07:28.257251Z"
    }
   },
   "source": [
    "for tensor_name, tensor_data in input_tucker_tensors.items():\n",
    "    with tl.backend_context(\"pytorch\"):\n",
    "        try:\n",
    "            if tensor_name not in tensor_tucker_rank_mapping:\n",
    "                print(f\"Processing tensor: {tensor_name}\")\n",
    "                method = \"differential_evolution\"\n",
    "\n",
    "                try:\n",
    "                    reconstructed_tensor, weight, factors, optimal_rank, final_loss_value, optimize_result, iteration_logs = (\n",
    "                        global_optimize_tucker_rank(\n",
    "                            optimization_method=method,\n",
    "                            tensor=tensor_data,\n",
    "                            target_compression_ratio=target_compression_ratio,\n",
    "                            frobenius_error_coef=frobenius_error_coef,\n",
    "                            compression_ratio_coef=compression_ratio_coef,\n",
    "                            verbose=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    tensor_tucker_rank_mapping[tensor_name] = optimal_rank\n",
    "\n",
    "                    frobenius_error = iteration_logs[-1]['metrics']['frobenius_error'] * 100\n",
    "                    compression_ratio = iteration_logs[-1]['metrics']['compression_ratio'] * 100\n",
    "\n",
    "                    print(\n",
    "                        f\"Tensor {tensor_name}: Best Rank = {optimal_rank}. Last iter results: Frobenius Error = {frobenius_error:.4f}%, Compression Ratio = {compression_ratio:.4f}%\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with method {method}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping tensor: {tensor_name} cause rank is exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tensor {tensor_name}: {e}\")\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tensor: image-0 cause rank is exist\n",
      "Skipping tensor: image-1 cause rank is exist\n",
      "Skipping tensor: image-2 cause rank is exist\n",
      "Skipping tensor: video-0 cause rank is exist\n",
      "Skipping tensor: video-1 cause rank is exist\n",
      "Skipping tensor: video-2 cause rank is exist\n",
      "Skipping tensor: eeg-0 cause rank is exist\n",
      "Skipping tensor: eeg-1 cause rank is exist\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:29.933225Z",
     "start_time": "2025-04-22T19:07:29.882579Z"
    }
   },
   "source": [
    "for tensor_name, tensor in input_tucker_tensors.items():\n",
    "    print(tensor_name, tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 (564, 564, 3)\n",
      "image-1 (412, 620, 3)\n",
      "image-2 (689, 1195, 3)\n",
      "video-0 (220, 256, 144, 3)\n",
      "video-1 (100, 144, 192, 3)\n",
      "video-2 (237, 144, 256, 3)\n",
      "eeg-0 (4, 12, 2, 15, 64, 1281)\n",
      "eeg-1 (3, 1050, 2, 132, 201)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:30.019879Z",
     "start_time": "2025-04-22T19:07:29.976536Z"
    }
   },
   "source": [
    "for tensor_name, rank in tensor_tucker_rank_mapping.items():\n",
    "    print(tensor_name, rank)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 [252, 255, 3]\n",
      "image-1 [220, 231, 3]\n",
      "image-2 [212, 595, 3]\n",
      "video-0 [176, 205, 112, 3]\n",
      "video-1 [51, 144, 186, 3]\n",
      "video-2 [222, 110, 178, 3]\n",
      "eeg-0 [4, 12, 2, 8, 63, 1221]\n",
      "eeg-1 [3, 1050, 2, 131, 100]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:30.139779Z",
     "start_time": "2025-04-22T19:07:30.095346Z"
    }
   },
   "source": [
    "tensor_train_args = {\"svd\": \"truncated_svd\"}"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:30.947464Z",
     "start_time": "2025-04-22T19:07:30.148210Z"
    }
   },
   "source": [
    "input_tensor_train_tensors = {\n",
    "    \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-0\": eegs[\"eeg-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"eeg-1\": eegs[\"eeg-1\"][\"frames\"].copy().astype(np.float32),\n",
    "}\n",
    "\n",
    "tensor_tensor_train_rank_mapping = {\n",
    "    \"image-0\": [1, 212, 3, 1],\n",
    "    \"image-1\": [1, 233, 2, 1],\n",
    "    \"image-2\": [1, 289, 3, 1],\n",
    "    \"video-0\": [1, 213, 222, 3, 1],\n",
    "    \"video-1\": [1, 83, 331, 3, 1],\n",
    "    \"video-2\": [1, 237, 374, 3, 1],\n",
    "    \"eeg-0\": [1, 4, 48, 96, 720, 1280, 1],\n",
    "    \"eeg-1\": [1, 3, 3150, 3152, 129, 1],\n",
    "    \n",
    "    # old\n",
    "    # \"image-0\": [1, 212, 3, 1],\n",
    "    # \"image-1\": [1, 169, 3, 1],\n",
    "    # \"image-2\": [1, 289, 3, 1],\n",
    "    # \"video-0\": [1, 220, 215, 1, 1],\n",
    "    # \"video-1\": [1, 100, 277, 3, 1],\n",
    "    # \"video-2\": [1, 237, 374, 3, 1],\n",
    "    # \"eeg-0\": [1, 4, 48, 2, 30, 1282, 1],\n",
    "}\n",
    "\n",
    "# eeg-1 - (3, 1050, 2, 132, 201)\n",
    "# 11h eeg-1 1795 | [1, 3, 1532, 217, 47, 1] | 4.095930 % | 44.831035 %"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:32.773041Z",
     "start_time": "2025-04-22T19:07:30.981249Z"
    }
   },
   "source": [
    "for tensor_name, tensor_data in input_tensor_train_tensors.items():\n",
    "    with tl.backend_context(\"pytorch\"):\n",
    "        try:\n",
    "            if tensor_name not in tensor_tensor_train_rank_mapping:\n",
    "                print(f\"Processing tensor: {tensor_name}\")\n",
    "                method = \"differential_evolution\"\n",
    "\n",
    "                try:\n",
    "                    reconstructed_tensor, tt_factors, optimal_rank, final_loss_value, optimize_result, iteration_logs = (\n",
    "                        global_optimize_tensor_train_rank(\n",
    "                            optimization_method=method,\n",
    "                            tensor=tensor_data,\n",
    "                            target_compression_ratio=target_compression_ratio,\n",
    "                            frobenius_error_coef=frobenius_error_coef,\n",
    "                            compression_ratio_coef=compression_ratio_coef,\n",
    "                            verbose=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    tensor_tensor_train_rank_mapping[tensor_name] = optimal_rank\n",
    "\n",
    "                    frobenius_error = iteration_logs[-1]['metrics']['frobenius_error'] * 100\n",
    "                    compression_ratio = iteration_logs[-1]['metrics']['compression_ratio'] * 100\n",
    "\n",
    "                    print(\n",
    "                        f\"Tensor {tensor_name}: Best Rank = {optimal_rank}. Last iter results: Frobenius Error = {frobenius_error:.4f}%, Compression Ratio = {compression_ratio:.4f}%\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with method {method}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping tensor: {tensor_name} cause rank is exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tensor {tensor_name}: {e}\")\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tensor: image-0 cause rank is exist\n",
      "Skipping tensor: image-1 cause rank is exist\n",
      "Skipping tensor: image-2 cause rank is exist\n",
      "Skipping tensor: video-0 cause rank is exist\n",
      "Skipping tensor: video-1 cause rank is exist\n",
      "Skipping tensor: video-2 cause rank is exist\n",
      "Skipping tensor: eeg-0 cause rank is exist\n",
      "Skipping tensor: eeg-1 cause rank is exist\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:32.858396Z",
     "start_time": "2025-04-22T19:07:32.808130Z"
    }
   },
   "source": [
    "for tensor_name, tensor in input_tensor_train_tensors.items():\n",
    "    print(tensor_name, tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 (564, 564, 3)\n",
      "image-1 (412, 620, 3)\n",
      "image-2 (689, 1195, 3)\n",
      "video-0 (220, 256, 144, 3)\n",
      "video-1 (100, 144, 192, 3)\n",
      "video-2 (237, 144, 256, 3)\n",
      "eeg-0 (4, 12, 2, 15, 64, 1281)\n",
      "eeg-1 (3, 1050, 2, 132, 201)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:33.014082Z",
     "start_time": "2025-04-22T19:07:32.961081Z"
    }
   },
   "source": [
    "for tensor_name, rank in tensor_tensor_train_rank_mapping.items():\n",
    "    print(tensor_name, rank)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 [1, 212, 3, 1]\n",
      "image-1 [1, 233, 2, 1]\n",
      "image-2 [1, 289, 3, 1]\n",
      "video-0 [1, 213, 222, 3, 1]\n",
      "video-1 [1, 83, 331, 3, 1]\n",
      "video-2 [1, 237, 374, 3, 1]\n",
      "eeg-0 [1, 4, 48, 96, 720, 1280, 1]\n",
      "eeg-1 [1, 3, 3150, 3152, 129, 1]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Theoretical comparison of some libraries and implementations"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some packages which can decompose some dense type of tensors, from [this](https://arxiv.org/pdf/2103.13756) paper\n",
    "\n",
    "\n",
    "Decomposition methods which used:\n",
    "1. Canonical Polyadic Decomposition as PARAllel FACtors analysis (aka PARAFAC aka CPD aka CP)\n",
    "2. Tucker Decomposition\n",
    "3. Tensor Train\n",
    "4. some variants of its (Other)\n",
    "\n",
    "Tensor types:\n",
    "1. Dense (D)\n",
    "2. Sparse (S)\n",
    "3. BlockSparse (BS)\n",
    "4. Symmetric\n",
    "5. Supersymmetric\n",
    "\n",
    "Target system:\n",
    "1. CPU (C)\n",
    "2. GPU(G)\n",
    "3. Distributed Memory (D)\n",
    "\n",
    "\n",
    "\n",
    "| Method name                                                                             | Decomposition methods implemented | Tensor Type | Platform | Language         | Git | PyPI | Want to check | Checked     |\n",
    "|-----------------------------------------------------------------------------------------|-----------------------------------|------------|----------|------------------|------|------|--------------|-------------|\n",
    "| [AdaTM](https://github.com/hpcgarage/AdaTM)                                             | CP                                | S          | C        | C                | +    | ?    |              |             |\n",
    "| [BTAS](https://github.com/ValeevGroup/BTAS)                                             | CP, Tucker                        | nan        | C        | C++              | +    | ?    |              |             |\n",
    "| [CP-CALS](https://github.com/HPAC/CP-CALS)                                              | CP, Other                         | D          | C, G     | C++, Mat         | +    |      | +            |             |\n",
    "| [CSTF](https://github.com/ZacBlanco/cstf)                                               | Other                             | S          | D        | Scala            | +    | ?    |              |             |\n",
    "| [D-Tucker](https://datalab.snu.ac.kr/dtucker/resources/DTucker-v1.0.tar.gz)             | Tucker, Other                     | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [DFacTo](http://www.joonheechoi.com/research.)                                          | CP                                | S          | C, D     | C++              |      | ?    |              |             |\n",
    "| [EXATN](https://github.com/ORNL-QCI/exatn)                                              | TensorTrain                       | D          | C, D, G  | C++, Py          | +    |      | +            |             |\n",
    "| [Genten](https://gitlab.com/tensors/genten)                                             | CP                                | D, S       | C, G     | C++              | +    |      | +            |             |\n",
    "| GigaTensor                                                                              | CP                                | D          | C        | C++, Python      |      | ?    |              |             |\n",
    "| [ITensor](https://github.com/ITensor/ITensor)                                           | TensorTrain                       | D, BS      | C, G     | C++, Julia       | +    |      | +            |             |\n",
    "| [multiway](https://cran.r-project.org/web/packages/multiway/index.html)                 | CP, Tucker, Other                 | D          | C        | R                |      | ?    |              |             |\n",
    "| [N-way toolbox](http://www.models.life.ku.dk/nwaytoolbox/download)                      | CP, Tucker, Other                 | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [ParCube](https://www.cs.ucr.edu/~epapalex/src/parCube.zip)                             | CP                                | S          | C        | Matlab           |      | ?    |              |             |\n",
    "| [ParTensor](https://github.com/neurocom/partensor-toolbox)                              | CP                                | D          | C, G     | C++              | +    |      | +            |             |\n",
    "| [ParTI!](https://github.com/hpcgarage/ParTI)                                            | CP, Tucker                        | S          | C, G     | C, CUDA, Mat     | +    | ?    |              |             |\n",
    "| [PLANC](https://github.com/ramkikannan/planc)                                           | CP                                | S          | C, D     | C++              | +    | ?    |              |             |\n",
    "| [PLS toolbox](https://eigenvector.com/software/pls-toolbox/)                            | CP          , Tucker              | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [Pytensor](https://code.google.com/archive/p/pytensor/source/default/source)            | Tucker                            | D, S       | C        | Python           |      | ?    |              |             |\n",
    "| [rTensor](https://github.com/jamesyili/rTensor)                                         | CP, Tucker, Other                 | D          | C        | R                | +    |      | +            |             |\n",
    "| [rTensor (randomized)](https://github.com/erichson/rTensor)                             | CP                                | D          | C        | Python           | +    |      | +       +    |             |\n",
    "| [scikit-tensor](https://github.com/mnick/scikit-tensor)                                 | CP, Tucker, Other                 | D, S       | C        | Python           | +    | +    | +    +   +   | too old     |\n",
    "| [Scikit-TT](https://github.com/PGelss/scikit_tt)                                        | TensorTrain                       | D          | C        | Python           | +    |      |     +   +    |             |\n",
    "| [SPALS](https://github.com/dehuacheng/SpAls)                                            | CP                                | S          | C        | C++              | +    | ?    |              |             |\n",
    "| [SPARTan](https://github.com/kperros/SPARTan)                                           | Other                             | S          | C        | Matlab           | +    | ?    |              |             |\n",
    "| [SPLATT](https://github.com/ShadenSmith/splatt)                                         | CP                                | S          | C, D     | C, C++, Oct, Mat | +    | ?    |              |             |\n",
    "| [SuSMoST](https://susmost.com/downloads.html)                                           | TensorTrain, Other                | D          | C        | Python           |      | ?    |              |             |\n",
    "| [T3F](https://github.com/Bihaqo/t3f)                                                    | TensorTrain                       | D          | C, G     | Python           | +    | +    | +    + +     | in progress |\n",
    "| [TDALAB](https://github.com/andrewssobral/TDALAB)                                       | CP                                | D, S       | C        | Python, Matlab   | +    |      | +         +  |             |\n",
    "| [TeNPy](https://github.com/tenpy/tenpy)                                        | TensorTrain                       | D          | C        | Python           | +    | +    | +      + +   | in progress |\n",
    "| [Tensor Fox](https://github.com/felipebottega/Tensor-Fox)                               | CP                                | D, S       | C        | Python, Matlab   | +    | +    | +    + +     | ?           |\n",
    "| [Tensor package](http://www.gipsa-lab.fr/~pierre.comon/TensorPackage/tensorPackage.html) | CP                                | D          | C        | Matlab           |      | ?    |              |             |\n",
    "| [Tensor Toolbox](https://gitlab.com/tensors/tensor_toolbox)                             | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |             |\n",
    "| [tensor_decomposition](https://github.com/cyclops-community/tensor_decomposition)       | CP, Tucker                        | D          | C, D     | Python           | +    |      | +        +   |             |\n",
    "| [TensorBox](https://github.com/phananhhuy/TensorBox)                                    | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +            |             |\n",
    "| [TensorD](https://github.com/Large-Scale-Tensor-Decomposition/tensorD)                  | CP, Tucker                        | D          | C, G     | Python           | ?    | ?    |              |             |\n",
    "| [TensorLab](https://www.tensorlab.net)                                                  | CP, Tucker, Other                 | D, S       | C        | Matlab           |      | ?    |              |             |\n",
    "| [TensorLab+](https://www.tensorlabplus.net)                                             | CP, Other                         | D, S       | C        | Matlab           |      | ?    |              |             |\n",
    "| [TensorLy](https://github.com/tensorly/tensorly)                                        | CP, Tucker, TensorTrain, Other    | D          | C, G     | Python           | +    | +    | +       + +  | in progress |\n",
    "| [Three-Way](https://github.com/cran/ThreeWay)                                           | CP, Tucker                        | D          | C        | R                | +    |      | +            |             |\n",
    "| [TNR](https://github.com/ycyuustc/matlab)                                               | Other                             | D          | C        | Matlab           | +    |      | +            |             |\n",
    "| [TT-Toolbox](https://github.com/oseledets/TT-Toolbox)                                   | TensorTrain                       | D          | C, D, G  | Matlab, Python   | +    |      | +       +    |             |\n",
    "| [xerus](https://git.hemio.de/xerus/xerus/)                                              | TensorTrain                       | D, S       | C        | C++              | +    |      | +            |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Implementations of Decompositions methods"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TensorLy"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:07:33.133749Z",
     "start_time": "2025-04-22T19:07:33.072290Z"
    }
   },
   "source": [
    "# {‘numpy’, ‘mxnet’, ‘pytorch’, ‘tensorflow’, ‘cupy’}\n",
    "# backend variants for tensorly\n",
    "# tl.set_backend('pytorch')\n",
    "# with tl.backend_context(‘pytorch’): ... pass\n",
    "\n",
    "# video_frames_cuda = tl.tensor(video_frames.copy()).to(device)\n",
    "# video_frames_cuda = tl.tensor(video_frames.copy())"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tucker (tl.decomposition.tucker)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:38.582819Z",
     "start_time": "2025-04-22T19:07:33.173812Z"
    }
   },
   "source": [
    "logs = LogReader.load_logs_from_file(log_file_path)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:38.657554Z",
     "start_time": "2025-04-22T19:09:38.613304Z"
    }
   },
   "source": [
    "tl.SVD_FUNS"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truncated_svd', 'symeig_svd', 'randomized_svd']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:38.880653Z",
     "start_time": "2025-04-22T19:09:38.827739Z"
    }
   },
   "source": [
    "input_tensors = input_tucker_tensors\n",
    "\n",
    "tensor_rank_mapping = tensor_tucker_rank_mapping\n",
    "\n",
    "n_iter_max_param = 100\n",
    "\n",
    "svd_params = [\"truncated_svd\", \"symeig_svd\", \"randomized_svd\"]\n",
    "\n",
    "init_params = [\"svd\", \"random\"]\n",
    "\n",
    "backend_params = [\"pytorch\"]\n",
    "\n",
    "random_state_param = 42\n",
    "\n",
    "total_iterations = len(list(product(svd_params, init_params, backend_params))) * len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:39.040392Z",
     "start_time": "2025-04-22T19:09:38.952650Z"
    }
   },
   "source": [
    "for data_type_name_with_index, input_tensor in input_tensors.items():\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "\n",
    "    for backend, svd_func, init_method in tqdm(\n",
    "            product(backend_params, svd_params, init_params),\n",
    "            desc=\"Проверка набора параметров\",\n",
    "            total=total_iterations,\n",
    "    ):\n",
    "        library_method_name = \"TensorLy_Tucker\"\n",
    "        method_name = f\"{library_method_name}_{data_type_name_with_index}_{backend}_{svd_func}_{init_method}\"\n",
    "\n",
    "        print(f\"Current method: {method_name}\")\n",
    "\n",
    "        if logs:\n",
    "            existing_log = next(\n",
    "                (\n",
    "                    log\n",
    "                    for log in logs\n",
    "                    if log[\"method_name\"] == method_name\n",
    "                       and log[\"method_args\"].get(\"init\") == init_method\n",
    "                       and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                       and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if existing_log:\n",
    "                print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with tl.backend_context(backend):\n",
    "                if backend == \"pytorch\":\n",
    "                    tensor_param = tl.tensor(input_tensor).to(torch_device)\n",
    "                elif backend == \"numpy\" or backend is None:\n",
    "                    tensor_param = tl.tensor(input_tensor)\n",
    "\n",
    "                method_runner = MethodRunner(\n",
    "                    func=tl.decomposition.tucker,\n",
    "                    method_input_tensor=tensor_param,\n",
    "                    library_method_name=library_method_name,\n",
    "                    backend_name=backend,\n",
    "                    gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                    ram_memory_tracker=RAMMemoryTracker(),\n",
    "                    time_tracker=TimeTracker(),\n",
    "                )\n",
    "\n",
    "                method_logger = MethodLogger(\n",
    "                    method_name=method_name,\n",
    "                    qualitative_metrics={\n",
    "                        \"Language\": \"Python\",\n",
    "                        \"Library\": \"TensorLy\",\n",
    "                        \"TensorLy backend\": f\"{backend}\",\n",
    "                        \"Tensor type\": \"Dense\",\n",
    "                        \"Data type\": data_type_name_with_index,\n",
    "                        \"Platform\": \"CPU, GPU\",\n",
    "                        \"Decomposition method\": \"Tucker\",\n",
    "                    },\n",
    "                    method_args={\n",
    "                        \"tensor\": tensor_param,\n",
    "                        \"rank\": rank_param,\n",
    "                        \"n_iter_max\": n_iter_max_param,\n",
    "                        \"init\": init_method,\n",
    "                        \"svd\": svd_func,\n",
    "                        \"random_state\": random_state_param,\n",
    "                    },\n",
    "                    runner=method_runner,\n",
    "                    is_test=False,\n",
    "                )\n",
    "\n",
    "                method_logger.run_experiments()\n",
    "\n",
    "            reconstructed_tensor = method_runner.reconstructed_tensor\n",
    "\n",
    "            reconstructed_frames = []\n",
    "\n",
    "            reconstructed_tensor = reconstructed_tensor.cpu().numpy() if backend == \"pytorch\" else reconstructed_tensor\n",
    "            reconstructed_frames = np.array([normalize_frames(frame) for frame in reconstructed_tensor])\n",
    "\n",
    "            save_params_combinations = {\n",
    "                \"image\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "                \"video\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                    \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "                    \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "                    if data_type_name == \"video\"\n",
    "                    else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "                },\n",
    "                \"eeg\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "            }\n",
    "            save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "            SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)\n",
    "\n",
    "        except (torch.cuda.OutOfMemoryError, MemoryError) as e:\n",
    "            error_message = f\"Пропущена итерация из-за ошибки: {backend}, {svd_func}, {init_method}. Ошибка: {e!s}\"\n",
    "            print(error_message)\n",
    "            torch.cuda.synchronize()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            method_logger.error_message = error_message\n",
    "\n",
    "            continue\n",
    "\n",
    "        finally:\n",
    "            method_logger.save_logs_to_file(is_test=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 31775.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_image-0_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-0_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-0_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-0_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-0_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-0_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_image-0_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-0_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 26434.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_image-1_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-1_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_image-1_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-1_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_image-1_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-1_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_image-1_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-1_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_image-1_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-1_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_image-1_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-1_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 27624.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_image-2_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-2_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_image-2_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-2_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_image-2_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-2_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_image-2_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-2_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_image-2_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-2_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_image-2_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_image-2_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 17772.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_video-0_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-0_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_video-0_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-0_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_video-0_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-0_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_video-0_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-0_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_video-0_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-0_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_video-0_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-0_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 17260.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_video-1_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-1_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_video-1_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-1_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_video-1_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-1_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_video-1_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-1_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_video-1_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-1_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_video-1_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-1_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 16699.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_video-2_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-2_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_video-2_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-2_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_video-2_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-2_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_video-2_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-2_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_video-2_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-2_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_video-2_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_video-2_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 15261.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_eeg-0_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-0_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_eeg-0_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-0_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_eeg-0_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-0_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_eeg-0_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-0_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_eeg-0_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-0_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_eeg-0_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-0_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Проверка набора параметров:  12%|█▎        | 6/48 [00:00<00:00, 11776.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method: TensorLy_Tucker_eeg-1_pytorch_truncated_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-1_pytorch_truncated_svd_svd\n",
      "Current method: TensorLy_Tucker_eeg-1_pytorch_truncated_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-1_pytorch_truncated_svd_random\n",
      "Current method: TensorLy_Tucker_eeg-1_pytorch_symeig_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-1_pytorch_symeig_svd_svd\n",
      "Current method: TensorLy_Tucker_eeg-1_pytorch_symeig_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-1_pytorch_symeig_svd_random\n",
      "Current method: TensorLy_Tucker_eeg-1_pytorch_randomized_svd_svd\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-1_pytorch_randomized_svd_svd\n",
      "Current method: TensorLy_Tucker_eeg-1_pytorch_randomized_svd_random\n",
      "Пропущена итерация: логи уже существуют для TensorLy_Tucker_eeg-1_pytorch_randomized_svd_random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:39.746604Z",
     "start_time": "2025-04-22T19:09:39.509263Z"
    }
   },
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"tensor_param\",\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"n_iter_max_param\",\n",
    "    \"svd_params\",\n",
    "    \"init_params\",\n",
    "    \"backend_params\",\n",
    "    \"random_state_param\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"backend\",\n",
    "    \"svd_func\",\n",
    "    \"init_method\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"reconstructed_tensor\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "    \"frame\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1932"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train - MPS (tensorly.decomposition.tensor_train)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.785320Z",
     "start_time": "2025-04-22T19:09:39.776482Z"
    }
   },
   "source": [
    "logs = LogReader.load_logs_from_file(log_file_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.836400600Z",
     "start_time": "2025-02-23T07:45:52.795727Z"
    }
   },
   "source": [
    "# input_tensors = {\n",
    "#     \"eeg-0\": eegs[\"eeg-0\"][\"frames\"].copy().astype(np.float32),\n",
    "#     # \"eeg-1\": eegs[\"eeg-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "# }\n",
    "# \n",
    "# tensor_rank_mapping = {\n",
    "#     \"image-0\": [1, 212, 212, 1],\n",
    "#     \"image-1\": [1, 170, 212, 1],\n",
    "#     \"image-2\": [1, 290, 300, 1],\n",
    "#     \"video-0\": [1, 300, 215, 300, 1],\n",
    "#     \"video-1\": [1, 500, 278, 500, 1],\n",
    "#     \"video-2\": [1, 500, 375, 500, 1],\n",
    "#     \"eeg-0\": [1, 1000, 1750, 2000, 1750, 1000, 1],  # (4, 12, 3, 29, 64, 321)\n",
    "#     # \"eeg-1\": [1, 1000, 1750, 2000, 1750, 1000, 1],  # (4, 12, 3, 29, 64, 321)\n",
    "# }\n",
    "\n",
    "input_tensors = input_tensor_train_tensors\n",
    "\n",
    "tensor_rank_mapping = tensor_tensor_train_rank_mapping\n",
    "\n",
    "svd_params = [\"randomized_svd\", \"truncated_svd\", \"symeig_svd\"]\n",
    "\n",
    "backend_params = [\"pytorch\"] # , \"numpy\"\n",
    "\n",
    "total_iterations = len(list(product(backend_params, svd_params))) * len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for data_type_name_with_index, input_tensor in input_tensors.items():\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "\n",
    "    for backend, svd_func in tqdm(\n",
    "            product(backend_params, svd_params),\n",
    "            desc=\"Проверка набора параметров\",\n",
    "            total=total_iterations,\n",
    "    ):\n",
    "        library_method_name = \"TensorLy_TensorTrain\"\n",
    "        method_name = f\"{library_method_name}_{data_type_name_with_index}_{backend}_{svd_func}\"\n",
    "\n",
    "        print(f\"Current method: {method_name}\")\n",
    "\n",
    "        if logs:\n",
    "            existing_log = next(\n",
    "                (\n",
    "                    log\n",
    "                    for log in logs\n",
    "                    if log[\"method_name\"] == method_name\n",
    "                       and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                       and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if existing_log:\n",
    "                print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with tl.backend_context(backend):\n",
    "                if backend == \"pytorch\":\n",
    "                    tensor_param = tl.tensor(input_tensor).to(torch_device)\n",
    "                elif backend == \"numpy\" or backend is None:\n",
    "                    tensor_param = tl.tensor(input_tensor)\n",
    "\n",
    "                method_runner = MethodRunner(\n",
    "                    func=tl.decomposition.tensor_train,\n",
    "                    method_input_tensor=tensor_param,\n",
    "                    library_method_name=library_method_name,\n",
    "                    backend_name=backend,\n",
    "                    gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                    ram_memory_tracker=RAMMemoryTracker(),\n",
    "                    time_tracker=TimeTracker(),\n",
    "                )\n",
    "\n",
    "                method_logger = MethodLogger(\n",
    "                    method_name=method_name,\n",
    "                    qualitative_metrics={\n",
    "                        \"Language\": \"Python\",\n",
    "                        \"Library\": \"TensorLy\",\n",
    "                        \"TensorLy backend\": f\"{backend}\",\n",
    "                        \"Tensor type\": \"Dense\",\n",
    "                        \"Data type\": data_type_name_with_index,\n",
    "                        \"Platform\": \"CPU, GPU\",\n",
    "                        \"Decomposition method\": \"TensorTrain\",\n",
    "                    },\n",
    "                    method_args={\n",
    "                        \"input_tensor\": tensor_param,\n",
    "                        \"rank\": rank_param,\n",
    "                        \"svd\": svd_func,\n",
    "                    },\n",
    "                    runner=method_runner,\n",
    "                    is_test=False,\n",
    "                )\n",
    "\n",
    "                method_logger.run_experiments()\n",
    "\n",
    "            reconstructed_tensor_from_tt_factors = method_runner.reconstructed_tensor\n",
    "\n",
    "            reconstructed_frames = []\n",
    "\n",
    "            for tt_factor in reconstructed_tensor_from_tt_factors:\n",
    "                if backend == \"pytorch\":\n",
    "                    reconstructed_frames.append(normalize_frames(tt_factor.cpu().numpy()))\n",
    "                else:\n",
    "                    reconstructed_frames.append(normalize_frames(tt_factor))\n",
    "            reconstructed_frames = np.array(reconstructed_frames)\n",
    "\n",
    "            save_params_combinations = {\n",
    "                \"image\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "                \"video\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                    \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "                    \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "                    if data_type_name == \"video\"\n",
    "                    else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "                },\n",
    "                \"eeg\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "            }\n",
    "            save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "            SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)\n",
    "\n",
    "            # break\n",
    "\n",
    "        except (torch.cuda.OutOfMemoryError, MemoryError) as e:\n",
    "            error_message = f\"Пропущена итерация из-за ошибки: {backend}, {svd_func}. Ошибка: {e!s}\"\n",
    "            print(error_message)\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            gc.collect()\n",
    "\n",
    "            method_logger.error_message = error_message\n",
    "\n",
    "            continue\n",
    "        finally:\n",
    "            method_logger.save_logs_to_file(is_test=False)\n",
    "    # break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.851901Z",
     "start_time": "2025-02-23T08:05:56.139105Z"
    }
   },
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"svd_params\",\n",
    "    \"backend_params\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"backend\",\n",
    "    \"svd_func\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"reconstructed_tensor_from_tt_factors\",\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "    \"tt_factor\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### CANDECOMP/PARAFAC (tensorly.decomposition.parafac)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852410300Z",
     "start_time": "2025-03-09T19:44:49.788060Z"
    }
   },
   "source": "logs = LogReader.load_logs_from_file(log_file_path)",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852410300Z",
     "start_time": "2025-03-09T19:46:32.275312Z"
    }
   },
   "source": [
    "input_tensors = {\n",
    "    \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "    \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "    # \"video-0\": videos['video-0']['frames'].copy().astype(np.float32),\n",
    "    # \"video-1\": videos['video-1']['frames'].copy().astype(np.float32),\n",
    "    # \"video-2\": videos['video-2']['frames'].copy().astype(np.float32),\n",
    "}\n",
    "\n",
    "tensor_rank_mapping = {\n",
    "    \"image-0\": 422,\n",
    "    \"image-1\": 370,\n",
    "    \"image-2\": 655,\n",
    "    # \"video-0\": 3500,\n",
    "    # \"video-1\": 2036,\n",
    "    # \"video-2\": 3620,\n",
    "}\n",
    "\n",
    "# backend_params = [\"pytorch\", \"numpy\"]\n",
    "backend_params = [\"pytorch\"]\n",
    "\n",
    "svd_params = [\"truncated_svd\", \"symeig_svd\", \"randomized_svd\"]\n",
    "\n",
    "init_params = [\"random\", \"svd\"]\n",
    "\n",
    "normalize_factors_params = [False, True]\n",
    "# normalize_factors_params = [False]\n",
    "\n",
    "orthogonalise_params = [False, True]\n",
    "# orthogonalise_params = [False]\n",
    "\n",
    "linesearch_params = [False, True]\n",
    "\n",
    "cvg_criterion_params = [\"abs_rec_error\", \"rec_error\"]\n",
    "\n",
    "l2_reg_params = [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "# l2_reg_params = [0]\n",
    "\n",
    "tol_params = [1e-8, 1e-5, 1e-6, 1e-7, 1e-9]\n",
    "# tol_params = [1e-8]\n",
    "\n",
    "n_iter_max_param = 100\n",
    "\n",
    "random_state_param = 42\n",
    "\n",
    "total_iterations = len(\n",
    "    list(\n",
    "        product(\n",
    "            backend_params,\n",
    "            svd_params,\n",
    "            init_params,\n",
    "            normalize_factors_params,\n",
    "            orthogonalise_params,\n",
    "            linesearch_params,\n",
    "            cvg_criterion_params,\n",
    "            l2_reg_params,\n",
    "            tol_params,\n",
    "        )\n",
    "    )\n",
    ") * len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for data_type_name_with_index, input_tensor in input_tensors.items():\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "\n",
    "    for (\n",
    "            backend,\n",
    "            normalize_factors,\n",
    "            orthogonalise,\n",
    "            linesearch,\n",
    "            cvg_criterion,\n",
    "            l2_reg,\n",
    "            tol,\n",
    "            init_method,\n",
    "            svd_func,\n",
    "    ) in tqdm(\n",
    "        product(\n",
    "            backend_params,\n",
    "            normalize_factors_params,\n",
    "            orthogonalise_params,\n",
    "            linesearch_params,\n",
    "            cvg_criterion_params,\n",
    "            l2_reg_params,\n",
    "            tol_params,\n",
    "            init_params,\n",
    "            svd_params,\n",
    "        ),\n",
    "        desc=\"Проверка набора параметров\",\n",
    "        total=total_iterations,\n",
    "    ):\n",
    "        library_method_name = \"TensorLy_CP\"\n",
    "        method_name = f\"{library_method_name}_{data_type_name_with_index}_{backend}_{svd_func}_{init_method}_{normalize_factors}_{orthogonalise}_{cvg_criterion}_{l2_reg}_{tol}\"\n",
    "\n",
    "        print(f\"Current method: {method_name}\")\n",
    "\n",
    "        if logs:\n",
    "            existing_log = next(\n",
    "                (\n",
    "                    log\n",
    "                    for log in logs\n",
    "                    if log[\"method_name\"] == method_name\n",
    "                       and log[\"method_args\"].get(\"init\") == init_method\n",
    "                       and log[\"method_args\"].get(\"svd\") == svd_func\n",
    "                       and log[\"method_args\"].get(\"normalize_factors\") == normalize_factors\n",
    "                       and log[\"method_args\"].get(\"orthogonalise\") == orthogonalise\n",
    "                       and log[\"method_args\"].get(\"cvg_criterion\") == cvg_criterion\n",
    "                       and log[\"method_args\"].get(\"l2_reg\") == l2_reg\n",
    "                       and log[\"method_args\"].get(\"tol\") == tol\n",
    "                       and log[\"qualitative_metrics\"].get(\"TensorLy backend\") == backend\n",
    "                       and log[\"method_args\"].get(\"linesearch\") == linesearch\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if existing_log:\n",
    "                print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            with tl.backend_context(backend):\n",
    "                if backend == \"pytorch\":\n",
    "                    tensor_param = tl.tensor(input_tensor).to(torch_device)\n",
    "                elif backend == \"numpy\" or backend is None:\n",
    "                    tensor_param = tl.tensor(input_tensor)\n",
    "\n",
    "                method_runner = MethodRunner(\n",
    "                    func=tl.decomposition.parafac,\n",
    "                    method_input_tensor=tensor_param,\n",
    "                    library_method_name=library_method_name,\n",
    "                    backend_name=backend,\n",
    "                    gpu_memory_tracker=GPUTorchMemoryTracker(),\n",
    "                    ram_memory_tracker=RAMMemoryTracker(),\n",
    "                    time_tracker=TimeTracker(),\n",
    "                )\n",
    "\n",
    "                method_logger = MethodLogger(\n",
    "                    method_name=method_name,\n",
    "                    qualitative_metrics={\n",
    "                        \"Language\": \"Python\",\n",
    "                        \"Library\": \"TensorLy\",\n",
    "                        \"TensorLy backend\": f\"{backend}\",\n",
    "                        \"Tensor type\": \"Dense\",\n",
    "                        \"Data type\": data_type_name_with_index,\n",
    "                        \"Platform\": \"CPU, GPU\",\n",
    "                        \"Decomposition method\": \"CP\",\n",
    "                    },\n",
    "                    method_args={\n",
    "                        \"tensor\": tensor_param,\n",
    "                        \"rank\": rank_param,\n",
    "                        \"n_iter_max\": n_iter_max_param,\n",
    "                        \"init\": init_method,\n",
    "                        \"svd\": svd_func,\n",
    "                        \"normalize_factors\": normalize_factors,\n",
    "                        \"orthogonalise\": orthogonalise,\n",
    "                        \"tol\": tol,\n",
    "                        \"random_state\": random_state_param,\n",
    "                        \"l2_reg\": l2_reg,\n",
    "                        \"cvg_criterion\": cvg_criterion,\n",
    "                        \"linesearch\": linesearch,\n",
    "                    },\n",
    "                    runner=method_runner,\n",
    "                    is_test=False,\n",
    "                )\n",
    "\n",
    "                method_logger.run_experiments()\n",
    "\n",
    "            reconstructed_tensor = method_runner.reconstructed_tensor\n",
    "\n",
    "            reconstructed_frames = []\n",
    "\n",
    "            reconstructed_tensor = reconstructed_tensor.cpu().numpy() if backend == \"pytorch\" else reconstructed_tensor\n",
    "            reconstructed_frames = np.array([normalize_frames(frame) for frame in reconstructed_tensor])\n",
    "\n",
    "            save_params_combinations = {\n",
    "                \"image\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                },\n",
    "                \"video\": {\n",
    "                    \"name\": method_logger.name,\n",
    "                    \"frames\": reconstructed_frames,\n",
    "                    \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "                    \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "                    if data_type_name == \"video\"\n",
    "                    else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "                },\n",
    "            }\n",
    "            save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "            SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)\n",
    "\n",
    "        except (\n",
    "                torch.cuda.OutOfMemoryError,\n",
    "                MemoryError,\n",
    "                np.linalg.LinAlgError,\n",
    "                torch._C._LinAlgError,\n",
    "        ) as e:\n",
    "            error_message = f\"Пропущена итерация из-за ошибки: {backend}, {svd_func}, {init_method}, {normalize_factors}, {orthogonalise}, {tol}, {l2_reg}, {cvg_criterion}. Ошибка: {e!s}\"\n",
    "            print(error_message)\n",
    "            torch.cuda.synchronize()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            method_logger.error_message = error_message\n",
    "\n",
    "            continue\n",
    "        finally:\n",
    "            method_metrics = method_logger.save_logs_to_file(is_test=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852923400Z",
     "start_time": "2025-03-10T09:35:47.203072Z"
    }
   },
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"tensor_param\",\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"n_iter_max_param\",\n",
    "    \"svd_params\",\n",
    "    \"init_params\",\n",
    "    \"backend_params\",\n",
    "    \"random_state_param\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"backend\",\n",
    "    \"svd_func\",\n",
    "    \"init_method\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"reconstructed_tensor\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "    \"frame\",\n",
    "    \"normalize_factors_params\",\n",
    "    \"orthogonalise_params\",\n",
    "    \"cvg_criterion_params\",\n",
    "    \"l2_reg_params\",\n",
    "    \"tol_params\",\n",
    "    \"normalize_factors\",\n",
    "    \"orthogonalise\",\n",
    "    \"cvg_criterion\",\n",
    "    \"tol\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## T3F"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Tensor Train"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.852923400Z",
     "start_time": "2025-02-23T08:05:56.530062Z"
    }
   },
   "source": [
    "logs = LogReader.load_logs_from_file(log_file_path)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853399200Z",
     "start_time": "2025-02-23T08:05:57.685362Z"
    }
   },
   "source": [
    "# input_tensors = {\n",
    "#     \"image-2\": images[\"image-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-1\": images[\"image-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"image-0\": images[\"image-0\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-2\": videos[\"video-2\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-1\": videos[\"video-1\"][\"frames\"].copy().astype(np.float32),\n",
    "#     \"video-0\": videos[\"video-0\"][\"frames\"].copy().astype(np.float32),\n",
    "# }\n",
    "# \n",
    "# tensor_rank_mapping = {\n",
    "#     \"image-0\": [1, 212, 212, 1],\n",
    "#     \"image-1\": [1, 170, 212, 1],\n",
    "#     \"image-2\": [1, 290, 300, 1],\n",
    "#     \"video-0\": [1, 300, 215, 300, 1],\n",
    "#     \"video-1\": [1, 500, 278, 500, 1],\n",
    "#     \"video-2\": [1, 500, 375, 500, 1],\n",
    "# }\n",
    "\n",
    "input_tensors = input_tensor_train_tensors\n",
    "\n",
    "tensor_rank_mapping = tensor_tensor_train_rank_mapping\n",
    "\n",
    "backend_param = \"tensorflow\"\n",
    "\n",
    "total_iterations = len(input_tensors)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Compare method with some params and log it"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for data_type_name_with_index, input_tensor in tqdm(\n",
    "        input_tensors.items(),\n",
    "        desc=\"Проверка набора параметров\",\n",
    "        total=total_iterations,\n",
    "):\n",
    "    rank_param = tensor_rank_mapping[data_type_name_with_index]\n",
    "    data_type_name = data_type_name_with_index.split(\"-\")[0]\n",
    "    tensor_param = input_tensor\n",
    "\n",
    "    library_method_name = \"T3F_TensorTrain\"\n",
    "    method_name = f\"{library_method_name}_{data_type_name_with_index}\"\n",
    "\n",
    "    print(method_name)\n",
    "\n",
    "    if logs:\n",
    "        existing_log = next((log for log in logs if log[\"method_name\"] == method_name), None)\n",
    "        if existing_log:\n",
    "            print(f\"Пропущена итерация: логи уже существуют для {method_name}\")\n",
    "            continue\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    method_runner = MethodRunner(\n",
    "        func=t3f.to_tt_tensor,\n",
    "        method_input_tensor=tensor_param,\n",
    "        library_method_name=library_method_name,\n",
    "        backend_name=backend_param,\n",
    "        gpu_memory_tracker=GPUTensorflowMemoryTracker(tf_devices=tf_devices),\n",
    "        ram_memory_tracker=RAMMemoryTracker(),\n",
    "        time_tracker=TimeTracker(),\n",
    "    )\n",
    "\n",
    "    method_logger = MethodLogger(\n",
    "        method_name=method_name,\n",
    "        qualitative_metrics={\n",
    "            \"Language\": \"Python\",\n",
    "            \"Library\": \"T3F\",\n",
    "            \"T3F backend\": f\"{backend_param}\",\n",
    "            \"Tensor type\": \"Dense\",\n",
    "            \"Data type\": data_type_name_with_index,\n",
    "            \"Platform\": \"CPU, GPU\",\n",
    "            \"Decomposition method\": \"TensorTrain\",\n",
    "        },\n",
    "        method_args={\n",
    "            \"tens\": tensor_param,\n",
    "            \"max_tt_rank\": rank_param,\n",
    "        },\n",
    "        runner=method_runner,\n",
    "        is_test=False,\n",
    "    )\n",
    "\n",
    "    method_logger.run_experiments()\n",
    "\n",
    "    reconstructed_tensor_t3f = method_runner.reconstructed_tensor\n",
    "\n",
    "    method_logger.save_logs_to_file(is_test=False)\n",
    "\n",
    "    reconstructed_frames = []\n",
    "\n",
    "    for frame in reconstructed_tensor_t3f:\n",
    "        reconstructed_frames.append(normalize_frames(frame))\n",
    "    reconstructed_frames = np.array(reconstructed_frames)\n",
    "\n",
    "    save_params_combinations = {\n",
    "        \"image\": {\"name\": method_logger.name, \"frames\": reconstructed_frames},\n",
    "        \"video\": {\n",
    "            \"name\": method_logger.name,\n",
    "            \"frames\": reconstructed_frames,\n",
    "            \"fps\": videos[data_type_name_with_index][\"original_fps\"] if data_type_name == \"video\" else 1,\n",
    "            \"frame_size\": videos[data_type_name_with_index][\"frame_size\"]\n",
    "            if data_type_name == \"video\"\n",
    "            else (input_tensor.shape[0], input_tensor.shape[1]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    save_params = save_params_combinations[data_type_name]\n",
    "\n",
    "    SaveFramesFactory.get_save_methods(frame_name=data_type_name).save_frames(**save_params)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Clear cache and gc collect"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853399200Z",
     "start_time": "2024-10-21T21:36:16.517666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()\n",
    "\n",
    "variables_to_delete = [\n",
    "    \"logs\",\n",
    "    \"tensor_rank_mapping\",\n",
    "    \"input_tensors\",\n",
    "    \"backend_param\",\n",
    "    \"total_iterations\",\n",
    "    \"data_type_name\",\n",
    "    \"input_tensor\",\n",
    "    \"rank_param\",\n",
    "    \"tensor_param\",\n",
    "    \"library_method_name\",\n",
    "    \"method_name\",\n",
    "    \"method_runner\",\n",
    "    \"method_logger\",\n",
    "    \"reconstructed_tensor_t3f\",\n",
    "    \"reconstructed_frames\",\n",
    "    \"frame\",\n",
    "    \"save_params_combinations\",\n",
    "    \"save_params\",\n",
    "]\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    with contextlib.suppress(KeyError):\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## TeNPy (not implemented)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853399200Z",
     "start_time": "2024-10-21T21:36:17.090065Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensor_param = video_frames.copy().astype(np.float32)\n",
    "#\n",
    "# # Размерность физического индекса\n",
    "# d = tensor_param.shape[-1]  # в вашем случае это 3\n",
    "#\n",
    "# # Создаем объект LegCharge\n",
    "# leg = LegCharge.from_trivial(d)\n",
    "#\n",
    "# # Создаем объекты Site для каждого физического индекса, кроме последнего\n",
    "# sites = [Site(leg) for _ in range(tensor_param.ndim - 1)]\n",
    "#\n",
    "# rank_param = [1, 500, 302, 500, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Implementation"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853900500Z",
     "start_time": "2024-10-21T21:36:17.151098Z"
    }
   },
   "outputs": [],
   "source": [
    "# mps = MPS.from_full(sites=sites, psi=tensor_param, normalize=False)\n",
    "#\n",
    "# reconstructed_tensor = mps.to_full_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853900500Z",
     "start_time": "2024-10-21T21:36:17.491557Z"
    }
   },
   "outputs": [],
   "source": [
    "# logs = load_logs_from_file(log_file_path)\n",
    "#\n",
    "# method_name = f\"TeNPy_TensorTrain\"\n",
    "#\n",
    "# if logs:\n",
    "#     existing_log = next(\n",
    "#         (log for log in logs if log['method_name'] == method_name),\n",
    "#         None\n",
    "#     )\n",
    "#     if existing_log:\n",
    "#         error_message = f\"Пропущена итерация: логи уже существуют для {method_name}\"\n",
    "#         raise error_message\n",
    "#\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.synchronize()\n",
    "#\n",
    "# method_logs = MethodLogger(\n",
    "#     method_name=method_name,\n",
    "#     method_input_tensor=tensor_param,\n",
    "#     qualitative_metrics={\n",
    "#         \"Language\": \"Python\",\n",
    "#         \"Library\": \"TeNPy\",\n",
    "#         \"Tensor type\": \"Dense\",\n",
    "#         \"Platform\": \"CPU\",\n",
    "#         \"Decomposition method\": \"TensorTrain\",\n",
    "#     },\n",
    "#     method_args={\n",
    "#         \"sites\": tensor_param,\n",
    "#         \"psi\": rank_param,\n",
    "#         \"normalize\": False,\n",
    "#     },\n",
    "#     func=tenpy.networks.mps.MPS.from_full\n",
    "# )\n",
    "#\n",
    "# method_logs_list.append(method_logs)\n",
    "#\n",
    "# tt_factors = method_logs.method_result\n",
    "#\n",
    "# reconstruct_frames_from_tenpy_tt_factors = tt_factors.to_full_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T19:09:57.853900500Z",
     "start_time": "2024-10-21T21:36:17.650064Z"
    }
   },
   "outputs": [],
   "source": [
    "# method_logs.quantitative_metrics['compression_ratio'] = (100.0 * get_tensors_size(*tt_factors) / get_tensors_size(tensor_param))\n",
    "\n",
    "# method_logs.quantitative_metrics['frobenius_error'] = (\n",
    "#         100.0 * np.linalg.norm(reconstruct_frames_from_tenpy_tt_factors - tensor_param) / tl.norm(\n",
    "#         tensor_param))\n",
    "#\n",
    "# save_logs_to_file(method_logs=method_logs, is_test=True)\n",
    "#\n",
    "# reconstructed_frames = []\n",
    "#\n",
    "# for i in range(len(reconstruct_frames_from_tenpy_tt_factors)):\n",
    "#     reconstructed_frames.append(normalize_frame_tensorly_tensortrain(reconstruct_frames_from_tenpy_tt_factors[i]))\n",
    "#\n",
    "# save_frames_as_video(name=method_logs.name, frames=reconstructed_frames, fps=original_fps, frame_size=frame_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
