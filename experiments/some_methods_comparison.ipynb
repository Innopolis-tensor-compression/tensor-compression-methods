{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.100393Z",
     "start_time": "2024-09-26T21:30:04.053284Z"
    }
   },
   "source": [
    "!python --version"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.140468Z",
     "start_time": "2024-09-26T21:30:04.132422Z"
    }
   },
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import psutil\n",
    "import yt_dlp\n",
    "from dotenv import load_dotenv\n",
    "from scipy.linalg import svd\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Some class and methods for logging of compression metrics of some methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.176231Z",
     "start_time": "2024-09-26T21:30:04.171211Z"
    }
   },
   "source": [
    "class MethodLogs:\n",
    "    def __init__(self, method_name: str, method_args: dict[str, Any]):\n",
    "        self.name = method_name\n",
    "        self.method_args = method_args\n",
    "        self.qualitative_metrics = {}\n",
    "        self.quantitative_metrics = {}\n",
    "\n",
    "\n",
    "method_logs_list = []\n",
    "\n",
    "\n",
    "def memory(*args):\n",
    "    total = 0\n",
    "    for arg in args:\n",
    "        partial = 1\n",
    "        for d in arg.shape:\n",
    "            partial *= d\n",
    "        total += partial\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_current_rss_memory(*, is_mb: bool = False) -> float:\n",
    "    process = psutil.Process(os.getpid())\n",
    "    rss_memory = process.memory_info().rss\n",
    "\n",
    "    if is_mb:\n",
    "        return rss_memory / (1024 * 1024)\n",
    "    return rss_memory"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Download video and extract frames from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some functions to do it"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.205047Z",
     "start_time": "2024-09-26T21:30:04.196861Z"
    }
   },
   "source": [
    "def download_progress_hook(d):\n",
    "    if d[\"status\"] == \"downloading\":\n",
    "        print(f\"Downloading: {d['_percent_str']} at {d['_speed_str']} ETA: {d['_eta_str']}\")\n",
    "    elif d[\"status\"] == \"finished\":\n",
    "        print(\"Download complete!\")\n",
    "\n",
    "\n",
    "def extract_video_id(video_url):\n",
    "    video_id_match = re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\", video_url)\n",
    "    if video_id_match:\n",
    "        return video_id_match.group(1)\n",
    "    error_message = \"Не удалось извлечь ID видео из URL\"\n",
    "    raise ValueError(error_message)\n",
    "\n",
    "\n",
    "def download_youtube_video(video_url, cache_dir=None, proxy_url=None):\n",
    "    if cache_dir:\n",
    "        Path(cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "        video_id = extract_video_id(video_url)\n",
    "        cache_video_path = Path(cache_dir) / f\"{video_id}.mp4\"\n",
    "    else:\n",
    "        cache_video_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "\n",
    "    if Path(cache_video_path).exists():\n",
    "        print(f\"Видео уже загружено и закешировано: {cache_video_path}\")\n",
    "        return cache_video_path\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"format\": \"best\",\n",
    "        \"outtmpl\": cache_video_path,\n",
    "        \"progress_hooks\": [download_progress_hook],\n",
    "    }\n",
    "\n",
    "    if proxy_url:\n",
    "        ydl_opts[\"proxy\"] = proxy_url\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "    print(f\"Видео загружено и сохранено: {cache_video_path}\")\n",
    "    return cache_video_path\n",
    "\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def process_frames(frames):\n",
    "    processed_frames = []\n",
    "\n",
    "    for frame in frames:\n",
    "        b_channel, g_channel, r_channel = cv2.split(frame)\n",
    "\n",
    "        merged_frame = cv2.merge((b_channel, g_channel, r_channel))\n",
    "\n",
    "        processed_frames.append(merged_frame)\n",
    "\n",
    "    return np.array(processed_frames)"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some params"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.222882Z",
     "start_time": "2024-09-26T21:30:04.218070Z"
    }
   },
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=eSKe2Vx-rpY\"\n",
    "proxy_url = os.getenv(\"PROXY_URL\")\n",
    "cache_dir = \"../.cache\""
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check how functions work"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.242964Z",
     "start_time": "2024-09-26T21:30:04.236741Z"
    }
   },
   "source": [
    "video_path = download_youtube_video(video_url, cache_dir=cache_dir, proxy_url=proxy_url)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео уже загружено и закешировано: ..\\.cache\\eSKe2Vx-rpY.mp4\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.450560Z",
     "start_time": "2024-09-26T21:30:04.303945Z"
    }
   },
   "source": [
    "video_frames = extract_frames(video_path)"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.549376Z",
     "start_time": "2024-09-26T21:30:04.455570Z"
    }
   },
   "source": [
    "processed_video_frames = process_frames(video_frames)"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check original video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.565965Z",
     "start_time": "2024-09-26T21:30:04.563132Z"
    }
   },
   "source": [
    "# for frame in processed_video_frames:\n",
    "#     cv2.imshow('Downloaded Video', frame)\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Implementations of Decompositions methods"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some packages which can decompose some dense type of tensors, from [this](https://arxiv.org/pdf/2103.13756) paper\n",
    "\n",
    "\n",
    "Decomposition methods which used:\n",
    "1. Canonical Polyadic Decomposition as PARAllel FACtors analysis (aka PARAFAC aka CPD aka CP)\n",
    "2. Tucker Decomposition\n",
    "3. Tensor Train\n",
    "4. some variants of its (Other)\n",
    "\n",
    "Tensor types:\n",
    "1. Dense (D)\n",
    "2. Sparse (S)\n",
    "3. BlockSparse (BS)\n",
    "4. Symmetric\n",
    "5. Supersymmetric\n",
    "\n",
    "Target system:\n",
    "1. CPU (C)\n",
    "2. GPU(G)\n",
    "3. Distributed Memory (D)\n",
    "\n",
    "\n",
    "\n",
    "| Method name                                                                             | Decomposition methods implemented | Tensor Type | Platform | Language         | Git | PyPI | Want to check | Checked |\n",
    "|-----------------------------------------------------------------------------------------|-----------------------------------|------------|----------|------------------|------|------|---------------|---------|\n",
    "| some experiment with SVD from scipy                                                     | -                                 | -          | -        | Python           | +    |      | +             | +       |\n",
    "| [AdaTM](https://github.com/hpcgarage/AdaTM)                                             | CP                                | S          | C        | C                | +    | ?    |               |         |\n",
    "| [BTAS](https://github.com/ValeevGroup/BTAS)                                             | CP, Tucker                        | nan        | C        | C++              | +    | ?    |               |         |\n",
    "| [CP-CALS](https://github.com/HPAC/CP-CALS)                                              | CP, Other                         | D          | C, G     | C++, Mat         | +    |      | +             |         |\n",
    "| [CSTF](https://github.com/ZacBlanco/cstf)                                               | Other                             | S          | D        | Scala            | +    | ?    |               |         |\n",
    "| [D-Tucker](https://datalab.snu.ac.kr/dtucker/resources/DTucker-v1.0.tar.gz)             | Tucker, Other                     | D          | C        | Matlab           |      | ?    |               |         |\n",
    "| [DFacTo](http://www.joonheechoi.com/research.)                                          | CP                                | S          | C, D     | C++              |      | ?    |               |         |\n",
    "| [EXATN](https://github.com/ORNL-QCI/exatn)                                              | TensorTrain                       | D          | C, D, G  | C++, Py          | +    |      | +             |         |\n",
    "| [Genten](https://gitlab.com/tensors/genten)                                             | CP                                | D, S       | C, G     | C++              | +    |      | +             |         |\n",
    "| GigaTensor                                                                              | CP                                | D          | C        | C++, Python      |      | ?    |               |         |\n",
    "| [ITensor](https://github.com/ITensor/ITensor)                                           | TensorTrain                       | D, BS      | C, G     | C++, Julia       | +    |      | +             |         |\n",
    "| [multiway](https://cran.r-project.org/web/packages/multiway/index.html)                 | CP, Tucker, Other                 | D          | C        | R                |      | ?    |               |         |\n",
    "| [N-way toolbox](http://www.models.life.ku.dk/nwaytoolbox/download)                      | CP, Tucker, Other                 | D          | C        | Matlab           |      | ?    |               |         |\n",
    "| [ParCube](https://www.cs.ucr.edu/~epapalex/src/parCube.zip)                             | CP                                | S          | C        | Matlab           |      | ?    |               |         |\n",
    "| [ParTensor](https://github.com/neurocom/partensor-toolbox)                              | CP                                | D          | C, G     | C++              | +    |      | +             |         |\n",
    "| [ParTI!](https://github.com/hpcgarage/ParTI)                                            | CP, Tucker                        | S          | C, G     | C, CUDA, Mat     | +    | ?    |               |         |\n",
    "| [PLANC](https://github.com/ramkikannan/planc)                                           | CP                                | S          | C, D     | C++              | +    | ?    |               |         |\n",
    "| [PLS toolbox](https://eigenvector.com/software/pls-toolbox/)                            | CP          , Tucker              | D          | C        | Matlab           |      | ?    |               |         |\n",
    "| [Pytensor](https://code.google.com/archive/p/pytensor/source/default/source)            | Tucker                            | D, S       | C        | Python           |      | ?    |               |         |\n",
    "| [rTensor](https://github.com/jamesyili/rTensor)                                         | CP, Tucker, Other                 | D          | C        | R                | +    |      | +             |         |\n",
    "| [rTensor (randomized)](https://github.com/erichson/rTensor)                             | CP                                | D          | C        | Python           | +    |      | +       +     |         |\n",
    "| [scikit-tensor](https://github.com/mnick/scikit-tensor)                                 | CP, Tucker, Other                 | D, S       | C        | Python           | +    | +    | +    +   +    |         |\n",
    "| [Scikit-TT](https://github.com/PGelss/scikit_tt)                                        | TensorTrain                       | D          | C        | Python           | +    |      | +    +   +    |         |\n",
    "| [SPALS](https://github.com/dehuacheng/SpAls)                                            | CP                                | S          | C        | C++              | +    | ?    |               |         |\n",
    "| [SPARTan](https://github.com/kperros/SPARTan)                                           | Other                             | S          | C        | Matlab           | +    | ?    |               |         |\n",
    "| [SPLATT](https://github.com/ShadenSmith/splatt)                                         | CP                                | S          | C, D     | C, C++, Oct, Mat | +    | ?    |               |         |\n",
    "| [SuSMoST](https://susmost.com/downloads.html)                                           | TensorTrain, Other                | D          | C        | Python           |      | ?    |               |         |\n",
    "| [T3F](https://github.com/Bihaqo/t3f)                                                    | TensorTrain                       | D          | C, G     | Python           | +    | +    | +    + +      |         |\n",
    "| [TDALAB](https://github.com/andrewssobral/TDALAB)                                       | CP                                | D, S       | C        | Python, Matlab   | +    |      | +         +   |         |\n",
    "| [TeNPy](https://github.com/tenpy/tenpy)                                        | TensorTrain                       | D          | C        | Python           | +    | +    | +      + +    |         |\n",
    "| [Tensor Fox](https://github.com/felipebottega/Tensor-Fox)                               | CP                                | D, S       | C        | Python, Matlab   | +    | +    | +    + +      |         |\n",
    "| [Tensor package](http://www.gipsa-lab.fr/~pierre.comon/TensorPackage/tensorPackage.html) | CP                                | D          | C        | Matlab           |      | ?    |               |         |\n",
    "| [Tensor Toolbox](https://gitlab.com/tensors/tensor_toolbox)                             | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +             |         |\n",
    "| [tensor_decomposition](https://github.com/cyclops-community/tensor_decomposition)       | CP, Tucker                        | D          | C, D     | Python           | +    |      | +        +    |         |\n",
    "| [TensorBox](https://github.com/phananhhuy/TensorBox)                                    | CP, Tucker, Other                 | D, S       | C        | Matlab           | +    |      | +             |         |\n",
    "| [TensorD](https://github.com/Large-Scale-Tensor-Decomposition/tensorD)                  | CP, Tucker                        | D          | C, G     | Python           | ?    | ?    |               |         |\n",
    "| [TensorLab](https://www.tensorlab.net)                                                  | CP, Tucker, Other                 | D, S       | C        | Matlab           |      | ?    |               |         |\n",
    "| [TensorLab+](https://www.tensorlabplus.net)                                             | CP, Other                         | D, S       | C        | Matlab           |      | ?    |               |         |\n",
    "| [TensorLy](https://github.com/tensorly/tensorly)                                        | CP, Tucker, TensorTrain, Other    | D          | C, G     | Python           | +    | +    | +       + +   |         |\n",
    "| [Three-Way](https://github.com/cran/ThreeWay)                                           | CP, Tucker                        | D          | C        | R                | +    |      | +             |         |\n",
    "| [TNR](https://github.com/ycyuustc/matlab)                                               | Other                             | D          | C        | Matlab           | +    |      | +             |         |\n",
    "| [TT-Toolbox](https://github.com/oseledets/TT-Toolbox)                                   | TensorTrain                       | D          | C, D, G  | Matlab, Python   | +    |      | +       +     |         |\n",
    "| [xerus](https://git.hemio.de/xerus/xerus/)                                              | TensorTrain                       | D, S       | C        | C++              | +    |      | +             |         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use SVD to reconstruct the video\n",
    "\n",
    "just simple implementation with SVD by scipy lib as baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Some functions to do it"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.588696Z",
     "start_time": "2024-09-26T21:30:04.579933Z"
    }
   },
   "source": [
    "def apply_and_reconstruct_svd(video_frames, svd_rank=None):\n",
    "    gc.collect()\n",
    "\n",
    "    started_memory = get_current_rss_memory(is_mb=True)\n",
    "\n",
    "    reconstructed_frames = []\n",
    "    compression_ratios = []\n",
    "    frobenius_errors = []\n",
    "    decomposition_times = []\n",
    "    max_memory = 0.0\n",
    "\n",
    "    for frame in tqdm(video_frames, desc=\"Applying SVD and Reconstructing\", unit=\"frame\"):\n",
    "        channels = cv2.split(frame)\n",
    "        reconstructed_channels = []\n",
    "\n",
    "        for channel in channels:\n",
    "            durations = []\n",
    "\n",
    "            for _ in range(10):\n",
    "                start = time.time()\n",
    "                u, s, v_t = svd(channel, full_matrices=True)\n",
    "                duration = time.time() - start\n",
    "                durations.append(duration)\n",
    "            duration = np.mean(durations)\n",
    "\n",
    "            if svd_rank:\n",
    "                u = u[:, :svd_rank]\n",
    "                s = s[:svd_rank]\n",
    "                v_t = v_t[:svd_rank, :]\n",
    "\n",
    "            s_matrix = np.diag(s)\n",
    "            reconstructed_channel = np.dot(u, np.dot(s_matrix, v_t))\n",
    "            reconstructed_channels.append(reconstructed_channel)\n",
    "\n",
    "            # Calculate metrics\n",
    "            original_memory = memory(channel)\n",
    "            compressed_memory = memory(u, s_matrix, v_t)\n",
    "            compression_ratio = 100.0 * compressed_memory / original_memory\n",
    "            frobenius_error = np.linalg.norm(channel - reconstructed_channel) / np.linalg.norm(channel)\n",
    "\n",
    "            compression_ratios.append(compression_ratio)\n",
    "            frobenius_errors.append(frobenius_error)\n",
    "            decomposition_times.append(duration)\n",
    "\n",
    "        reconstructed_frame = cv2.merge(reconstructed_channels)\n",
    "        reconstructed_frames.append(reconstructed_frame)\n",
    "\n",
    "        max_memory = max(max_memory, get_current_rss_memory(is_mb=True) - started_memory)\n",
    "\n",
    "    metrics = {\n",
    "        \"compression_ratio\": np.sum(compression_ratios),\n",
    "        \"frobenius_error\": np.sum(frobenius_errors),\n",
    "        \"decomposition_time_sec\": np.sum(decomposition_times),\n",
    "        \"max_memory_MiB\": max_memory,\n",
    "    }\n",
    "\n",
    "    return np.array(reconstructed_frames, dtype=np.uint8), metrics"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Params"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-26T21:30:04.607351Z",
     "start_time": "2024-09-26T21:30:04.602756Z"
    }
   },
   "source": [
    "svd_rank = 30\n",
    "\n",
    "method_logs = MethodLogs(method_name=\"SVD\", method_args={\"svd_rank\": svd_rank})\n",
    "method_logs.qualitative_metrics = {\"deps to implement\": [\"python\", \"opencv-python\", \"numpy\"]}\n",
    "\n",
    "method_logs_list.append(method_logs)"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Check how functions work"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-26T21:30:04.638884Z"
    }
   },
   "source": [
    "reconstruct_frames_from_svd, metrics = apply_and_reconstruct_svd(video_frames, svd_rank=svd_rank)\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SVD and Reconstructing:   2%|▏         | 7/440 [00:11<12:51,  1.78s/frame]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:56:08.568527Z",
     "start_time": "2024-09-26T20:56:08.563002Z"
    }
   },
   "outputs": [],
   "source": [
    "method_logs.quantitative_metrics = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "### Check reconstructed video"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:56:08.633226Z",
     "start_time": "2024-09-26T20:56:08.629131Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for frame in reconstruct_frames_from_svd:\n",
    "#     cv2.imshow('Reconstructed Video', frame)\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:56:08.661027Z",
     "start_time": "2024-09-26T20:56:08.657214Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "{'svd_rank': 30}\n",
      "{'compression_ratio': np.float64(32237.62376237623), 'frobenius_error': np.float64(67.3504829205391), 'decomposition_time_sec': np.float64(24.404303789138794), 'max_memory_MiB': 371.2421875}\n",
      "{'deps to implement': ['python', 'opencv-python', 'numpy']}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    method_logs_list[0].name, method_logs_list[0].method_args, method_logs_list[0].quantitative_metrics, method_logs_list[0].qualitative_metrics, sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:56:08.734142Z",
     "start_time": "2024-09-26T20:56:08.730745Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
