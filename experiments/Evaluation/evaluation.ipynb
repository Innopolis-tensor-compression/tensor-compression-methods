{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:49.987560Z",
     "start_time": "2025-04-08T12:20:47.600304Z"
    }
   },
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "from copy import deepcopy\n",
    "from timeit import timeit\n",
    "from flopco import FlopCo\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.model_compressor.model_compressor import compress_model\n",
    "\n",
    "from torchvision.models import (resnet18, ResNet18_Weights,\n",
    "                                resnet34, ResNet34_Weights,\n",
    "                                resnet50, ResNet50_Weights,\n",
    "                                resnet101, ResNet101_Weights,\n",
    "                                resnet152, ResNet152_Weights,\n",
    "                                vgg11, VGG11_Weights,\n",
    "                                vgg13, VGG13_Weights,\n",
    "                                vgg16, VGG16_Weights,\n",
    "                                vgg19, VGG19_Weights,\n",
    "                                mobilenet_v2, MobileNet_V2_Weights,\n",
    "                                mobilenet_v3_large, MobileNet_V3_Large_Weights,\n",
    "                                mobilenet_v3_small, MobileNet_V3_Small_Weights,\n",
    "                                efficientnet_b0, EfficientNet_B0_Weights,\n",
    "                                efficientnet_b1, EfficientNet_B1_Weights,\n",
    "                                efficientnet_b2, EfficientNet_B2_Weights,\n",
    "                                efficientnet_b3, EfficientNet_B3_Weights,\n",
    "                                efficientnet_b4, EfficientNet_B4_Weights\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:51.210914Z",
     "start_time": "2025-04-08T12:20:49.999904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "def load_synset_mapping(mapping_file):\n",
    "    \"\"\"\n",
    "    Load the synset mapping from LOC_synset_mapping.txt.\n",
    "    Each line should be formatted as:\n",
    "        n01440764 tench, Tinca tinca\n",
    "    The order of lines defines the class index.\n",
    "    Returns a dict mapping synset id to an integer index (zero-indexed).\n",
    "    \"\"\"\n",
    "    synset2idx = {}\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            parts = line.strip().split()\n",
    "            if parts:\n",
    "                synset = parts[0]\n",
    "                synset2idx[synset] = idx\n",
    "    return synset2idx\n",
    "\n",
    "def load_annotations(csv_file, synset2idx):\n",
    "    \"\"\"\n",
    "    Load annotations from a CSV file (either LOC_train_solution.csv or LOC_val_solution.csv).\n",
    "    Each row should contain:\n",
    "         ImageId, PredictionString\n",
    "    The first token in PredictionString is assumed to be the synset id.\n",
    "    Returns a dictionary mapping the image id (without extension) to its integer label.\n",
    "    \"\"\"\n",
    "    annotations = {}\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        # If the header isn't as expected, rewind\n",
    "        if header[0] != \"ImageId\":\n",
    "            f.seek(0)\n",
    "            reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "            image_id = row[0].strip()\n",
    "            pred_tokens = row[1].split()\n",
    "            if pred_tokens:\n",
    "                synset = pred_tokens[0].strip()\n",
    "                if synset in synset2idx:\n",
    "                    annotations[image_id] = synset2idx[synset]\n",
    "    return annotations\n",
    "\n",
    "class ImageNetCLS(Dataset):\n",
    "    def __init__(self, root, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Root directory containing ILSVRC, e.g. '/path/to/ILSVRC'\n",
    "            split (str): One of 'train', 'val', or 'test'\n",
    "            transform (callable, optional): Transformations to apply to the images.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split.lower()\n",
    "        self.transform = transform if transform is not None else transforms.ToTensor()\n",
    "\n",
    "        # Load the synset mapping file\n",
    "        mapping_path = os.path.join(root, \"LOC_synset_mapping.txt\")\n",
    "        self.synset2idx = load_synset_mapping(mapping_path)\n",
    "\n",
    "        # Define the base folder for images\n",
    "        base_img_folder = os.path.join(root, \"Data\", \"CLS-LOC\", self.split)\n",
    "        if not os.path.isdir(base_img_folder):\n",
    "            raise RuntimeError(f\"Expected folder {base_img_folder} not found.\")\n",
    "\n",
    "        self.samples = []  # List of (image_path, label) tuples\n",
    "\n",
    "        if self.split == 'train':\n",
    "            # In train, images are stored in subfolders named after the synset.\n",
    "            for synset_folder in os.listdir(base_img_folder):\n",
    "                synset_path = os.path.join(base_img_folder, synset_folder)\n",
    "                if not os.path.isdir(synset_path):\n",
    "                    continue\n",
    "                # Skip folders not in the synset mapping\n",
    "                if synset_folder not in self.synset2idx:\n",
    "                    continue\n",
    "                label = self.synset2idx[synset_folder]\n",
    "                for fname in os.listdir(synset_path):\n",
    "                    if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                        img_path = os.path.join(synset_path, fname)\n",
    "                        self.samples.append((img_path, label))\n",
    "        elif self.split in ['val', 'test']:\n",
    "            # For val and test, images are directly in the folder.\n",
    "            # For validation, we use the corresponding CSV to obtain labels.\n",
    "            annotations = {}\n",
    "            if self.split == 'val':\n",
    "                csv_file = os.path.join(root, \"LOC_val_solution.csv\")\n",
    "                annotations = load_annotations(csv_file, self.synset2idx)\n",
    "            for fname in os.listdir(base_img_folder):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                    base_name, _ = os.path.splitext(fname)\n",
    "                    img_path = os.path.join(base_img_folder, fname)\n",
    "                    # For validation, only include images that have an annotation.\n",
    "                    if self.split == 'val':\n",
    "                        if base_name in annotations:\n",
    "                            label = annotations[base_name]\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        # For test, no label is available. Use a dummy label.\n",
    "                        label = -1\n",
    "                    self.samples.append((img_path, label))\n",
    "        else:\n",
    "            raise ValueError(\"split must be one of 'train', 'val', or 'test'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define any transforms (resize, normalization, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.256, 0.232, 0.181),(0.458, 0.448, 0.45))\n",
    "])\n",
    "# Path to your ILSVRC directory\n",
    "root_dir = '/home/aleksandr-vashchenko/Desktop/Thesis/tensor-compression-methods/experiments/Evaluation/archive/ILSVRC'\n",
    "# Training dataset\n",
    "train_dataset = ImageNetCLS(root=root_dir, split='train', transform=transform)\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "# Validation dataset\n",
    "val_dataset = ImageNetCLS(root=root_dir, split='val', transform=transform)\n",
    "print(\"Number of validation samples:\", len(val_dataset))\n",
    "# Test dataset (without labels)\n",
    "test_dataset = ImageNetCLS(root=root_dir, split='test', transform=transform)\n",
    "print(\"Number of test samples:\", len(test_dataset))\n",
    "# Retrieve a sample from the training set\n"
   ],
   "id": "3c1ca6037233364e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1281167\n",
      "Number of validation samples: 50000\n",
      "Number of test samples: 100000\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:51.276859Z",
     "start_time": "2025-04-08T12:20:51.260611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_img, sample_label = train_dataset[0]\n",
    "print(\"Sample image size:\", sample_img.size())\n",
    "print(\"Sample label:\", sample_label)\n",
    "sample_img, sample_label = val_dataset[0]\n",
    "print(\"Sample image size:\", sample_img.size())\n",
    "print(\"Sample label:\", sample_label)"
   ],
   "id": "9d0dcd36a6bbc846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image size: torch.Size([3, 224, 224])\n",
      "Sample label: 984\n",
      "Sample image size: torch.Size([3, 224, 224])\n",
      "Sample label: 786\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:51.352931Z",
     "start_time": "2025-04-08T12:20:51.308299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters for compression\n",
    "compression_params = {\n",
    "    'layers': [torch.nn.Conv2d, torch.nn.ConvTranspose2d],\n",
    "    'conv_compression_method': 'TKD',\n",
    "    'conv_transpose_compression_method': 'TKD',\n",
    "    'finetune': False,\n",
    "    'optimizer': AdamW,\n",
    "    'data_size': [3, 224, 224],\n",
    "    'lr': 0.001,\n",
    "    'loss_function': CrossEntropyLoss,\n",
    "    'finetune_device': device,\n",
    "    'task': 'classification',\n",
    "}\n",
    "\n",
    "# Functions to load models\n",
    "models = [\n",
    "    (resnet18, ResNet18_Weights.IMAGENET1K_V1),\n",
    "    # (resnet34, ResNet34_Weights.IMAGENET1K_V1),\n",
    "    # (resnet50, ResNet50_Weights.IMAGENET1K_V1),\n",
    "    # (resnet101, ResNet101_Weights.IMAGENET1K_V1),\n",
    "    # (resnet152, ResNet152_Weights.IMAGENET1K_V1),\n",
    "    # (vgg11, VGG11_Weights.IMAGENET1K_V1),\n",
    "    # (vgg13, VGG13_Weights.IMAGENET1K_V1),\n",
    "    # (vgg16, VGG16_Weights.IMAGENET1K_V1),\n",
    "    # (vgg19, VGG19_Weights.IMAGENET1K_V1),\n",
    "    # (mobilenet_v2, MobileNet_V2_Weights.IMAGENET1K_V1),\n",
    "    # (mobilenet_v3_large, MobileNet_V3_Large_Weights.IMAGENET1K_V1),\n",
    "    # (mobilenet_v3_small, MobileNet_V3_Small_Weights.IMAGENET1K_V1),\n",
    "    # (efficientnet_b0, EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
    "    # (efficientnet_b1, EfficientNet_B1_Weights.IMAGENET1K_V1),\n",
    "    # (efficientnet_b2, EfficientNet_B2_Weights.IMAGENET1K_V1),\n",
    "    # (efficientnet_b3, EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
    "    # (efficientnet_b4, EfficientNet_B4_Weights.IMAGENET1K_V1),\n",
    "]"
   ],
   "id": "36ad6d490d15b379",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:51.399447Z",
     "start_time": "2025-04-08T12:20:51.396235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_top1_top5(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided dataloader and computes top-1 and top-5 accuracy.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained PyTorch model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "        device (torch.device): The device on which to run the evaluation (e.g., \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        (top1_acc, top5_acc): Tuple of top-1 and top-5 accuracy in percentage.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)  # Shape: (batch_size, num_classes)\n",
    "\n",
    "            # Get top 1 prediction.\n",
    "            _, pred_top1 = outputs.topk(1, dim=1, largest=True, sorted=True)\n",
    "            # Get top 5 predictions.\n",
    "            _, pred_top5 = outputs.topk(5, dim=1, largest=True, sorted=True)\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            # Check top-1: squeeze pred_top1 from (batch_size, 1) to (batch_size)\n",
    "            top1_correct += (pred_top1.squeeze(1) == labels).sum().item()\n",
    "\n",
    "            # For top-5, check whether the true label is among the top-5 predictions for each sample.\n",
    "            # pred_top5: shape (batch_size, 5)\n",
    "            # labels: shape (batch_size,) -> unsqueeze to (batch_size, 1) to compare.\n",
    "            top5_correct += (pred_top5.eq(labels.view(-1, 1)).sum(dim=1) > 0).sum().item()\n",
    "\n",
    "    top1_acc = 100.0 * top1_correct / total_samples\n",
    "    top5_acc = 100.0 * top5_correct / total_samples\n",
    "    return top1_acc, top5_acc"
   ],
   "id": "6edaa54196bb36b1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:51.452511Z",
     "start_time": "2025-04-08T12:20:51.448728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def performance_test(model, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=True):\n",
    "            model(input_tensor)\n",
    "\n",
    "def evaluate_compressed_model(original_model, compressed_model):\n",
    "    # Set models to evaluation mode\n",
    "    model1 = original_model.to(device).eval()\n",
    "    model2 = compressed_model.to(device).eval()\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "    top1_acc_orig, top5_acc_orig = evaluate_top1_top5(model1, val_dataloader, device)\n",
    "    top1_acc_comp, top5_acc_comp = evaluate_top1_top5(model2, val_dataloader, device)\n",
    "\n",
    "    print(f\"Top-1 Accuracy (original): {top1_acc_orig:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy (original): {top5_acc_orig:.2f}%\")\n",
    "    print(f\"Top-1 Accuracy (compressed): {top1_acc_comp:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy (compressed): {top5_acc_comp:.2f}%\")\n",
    "    flopco_stats_original = FlopCo(model1, device=device)\n",
    "    flopco_stats_compressed = FlopCo(model2, device=device)\n",
    "\n",
    "    print(f'FLOPs: {flopco_stats_original.total_flops}')\n",
    "    print(f'Parameters: {flopco_stats_original.total_params}')\n",
    "    print(f'Total macs: {flopco_stats_original.total_macs}')\n",
    "\n",
    "    print(f'FLOPs (compressed): {flopco_stats_compressed.total_flops}')\n",
    "    print(f'Parameters (compressed): {flopco_stats_compressed.total_params}')\n",
    "    print(f'Total macs (compressed): {flopco_stats_compressed.total_macs}')\n",
    "\n",
    "    print(f'Compression Ratio: {flopco_stats_original.total_params / flopco_stats_compressed.total_params:.2f}')\n",
    "    print(f'Compression Ratio (FLOPs): {flopco_stats_original.total_flops / flopco_stats_compressed.total_flops:.2f}')\n",
    "    print(f'Compression Ratio (macs): {flopco_stats_original.total_macs / flopco_stats_compressed.total_macs:.2f}')\n",
    "\n",
    "\n",
    "    # Measure performance\n",
    "    input_tensor = torch.randn(64, 3, 224, 224).to(device)\n",
    "    time_original = timeit(lambda: performance_test(model1, input_tensor), number=1000)\n",
    "    time_compressed = timeit(lambda: performance_test(model2, input_tensor), number=1000)\n",
    "\n",
    "    return top1_acc_orig, top5_acc_orig, top1_acc_comp, top5_acc_comp, flopco_stats_original, flopco_stats_compressed, time_original, time_compressed"
   ],
   "id": "d6d62a773ffa9920",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:20:51.496995Z",
     "start_time": "2025-04-08T12:20:51.493594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def finetune(model):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=0.01)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "    # Initialize variables for loss tracking\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    # Create tqdm progress bar\n",
    "    pbar = tqdm(train_dataloader)\n",
    "\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(enabled=True, device_type='cuda', dtype=torch.bfloat16):\n",
    "            outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update loss statistics\n",
    "        current_loss = loss.item()\n",
    "        running_loss += current_loss\n",
    "        batch_count += 1\n",
    "        avg_loss = running_loss / batch_count\n",
    "\n",
    "        # Update tqdm with current and average loss\n",
    "        pbar.set_postfix({'loss': f'{current_loss:.4f}', 'avg_loss': f'{avg_loss:.4f}'})\n",
    "\n",
    "    return model"
   ],
   "id": "b8fa2ab5cc43764a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:31:22.409932Z",
     "start_time": "2025-04-08T12:26:24.073876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model_func, weights in models:\n",
    "    print(f\"Loading model: {model_func.__name__}\")\n",
    "    original_model = model_func(weights=weights)\n",
    "    compressed_model = deepcopy(original_model)\n",
    "    compress_model(compressed_model, **compression_params)\n",
    "\n",
    "    # compressed_model = finetune(compressed_model)\n",
    "\n",
    "    top1_acc_orig, top5_acc_orig, top1_acc_comp, top5_acc_comp, stats_original, stats_compressed, time_original, time_compressed = evaluate_compressed_model(original_model, compressed_model)\n",
    "    results = {\n",
    "        'model': model_func.__name__,\n",
    "        'top1_acc_orig': top1_acc_orig,\n",
    "        'top5_acc_orig': top5_acc_orig,\n",
    "        'top1_acc_comp': top1_acc_comp,\n",
    "        'top5_acc_comp': top5_acc_comp,\n",
    "        'time_original': time_original,\n",
    "        'time_compressed': time_compressed,\n",
    "        'flopco_stats_original': {\n",
    "            'total_flops': stats_original.total_flops,\n",
    "            'total_params': stats_original.total_params,\n",
    "            'total_macs': stats_original.total_macs,\n",
    "            'flops': stats_original.flops,\n",
    "            'macs': stats_original.macs,\n",
    "            'params': stats_original.params,\n",
    "            'relative_flops': stats_original.relative_flops,\n",
    "            'relative_macs': stats_original.relative_macs,\n",
    "            'relative_params': stats_original.relative_params,\n",
    "        },\n",
    "        'flopco_stats_compressed': {\n",
    "            'total_flops': stats_compressed.total_flops,\n",
    "            'total_params': stats_compressed.total_params,\n",
    "            'total_macs': stats_compressed.total_macs,\n",
    "            'flops': stats_compressed.flops,\n",
    "            'macs': stats_compressed.macs,\n",
    "            'params': stats_compressed.params,\n",
    "            'relative_flops': stats_compressed.relative_flops,\n",
    "            'relative_macs': stats_compressed.relative_macs,\n",
    "            'relative_params': stats_compressed.relative_params,\n",
    "        },\n",
    "        'compression_ratio': {\n",
    "            'params': stats_original.total_params / stats_compressed.total_params,\n",
    "            'flops': stats_original.total_flops / stats_compressed.total_flops,\n",
    "            'macs': stats_original.total_macs / stats_compressed.total_macs,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Append results to a JSON file\n",
    "    try:\n",
    "        with open('./results4.json', 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        existing_results = []\n",
    "\n",
    "    existing_results.append(results)\n",
    "\n",
    "    with open('./results4.json', 'w+') as f:\n",
    "        json.dump(existing_results, f, indent=4)\n",
    "\n",
    "    torch.save(compressed_model, f\"./models/{model_func.__name__}.pt\")\n",
    "\n",
    "    del compressed_model, original_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "41b35665d663a217",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: resnet18\n",
      "differential_evolution step 1: f(x)= 0.1024243990231649\n",
      "differential_evolution step 2: f(x)= 0.10055490507503358\n",
      "differential_evolution step 3: f(x)= 0.10055490507503358\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.21672756172293045\n",
      "differential_evolution step 2: f(x)= 0.21672756172293045\n",
      "differential_evolution step 3: f(x)= 0.21384909107197783\n",
      "differential_evolution step 4: f(x)= 0.2137928952114772\n",
      "differential_evolution step 5: f(x)= 0.2112575950891102\n",
      "differential_evolution step 6: f(x)= 0.2112575950891102\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.32625396735710693\n",
      "differential_evolution step 2: f(x)= 0.32625396735710693\n",
      "differential_evolution step 3: f(x)= 0.32284515316194556\n",
      "differential_evolution step 4: f(x)= 0.32210522404514313\n",
      "differential_evolution step 5: f(x)= 0.32210522404514313\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.3351041842044772\n",
      "differential_evolution step 2: f(x)= 0.32805617183851155\n",
      "differential_evolution step 3: f(x)= 0.32805617183851155\n",
      "differential_evolution step 4: f(x)= 0.32805617183851155\n",
      "differential_evolution step 5: f(x)= 0.3267182789912149\n",
      "differential_evolution step 6: f(x)= 0.32641746225271295\n",
      "differential_evolution step 7: f(x)= 0.32641746225271295\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.39667406758145035\n",
      "differential_evolution step 2: f(x)= 0.3799923144450113\n",
      "differential_evolution step 3: f(x)= 0.3794081970206704\n",
      "differential_evolution step 4: f(x)= 0.3794081970206704\n",
      "differential_evolution step 5: f(x)= 0.3794081970206704\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.33400401291351567\n",
      "differential_evolution step 2: f(x)= 0.33074313700153707\n",
      "differential_evolution step 3: f(x)= 0.3289986881536057\n",
      "differential_evolution step 4: f(x)= 0.32879332760869867\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.3728244827208296\n",
      "differential_evolution step 2: f(x)= 0.34834896149549555\n",
      "differential_evolution step 3: f(x)= 0.3376798963441371\n",
      "differential_evolution step 4: f(x)= 0.33488310305147595\n",
      "differential_evolution step 5: f(x)= 0.33463834670259174\n",
      "differential_evolution step 6: f(x)= 0.33417252941300385\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.46436429023742676\n",
      "differential_evolution step 2: f(x)= 0.45474886894226074\n",
      "differential_evolution step 3: f(x)= 0.45474886894226074\n",
      "differential_evolution step 4: f(x)= 0.45474886894226074\n",
      "differential_evolution step 5: f(x)= 0.45474886894226074\n",
      "differential_evolution step 6: f(x)= 0.45474886894226074\n",
      "differential_evolution step 7: f(x)= 0.45474886894226074\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.3732771895777033\n",
      "differential_evolution step 2: f(x)= 0.3711665266171731\n",
      "differential_evolution step 3: f(x)= 0.3711665266171731\n",
      "differential_evolution step 4: f(x)= 0.3711665266171731\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.42976778017967654\n",
      "differential_evolution step 2: f(x)= 0.3970502808399361\n",
      "differential_evolution step 3: f(x)= 0.3970502808399361\n",
      "differential_evolution step 4: f(x)= 0.3965892849038367\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.32430125245813946\n",
      "differential_evolution step 2: f(x)= 0.32333348156063\n",
      "differential_evolution step 3: f(x)= 0.3193841667286853\n",
      "differential_evolution step 4: f(x)= 0.3178953776370823\n",
      "differential_evolution step 5: f(x)= 0.3178953776370823\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.36127123723141286\n",
      "differential_evolution step 2: f(x)= 0.36127123723141286\n",
      "differential_evolution step 3: f(x)= 0.3597386463252424\n",
      "differential_evolution step 4: f(x)= 0.35716157500850565\n",
      "differential_evolution step 5: f(x)= 0.3565611373170395\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.6227371692657471\n",
      "differential_evolution step 2: f(x)= 0.5665958896279335\n",
      "differential_evolution step 3: f(x)= 0.5581416860222816\n",
      "differential_evolution step 4: f(x)= 0.5573984086513519\n",
      "differential_evolution step 5: f(x)= 0.5545987579971552\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.3776466005905212\n",
      "differential_evolution step 2: f(x)= 0.3736879083954935\n",
      "differential_evolution step 3: f(x)= 0.3708878366744767\n",
      "differential_evolution step 4: f(x)= 0.3708878366744767\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.3883864977237333\n",
      "differential_evolution step 2: f(x)= 0.3804248865013024\n",
      "differential_evolution step 3: f(x)= 0.3804248865013024\n",
      "differential_evolution step 4: f(x)= 0.3779424856885452\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.35366060912314984\n",
      "differential_evolution step 2: f(x)= 0.34742916506019433\n",
      "differential_evolution step 3: f(x)= 0.34593918745955243\n",
      "differential_evolution step 4: f(x)= 0.34553617804401426\n",
      "differential_evolution step 5: f(x)= 0.34553617804401426\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.41877502372871356\n",
      "differential_evolution step 2: f(x)= 0.4130988182010319\n",
      "differential_evolution step 3: f(x)= 0.41267420460339227\n",
      "differential_evolution step 4: f(x)= 0.41207853144192674\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.6045874729752541\n",
      "differential_evolution step 2: f(x)= 0.6045874729752541\n",
      "differential_evolution step 3: f(x)= 0.5930195586988702\n",
      "differential_evolution step 4: f(x)= 0.49045355059206486\n",
      "differential_evolution step 5: f(x)= 0.49045355059206486\n",
      "differential_evolution step 6: f(x)= 0.49045355059206486\n",
      "differential_evolution step 7: f(x)= 0.4883751372108236\n",
      "differential_evolution step 8: f(x)= 0.48714042641222477\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.3857473677441289\n",
      "differential_evolution step 2: f(x)= 0.3831703584580216\n",
      "differential_evolution step 3: f(x)= 0.38122239933670204\n",
      "differential_evolution step 4: f(x)= 0.3811156792119611\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "differential_evolution step 1: f(x)= 0.23177847212372646\n",
      "differential_evolution step 2: f(x)= 0.2102832737973149\n",
      "differential_evolution step 3: f(x)= 0.2102832737973149\n",
      "differential_evolution step 4: f(x)= 0.20941107882818227\n",
      "differential_evolution step 5: f(x)= 0.20941107882818227\n",
      "Polishing solution with 'L-BFGS-B'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:29<00:00, 26.58it/s]\n",
      "100%|██████████| 782/782 [00:34<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy (original): 62.22%\n",
      "Top-5 Accuracy (original): 84.41%\n",
      "Top-1 Accuracy (compressed): 41.40%\n",
      "Top-5 Accuracy (compressed): 66.99%\n",
      "FLOPs: 3628147200\n",
      "Parameters: 11679912\n",
      "Total macs: 1814073344\n",
      "FLOPs (compressed): 2531191256\n",
      "Parameters (compressed): 8137570\n",
      "Total macs (compressed): 1265595372\n",
      "Compression Ratio: 1.44\n",
      "Compression Ratio (FLOPs): 1.43\n",
      "Compression Ratio (macs): 1.43\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:22:56.946523Z",
     "start_time": "2025-04-08T11:22:56.809185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compressed_model = torch.load(\"./models/resnet18.pt\")\n",
    "original_model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).to(device)\n",
    "data = val_dataset[0][0].to(device).unsqueeze(0)"
   ],
   "id": "a6b388bc87402907",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_354489/2321198882.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  compressed_model = torch.load(\"./models/resnet18.pt\")\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:22:57.503214Z",
     "start_time": "2025-04-08T11:22:57.500948Z"
    }
   },
   "cell_type": "code",
   "source": "a = deepcopy(original_model.conv1).cpu()",
   "id": "951142da1644199f",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:00.581545Z",
     "start_time": "2025-04-08T11:22:57.856072Z"
    }
   },
   "cell_type": "code",
   "source": "b = compress_model(a, conv_compression_method=\"TKDCPD\")",
   "id": "e95ff350dadb1798",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 0.14084371329445\n",
      "differential_evolution step 2: f(x)= 0.10055490507503358\n",
      "differential_evolution step 3: f(x)= 0.10055490507503358\n",
      "differential_evolution step 4: f(x)= 0.10055490507503358\n",
      "differential_evolution step 5: f(x)= 0.10055490507503358\n",
      "Polishing solution with 'L-BFGS-B'\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:00.587527Z",
     "start_time": "2025-04-08T11:23:00.584775Z"
    }
   },
   "cell_type": "code",
   "source": "a_result = a.to(device)(data)",
   "id": "2b702e797624efb",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:00.635255Z",
     "start_time": "2025-04-08T11:23:00.629755Z"
    }
   },
   "cell_type": "code",
   "source": "b_result = b.to(device)(data)",
   "id": "c73732857c515484",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:00.682272Z",
     "start_time": "2025-04-08T11:23:00.679203Z"
    }
   },
   "cell_type": "code",
   "source": "torch.mean(torch.abs(a_result - b_result))",
   "id": "17a190fd45d5480a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1434, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:00.729109Z",
     "start_time": "2025-04-08T11:23:00.725723Z"
    }
   },
   "cell_type": "code",
   "source": "torch.mean(a_result)",
   "id": "51916b4888f943c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:00.775282Z",
     "start_time": "2025-04-08T11:23:00.772022Z"
    }
   },
   "cell_type": "code",
   "source": "torch.mean(b_result)",
   "id": "f80b079ae7428e56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:01.241945Z",
     "start_time": "2025-04-08T11:23:01.234371Z"
    }
   },
   "cell_type": "code",
   "source": "a_result",
   "id": "d47d9274d4a602c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.9331e-01,  1.1938e+00,  1.1811e+00,  ...,  5.9311e-01,\n",
       "            5.1131e-01,  4.1525e-01],\n",
       "          [ 1.0666e-01,  9.5170e-02, -1.6279e-02,  ...,  3.7675e-02,\n",
       "            1.3672e-02, -8.3489e-04],\n",
       "          [-5.1655e-02, -4.4190e-02, -4.9251e-02,  ...,  3.2046e-02,\n",
       "            8.4421e-03, -2.0382e-02],\n",
       "          ...,\n",
       "          [-9.7974e-02, -6.0040e-02, -9.7559e-02,  ..., -1.5516e-01,\n",
       "           -1.1645e-01, -4.2491e-02],\n",
       "          [-1.5003e-02, -1.9886e-02, -1.0525e-01,  ...,  3.8734e-02,\n",
       "            5.5388e-02,  1.0540e-02],\n",
       "          [ 1.2019e+00,  1.2985e+00,  1.2867e+00,  ...,  1.0002e+00,\n",
       "            1.1296e+00,  6.1471e-01]],\n",
       "\n",
       "         [[ 1.1954e+00,  1.8428e+00,  1.8801e+00,  ...,  1.0175e+00,\n",
       "            9.3251e-01,  7.1561e-01],\n",
       "          [-1.7345e-01,  3.1996e-01,  3.6642e-01,  ...,  2.6724e-01,\n",
       "            2.1353e-01,  3.0953e-01],\n",
       "          [-2.3716e-01,  1.9480e-01,  2.8675e-01,  ..., -8.6663e-02,\n",
       "            1.4780e-01,  3.0459e-01],\n",
       "          ...,\n",
       "          [-3.1916e-01,  2.2204e-01,  3.1048e-01,  ...,  2.0106e-01,\n",
       "            1.8664e-01,  6.9062e-01],\n",
       "          [-2.8214e-01,  2.5549e-01,  3.4055e-01,  ...,  1.7362e-01,\n",
       "            1.6263e-01,  6.8091e-01],\n",
       "          [-3.7440e-01,  2.7556e-01,  5.2131e-01,  ...,  3.1431e-01,\n",
       "            2.2658e-01,  7.7364e-01]],\n",
       "\n",
       "         [[-1.2976e-06, -2.1571e-06, -2.4628e-06,  ..., -1.0900e-06,\n",
       "           -1.0103e-06, -7.2566e-07],\n",
       "          [-1.5061e-06, -2.6161e-06, -2.9858e-06,  ..., -1.1228e-06,\n",
       "           -1.2139e-06, -9.1580e-07],\n",
       "          [-1.2043e-06, -2.2058e-06, -2.4654e-06,  ..., -4.3556e-07,\n",
       "           -7.1755e-07, -7.0038e-07],\n",
       "          ...,\n",
       "          [-1.3283e-06, -2.6164e-06, -3.0655e-06,  ..., -2.3990e-06,\n",
       "           -2.5344e-06, -2.1766e-06],\n",
       "          [-1.3137e-06, -2.6130e-06, -3.0614e-06,  ..., -2.4414e-06,\n",
       "           -2.4802e-06, -2.0808e-06],\n",
       "          [ 1.4025e-07, -4.1574e-07, -5.9044e-07,  ..., -6.1985e-07,\n",
       "           -4.8489e-07, -4.8415e-07]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.1711e-01, -7.9600e-01, -7.2763e-01,  ..., -3.4831e-01,\n",
       "           -3.1423e-01, -2.5837e-01],\n",
       "          [-1.1177e+00, -1.3793e+00, -1.2171e+00,  ..., -5.4271e-01,\n",
       "           -5.1873e-01, -3.7654e-01],\n",
       "          [-1.1736e+00, -1.4250e+00, -1.1527e+00,  ..., -3.3444e-01,\n",
       "           -4.5533e-01, -3.6844e-01],\n",
       "          ...,\n",
       "          [-1.4560e+00, -1.8127e+00, -1.5336e+00,  ..., -1.1403e+00,\n",
       "           -1.3602e+00, -1.4610e+00],\n",
       "          [-1.4461e+00, -1.8097e+00, -1.5455e+00,  ..., -1.1835e+00,\n",
       "           -1.2935e+00, -1.4304e+00],\n",
       "          [-1.0144e+00, -1.3093e+00, -1.1148e+00,  ..., -8.5512e-01,\n",
       "           -9.3523e-01, -8.9915e-01]],\n",
       "\n",
       "         [[ 6.0801e-02,  2.3081e-01,  2.3914e-01,  ...,  1.7184e-01,\n",
       "            1.5595e-01,  1.5700e-01],\n",
       "          [ 6.9453e-02,  6.6058e-01,  7.1243e-01,  ...,  4.4356e-01,\n",
       "            4.0963e-01,  3.9636e-01],\n",
       "          [ 5.5882e-02,  6.5336e-01,  7.1225e-01,  ...,  4.0986e-01,\n",
       "            4.3015e-01,  3.9565e-01],\n",
       "          ...,\n",
       "          [-4.5380e-03,  7.2344e-01,  8.1879e-01,  ...,  6.3454e-01,\n",
       "            5.7882e-01,  9.6922e-01],\n",
       "          [-5.8694e-03,  7.2107e-01,  8.0207e-01,  ...,  6.6246e-01,\n",
       "            6.0631e-01,  9.4843e-01],\n",
       "          [ 5.0314e-02,  8.3832e-01,  9.2128e-01,  ...,  7.5827e-01,\n",
       "            6.5869e-01,  9.2654e-01]],\n",
       "\n",
       "         [[-8.7615e-01,  1.1581e-01,  9.8127e-02,  ...,  1.5183e-01,\n",
       "            8.3784e-02,  2.4168e-01],\n",
       "          [-3.7063e-01,  2.2312e-01,  2.0540e-01,  ...,  7.2996e-02,\n",
       "            1.2499e-01,  8.7215e-02],\n",
       "          [-3.4082e-01,  2.4591e-01,  9.7319e-02,  ...,  4.6267e-02,\n",
       "           -3.4582e-02,  9.2479e-02],\n",
       "          ...,\n",
       "          [-3.9267e-01,  2.7824e-01,  1.1133e-01,  ...,  8.5301e-02,\n",
       "            7.1286e-02,  2.3725e-01],\n",
       "          [-4.1444e-01,  2.6927e-01,  1.0103e-01,  ...,  2.0958e-01,\n",
       "            1.3814e-01,  2.0849e-01],\n",
       "          [ 2.7091e-01,  1.2058e+00,  1.0547e+00,  ...,  9.1684e-01,\n",
       "            6.2831e-01,  1.2929e+00]]]], device='cuda:0',\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:23:01.904979Z",
     "start_time": "2025-04-08T11:23:01.898762Z"
    }
   },
   "cell_type": "code",
   "source": "b_result",
   "id": "b7848f23564f1f45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.9827e-01,  1.1844e+00,  1.2007e+00,  ...,  5.9341e-01,\n",
       "            5.1509e-01,  4.2156e-01],\n",
       "          [ 1.0942e-01,  9.3683e-02,  9.7763e-03,  ...,  3.9626e-02,\n",
       "            1.9725e-02,  1.3329e-02],\n",
       "          [-4.6906e-02, -5.0772e-02, -3.3241e-02,  ...,  2.7200e-02,\n",
       "            7.0475e-03, -5.5926e-03],\n",
       "          ...,\n",
       "          [-9.9068e-02, -6.9433e-02, -8.3131e-02,  ..., -1.5844e-01,\n",
       "           -1.1299e-01, -1.2135e-02],\n",
       "          [-1.5742e-02, -2.9500e-02, -9.0643e-02,  ...,  4.4668e-02,\n",
       "            6.1293e-02,  4.4004e-02],\n",
       "          [ 1.1875e+00,  1.2869e+00,  1.2806e+00,  ...,  9.8769e-01,\n",
       "            1.1155e+00,  6.4490e-01]],\n",
       "\n",
       "         [[ 1.1355e+00,  1.7511e+00,  1.8490e+00,  ...,  9.8566e-01,\n",
       "            9.1478e-01,  7.2496e-01],\n",
       "          [-2.4801e-01,  1.6266e-01,  2.5740e-01,  ...,  2.0460e-01,\n",
       "            1.6210e-01,  2.9766e-01],\n",
       "          [-3.5896e-01, -3.5087e-02,  1.0346e-01,  ..., -1.5719e-01,\n",
       "            7.8994e-02,  2.8144e-01],\n",
       "          ...,\n",
       "          [-4.9174e-01, -8.3944e-02,  6.1807e-02,  ...,  8.6418e-03,\n",
       "           -3.8598e-02,  5.2832e-01],\n",
       "          [-4.5391e-01, -5.2764e-02,  9.3713e-02,  ..., -9.3596e-03,\n",
       "           -6.0311e-02,  5.2951e-01],\n",
       "          [-4.9672e-01,  3.6185e-02,  2.8917e-01,  ...,  1.1864e-01,\n",
       "            7.5188e-03,  6.2406e-01]],\n",
       "\n",
       "         [[-2.1269e-06, -2.4927e-06, -2.2762e-06,  ..., -8.0926e-07,\n",
       "           -7.2854e-07, -2.4606e-07],\n",
       "          [-2.8316e-06, -3.4573e-06, -3.2059e-06,  ..., -1.2599e-06,\n",
       "           -1.2886e-06, -6.8006e-07],\n",
       "          [-2.1958e-06, -2.7159e-06, -2.4601e-06,  ..., -7.3903e-07,\n",
       "           -9.7215e-07, -4.8810e-07],\n",
       "          ...,\n",
       "          [-2.5505e-06, -3.3670e-06, -3.2543e-06,  ..., -2.5392e-06,\n",
       "           -2.7099e-06, -2.0051e-06],\n",
       "          [-2.5395e-06, -3.3372e-06, -3.2223e-06,  ..., -2.5354e-06,\n",
       "           -2.6056e-06, -1.9223e-06],\n",
       "          [-8.3029e-07, -1.2854e-06, -1.2415e-06,  ..., -1.0940e-06,\n",
       "           -8.9694e-07, -9.7974e-07]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.0726e-01, -6.7955e-01, -5.6825e-01,  ..., -2.9124e-01,\n",
       "           -2.5505e-01, -2.2696e-01],\n",
       "          [-9.8367e-01, -1.1730e+00, -9.8150e-01,  ..., -4.6779e-01,\n",
       "           -4.3619e-01, -3.1942e-01],\n",
       "          [-9.6805e-01, -1.1306e+00, -8.9113e-01,  ..., -3.1529e-01,\n",
       "           -4.0981e-01, -3.1485e-01],\n",
       "          ...,\n",
       "          [-1.1913e+00, -1.4169e+00, -1.1664e+00,  ..., -9.0544e-01,\n",
       "           -1.0667e+00, -1.1543e+00],\n",
       "          [-1.1808e+00, -1.4141e+00, -1.1766e+00,  ..., -9.2503e-01,\n",
       "           -1.0030e+00, -1.1378e+00],\n",
       "          [-8.7726e-01, -1.0562e+00, -8.8685e-01,  ..., -6.9158e-01,\n",
       "           -7.6375e-01, -6.7025e-01]],\n",
       "\n",
       "         [[ 1.5224e-02,  1.6360e-01,  1.8517e-01,  ...,  1.3810e-01,\n",
       "            1.2710e-01,  1.3090e-01],\n",
       "          [ 3.8299e-02,  5.2693e-01,  5.8184e-01,  ...,  3.7057e-01,\n",
       "            3.4236e-01,  3.3011e-01],\n",
       "          [-2.7548e-02,  4.8970e-01,  5.4695e-01,  ...,  3.2389e-01,\n",
       "            3.4168e-01,  3.1040e-01],\n",
       "          ...,\n",
       "          [-1.0095e-01,  5.2987e-01,  6.2748e-01,  ...,  4.6257e-01,\n",
       "            4.0669e-01,  7.8380e-01],\n",
       "          [-1.0236e-01,  5.2581e-01,  6.1293e-01,  ...,  4.9139e-01,\n",
       "            4.3194e-01,  7.6732e-01],\n",
       "          [-2.1543e-02,  6.7635e-01,  7.6486e-01,  ...,  6.3036e-01,\n",
       "            5.2464e-01,  7.8503e-01]],\n",
       "\n",
       "         [[-8.5031e-01,  1.3129e-01,  1.1606e-01,  ...,  1.4516e-01,\n",
       "            8.2343e-02,  2.2772e-01],\n",
       "          [-3.5761e-01,  2.2559e-01,  2.1410e-01,  ...,  5.7781e-02,\n",
       "            1.1160e-01,  8.0307e-02],\n",
       "          [-3.2036e-01,  2.4273e-01,  1.0658e-01,  ...,  3.6279e-02,\n",
       "           -4.3717e-02,  7.7955e-02],\n",
       "          ...,\n",
       "          [-3.6647e-01,  2.7993e-01,  1.3458e-01,  ...,  9.3319e-02,\n",
       "            8.3284e-02,  2.2644e-01],\n",
       "          [-3.8691e-01,  2.7105e-01,  1.2294e-01,  ...,  2.1467e-01,\n",
       "            1.4900e-01,  2.0473e-01],\n",
       "          [ 2.6987e-01,  1.1820e+00,  1.0266e+00,  ...,  8.8052e-01,\n",
       "            5.9480e-01,  1.2697e+00]]]], device='cuda:0',\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c6a38a1f7e06861"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
