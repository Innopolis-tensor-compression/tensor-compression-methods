{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "415b86a58f1eefa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"src.utils.method_loggers\",\n",
    "    \"src.utils.method_runners\",\n",
    "    \"src.utils.metrics_calculators\",\n",
    "    \"src.utils.tensor_handlers\",\n",
    "    \"src.utils.trackers\",\n",
    "    \"src.utils.video_controller\",\n",
    "    \"src.utils.optimal_rank_finders\",\n",
    "]\n",
    "\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import argrelextrema\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import tensorly as tl\n",
    "from dotenv import load_dotenv\n",
    "from scipy.optimize import OptimizeResult\n",
    "from scipy.optimize import minimize, differential_evolution, shgo\n",
    "\n",
    "from src.utils.image_controller import download_image, extract_image_frames\n",
    "from src.utils.metrics_calculators import IMetricCalculator\n",
    "from src.utils.optimal_rank_finders import (\n",
    "    find_optimal_rank_tensor_train_by_compression_ratio,\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "93fd96fe374eb7ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get tensor",
   "id": "626b5425644480c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cache_dir_image = \"../.cache/image\"\n",
    "\n",
    "image_urls = [\n",
    "    \"https://i.pinimg.com/564x/04/b2/68/04b26838bdd5e2ba54d0144558685bae.jpg\",\n",
    "    \"https://cdnstatic.rg.ru/crop620x412/uploads/images/187/94/47/iStock-644032024.jpg\",\n",
    "    \"https://i.sstatic.net/uQggz.png\",\n",
    "]\n",
    "\n",
    "images = {}"
   ],
   "id": "a2d129f57bead309"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "image_paths = [download_image(image_url, cache_dir_image) for image_url in image_urls]",
   "id": "edd35419372de37f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for image_index, image_path in enumerate(image_paths):\n",
    "    image_frames = extract_image_frames(image_path)\n",
    "\n",
    "    images[f\"image-{image_index}\"] = {\n",
    "        \"image_url\": image_urls[image_index],\n",
    "        \"image_path\": image_path,\n",
    "        \"frames\": image_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"iamge-{image_index} - {image_frames.shape}\")"
   ],
   "id": "5c010beb08c35ab5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tensor_train_args = {\"svd\": \"truncated_svd\"}",
   "id": "5fa3f3a3df6b5e1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tensor_name = \"image-2\"",
   "id": "c6559eb0b69d5ffa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "example_tensor = images[tensor_name][\"frames\"].copy().astype(np.float32)",
   "id": "66e55dddbf0a887d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# func for calculate bounds for tensor train factors",
   "id": "51b1f4234acc1853"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_tt_bounds(shape: tuple | list) -> list:\n",
    "    \"\"\"\n",
    "    Calculate the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : tuple[int, ...] | list[int]\n",
    "        The shape of the tensor as a list or tuple of integers.\n",
    "        Each element represents the size of the tensor along a corresponding dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int]]\n",
    "        A list of rank bounds for the Tensor Train (TT) decomposition.\n",
    "        Each element is a tuple (r_min, r_max), where:\n",
    "        - r_min is always 1.\n",
    "        - r_max is the upper bound for the TT-rank at the corresponding position.\n",
    "\n",
    "    Examples\n",
    "    -------\n",
    "    >>> calculate_tt_bounds((3, 4, 5))\n",
    "    [(1, 1), (1, 3), (1, 12), (1, 1)]\n",
    "    \"\"\"\n",
    "    d = len(shape)\n",
    "    bounds = [(1, 1)]\n",
    "\n",
    "    for k in range(1, d):\n",
    "        prod_left = 1\n",
    "        for i in range(k):\n",
    "            prod_left *= shape[i]\n",
    "\n",
    "        prod_right = 1\n",
    "        for j in range(k, d):\n",
    "            prod_right *= shape[j]\n",
    "\n",
    "        rk_max = min(prod_left, prod_right)\n",
    "        bounds.append((1, rk_max))\n",
    "\n",
    "    bounds.append((1, 1))\n",
    "    return bounds"
   ],
   "id": "5f8a383ad76fde04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# func for calculate optimal initial rank of tensor train",
   "id": "f27f6565d8fba675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Выходит локальный минимум ;c\n",
    "# def calculate_tensor_train_initial_rank(bounds: tuple) -> list[int]:\n",
    "#     return [max(1, round(max_bound / 2)) for min_bound, max_bound in bounds]\n",
    "\n",
    "def calculate_tensor_train_initial_rank(bounds: tuple | list) -> list[int]:\n",
    "    return [min_bound for min_bound, max_bound in bounds]"
   ],
   "id": "968a81a8e244868"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# calculate metrics for the entire search area for example tensor",
   "id": "427f7a98321f8757"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tt_bounds_example_tensor = calculate_tt_bounds(example_tensor.shape)\n",
    "example_tensor_initial_rank = calculate_tensor_train_initial_rank(tt_bounds_example_tensor)\n",
    "\n",
    "print(\n",
    "    tt_bounds_example_tensor,\n",
    "    example_tensor_initial_rank,\n",
    "    sep='\\n'\n",
    ")"
   ],
   "id": "bf32a2ca0f025122"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# target_compression_ratio_for_graphs = 50.0\n",
    "# frobenius_error_coef_for_graphs = 1.0\n",
    "# compression_ratio_coef_for_graphs = 10.0\n",
    "# \n",
    "# rank_ranges = [range(bound[0], bound[1] + 1) for bound in tt_bounds_example_tensor]\n",
    "# \n",
    "# tqdm_iterable = product(*rank_ranges)\n",
    "# tqdm_total = np.prod([len(r) for r in rank_ranges])\n",
    "# \n",
    "# search_area_example_results = {}\n",
    "# \n",
    "# for rank_combination in tqdm(\n",
    "#         iterable=tqdm_iterable, total=tqdm_total, desc=\"Processing Ranks\"\n",
    "# ):\n",
    "#     test_rank = list(rank_combination)\n",
    "#     internal_indices = test_rank[1:-1]\n",
    "# \n",
    "#     try:\n",
    "#         with tl.backend_context(\"pytorch\"):\n",
    "#             example_tensor_cuda = tl.tensor(example_tensor).to(\"cuda\")\n",
    "#             method_result = tl.decomposition.tensor_train(example_tensor_cuda, rank=test_rank, **tensor_train_args)\n",
    "#             tt_factors = method_result\n",
    "#             reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "# \n",
    "#             frobenius_error = (\n",
    "#                     tl.norm(reconstructed_tensor - example_tensor_cuda) / tl.norm(example_tensor_cuda)\n",
    "#             ).item()\n",
    "#             compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(\n",
    "#                 example_tensor_cuda\n",
    "#             )\n",
    "#             compression_penalty = (target_compression_ratio_for_graphs / 100 - compression_ratio) ** 2\n",
    "#             loss_function_result = (\n",
    "#                     frobenius_error_coef_for_graphs * frobenius_error\n",
    "#                     + compression_ratio_coef_for_graphs * compression_penalty\n",
    "#             )\n",
    "# \n",
    "#             search_area_example_results[tuple(internal_indices)] = {\n",
    "#                 \"rank\": test_rank,\n",
    "#                 \"frobenius_error\": frobenius_error,\n",
    "#                 \"compression_ratio\": compression_ratio,\n",
    "#                 \"compression_penalty\": compression_penalty,\n",
    "#                 \"loss_function_result\": loss_function_result,\n",
    "#             }\n",
    "# \n",
    "#             del tt_factors, reconstructed_tensor\n",
    "#     except Exception as e:\n",
    "#         search_area_example_results[tuple(internal_indices)] = {\"rank\": test_rank, \"error\": str(e)}\n",
    "#     finally:\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()"
   ],
   "id": "f339e8ccc35dccaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph of search area",
   "id": "7811549fbb28e032"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# internal_indices = np.array(list(search_area_example_results.keys()))\n",
    "# metrics = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "# \n",
    "# metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "# \n",
    "# figs = []\n",
    "# \n",
    "# for metric in metrics:\n",
    "#     z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "#     x_indices = internal_indices[:, 0]\n",
    "#     y_indices = internal_indices[:, 1]\n",
    "# \n",
    "#     local_min_points = []\n",
    "# \n",
    "#     for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "#         z = z_values[i]\n",
    "# \n",
    "#         neighbors = [\n",
    "#             (x - 1, y), (x + 1, y),\n",
    "#             (x, y - 1), (x, y + 1)\n",
    "#         ]\n",
    "# \n",
    "#         is_local_min = all(\n",
    "#             (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "#             for neighbor in neighbors\n",
    "#         )\n",
    "# \n",
    "#         if is_local_min:\n",
    "#             local_min_points.append((x, y, z))\n",
    "# \n",
    "#     x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "# \n",
    "#     fig = go.Figure()\n",
    "# \n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=x_indices,\n",
    "#         y=y_indices,\n",
    "#         z=z_values,\n",
    "#         mode=\"markers\",\n",
    "#         marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "#         name=metric\n",
    "#     ))\n",
    "# \n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=x_min,\n",
    "#         y=y_min,\n",
    "#         z=z_min,\n",
    "#         mode=\"markers+text\",\n",
    "#         marker={\"size\": 6, \"color\": \"red\", \"symbol\": \"diamond\"},\n",
    "#         text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "#         textposition=\"top center\",\n",
    "#         name=\"Local Minima\"\n",
    "#     ))\n",
    "# \n",
    "#     fig.update_layout(\n",
    "#         title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()}\",\n",
    "#         scene={\n",
    "#             \"xaxis_title\": \"Rank Index 1\",\n",
    "#             \"yaxis_title\": \"Rank Index 2\",\n",
    "#             \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "#             \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))}\n",
    "#         },\n",
    "#         margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "#         template=\"plotly_white\",\n",
    "#         showlegend=False,\n",
    "#     )\n",
    "# \n",
    "#     figs.append(fig)\n",
    "# \n",
    "# html_str = \"\"\n",
    "# for fig in figs:\n",
    "#     html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "# \n",
    "# html_file = f\"\"\"\n",
    "# <!DOCTYPE html>\n",
    "# <html>\n",
    "# <head>\n",
    "#     <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "# </head>\n",
    "# <body>\n",
    "# <h1>Search area by some metrics</h1>\n",
    "# {html_str}\n",
    "# </body>\n",
    "# </html>\n",
    "# \"\"\"\n",
    "# \n",
    "# output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}.html\"\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "#     f.write(html_file)"
   ],
   "id": "85ac1d75df5d5146"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimization algs test",
   "id": "e69117e76cbef0a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## optimize with custom algorithm",
   "id": "23c74370dc54bcbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# start_time = time.perf_counter()\n",
    "# best_rank, compression_ratio, frobenius_error, find_rank_logs = find_optimal_rank_tensor_train_by_compression_ratio(\n",
    "#     tensor=example_tensor,\n",
    "#     target_compression_ratio=50.0,\n",
    "#     initial_rank_arg=example_tensor_initial_rank,\n",
    "#     tensor_train_args=tensor_train_args,\n",
    "#     search_strategy=\"custom\",\n",
    "# )\n",
    "# elapsed_time = time.perf_counter() - start_time"
   ],
   "id": "f5f43b23be34d57a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print(\n",
    "#     f\"Tensor shape = {list(example_tensor.shape)}\",\n",
    "#     f\"Best Rank = {best_rank}\",\n",
    "#     f\"Frobenius Error = {frobenius_error:.6f}%\",\n",
    "#     f\"Compression Ratio = {compression_ratio:.6f}%\",\n",
    "#     f\"Elapsed Time = {elapsed_time:.6f} seconds\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# \n",
    "# # Tensor shape = [412, 620, 3]\n",
    "# # Best Rank = [1, 169, 3, 1]\n",
    "# # Frobenius Error = 3.607338%\n",
    "# # Compression Ratio = 50.106613%\n",
    "# # Elapsed Time = 46.066486 seconds"
   ],
   "id": "19e9ab98a4dbd989"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### calculate metrics",
   "id": "e27ef03b7ea9bc9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# target_compression_ratio_for_graphs_percent = 50.0\n",
    "# frobenius_error_coef_for_graphs = 1.0\n",
    "# compression_ratio_coef_for_graphs = 10.0\n",
    "# \n",
    "# (\n",
    "#     custom_alg_compression_ratios,\n",
    "#     custom_alg_frobenius_errors,\n",
    "#     custom_alg_compression_penalties,\n",
    "#     custom_alg_loss_function_results,\n",
    "# ) = [], [], [], []\n",
    "# for element in find_rank_logs:\n",
    "#     compression_ratio = element[\"compression_ratio\"] / 100.0\n",
    "#     frobenius_error = element[\"frobenius_error\"] / 100.0\n",
    "#     target_compression_ratio_for_graphs = target_compression_ratio_for_graphs_percent / 100.0\n",
    "# \n",
    "#     custom_alg_compression_ratios.append(compression_ratio)\n",
    "#     custom_alg_frobenius_errors.append(frobenius_error)\n",
    "# \n",
    "#     compression_penalty = (target_compression_ratio_for_graphs - compression_ratio) ** 2\n",
    "#     loss_function_result = (\n",
    "#             frobenius_error_coef_for_graphs * frobenius_error + compression_ratio_coef_for_graphs * compression_penalty\n",
    "#     )\n",
    "# \n",
    "#     custom_alg_compression_penalties.append(compression_penalty)\n",
    "#     custom_alg_loss_function_results.append(loss_function_result)"
   ],
   "id": "fecad357155d054"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph of metrics path in search area",
   "id": "54942db9f2e6ff13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# figs = []\n",
    "# \n",
    "# for metric, metric_data in zip(\n",
    "#         metrics,\n",
    "#         [\n",
    "#             custom_alg_frobenius_errors,\n",
    "#             custom_alg_compression_ratios,\n",
    "#             custom_alg_compression_penalties,\n",
    "#             custom_alg_loss_function_results,\n",
    "#         ],\n",
    "#         strict=False,\n",
    "# ):\n",
    "#     z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "#     x_indices = internal_indices[:, 0]\n",
    "#     y_indices = internal_indices[:, 1]\n",
    "# \n",
    "#     # Поиск локальных минимумов\n",
    "#     local_min_points = []\n",
    "# \n",
    "#     metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "# \n",
    "#     for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "#         z = z_values[i]\n",
    "# \n",
    "#         neighbors = [\n",
    "#             (x - 1, y), (x + 1, y),  # По оси X\n",
    "#             (x, y - 1), (x, y + 1)  # По оси Y\n",
    "#         ]\n",
    "# \n",
    "#         is_local_min = all(\n",
    "#             (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "#             for neighbor in neighbors\n",
    "#         )\n",
    "# \n",
    "#         if is_local_min:\n",
    "#             local_min_points.append((x, y, z))\n",
    "# \n",
    "#     x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "# \n",
    "#     fig = go.Figure()\n",
    "# \n",
    "#     # Основные точки\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=x_indices,\n",
    "#         y=y_indices,\n",
    "#         z=z_values,\n",
    "#         mode=\"markers\",\n",
    "#         marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "#     ))\n",
    "# \n",
    "#     path_x = []\n",
    "#     path_y = []\n",
    "#     path_z = []\n",
    "# \n",
    "#     for i, log in enumerate(find_rank_logs):\n",
    "#         rank = log[\"rank\"]\n",
    "#         if metric == \"frobenius_error\":\n",
    "#             z_value = custom_alg_frobenius_errors[i]\n",
    "#         elif metric == \"compression_ratio\":\n",
    "#             z_value = custom_alg_compression_ratios[i]\n",
    "#         elif metric == \"compression_penalty\":\n",
    "#             z_value = custom_alg_compression_penalties[i]\n",
    "#         elif metric == \"loss_function_result\":\n",
    "#             z_value = custom_alg_loss_function_results[i]\n",
    "# \n",
    "#         path_x.append(rank[1])\n",
    "#         path_y.append(rank[2])\n",
    "#         path_z.append(z_value)\n",
    "# \n",
    "#         fig.add_trace(\n",
    "#             go.Scatter3d(\n",
    "#                 x=[rank[1]],\n",
    "#                 y=[rank[2]],\n",
    "#                 z=[z_value],\n",
    "#                 mode=\"markers\",\n",
    "#                 marker={\n",
    "#                     \"size\": 10 if i == 0 or i == len(find_rank_logs) - 1 else 5,\n",
    "#                     \"color\": \"yellow\" if i == 0 or i == len(find_rank_logs) - 1 else \"red\",\n",
    "#                     \"opacity\": 0.8,\n",
    "#                 },\n",
    "#             )\n",
    "#         )\n",
    "# \n",
    "#     # Добавляем локальные минимумы (выделенные точки)\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=x_min,\n",
    "#         y=y_min,\n",
    "#         z=z_min,\n",
    "#         mode=\"markers+text\",\n",
    "#         marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "#         text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "#         textposition=\"top center\",\n",
    "#     ))\n",
    "# \n",
    "#     fig.add_trace(\n",
    "#         go.Scatter3d(\n",
    "#             x=path_x,\n",
    "#             y=path_y,\n",
    "#             z=path_z,\n",
    "#             mode=\"lines+markers\",\n",
    "#             marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "#             line={\"color\": \"red\", \"width\": 3},\n",
    "#         )\n",
    "#     )\n",
    "# \n",
    "#     fig.update_layout(\n",
    "#         title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with custom alg path\",\n",
    "#         scene={\n",
    "#             \"xaxis_title\": \"Rank Index 1\",\n",
    "#             \"yaxis_title\": \"Rank Index 2\",\n",
    "#             \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "#             \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "#         },\n",
    "#         margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "#         template=\"plotly_white\",\n",
    "#         showlegend=False,\n",
    "#     )\n",
    "# \n",
    "#     figs.append(fig)\n",
    "# \n",
    "# html_str = \"\"\n",
    "# for fig in figs:\n",
    "#     html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "# \n",
    "# html_file = f\"\"\"\n",
    "# <!DOCTYPE html>\n",
    "# <html>\n",
    "# <head>\n",
    "#     <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "# </head>\n",
    "# <body>\n",
    "# <h1>Search area by some metrics</h1>\n",
    "# {html_str}\n",
    "# </body>\n",
    "# </html>\n",
    "# \"\"\"\n",
    "# \n",
    "# output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_custom_alg.html\"\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "#     f.write(html_file)"
   ],
   "id": "9d1b32609db91a71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## scipy algs",
   "id": "2651d78941d7d00d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### args for algs",
   "id": "4d64c4af94a47035"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    f\"TT args: {tensor_train_args}\",\n",
    "    sep='\\n',\n",
    ")\n",
    "\n",
    "frobenius_error_coef_algs = 1.0\n",
    "compression_ratio_coef_algs = 10.0\n",
    "\n",
    "target_compression_ratio_algs = 50.0"
   ],
   "id": "7fcbae2bed1a303b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scipy_algs_results = {}",
   "id": "b9d65348e1010483"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funcs for check scipy algs",
   "id": "e00607b46194cb5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### loss function",
   "id": "b01d6e26d0f4bd81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def loss_function(\n",
    "        rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "):\n",
    "    try:\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "            \n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "    \n",
    "            target_compression_ratio /= 100\n",
    "    \n",
    "            compression_penalty = (target_compression_ratio - compression_ratio) ** 2\n",
    "    \n",
    "            # compression_penalty = target_compression_ratio - compression_ratio\n",
    "            #\n",
    "            # if compression_ratio > 1.0 or compression_ratio < 0.0 or compression_penalty < 0.0 or compression_penalty > 1.0:\n",
    "            #     compression_penalty = float(\"inf\")\n",
    "    \n",
    "        return frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor, tensor_cuda, tt_factors, reconstructed_tensor, compression_ratio, compression_penalty\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "id": "765c541ff7f4fa73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### local optimization",
   "id": "4138a6c01de98a43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def local_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        initial_rank: list[int],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"nelder-mead\",\n",
    "        jac: str | None = None,\n",
    "        hess: str | None = None,\n",
    "):\n",
    "    def loss_wrapper(free_rank: list):\n",
    "        full_rank = [1] + list(np.clip(np.round(free_rank).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "        return loss_function(\n",
    "            rank=full_rank,\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio,\n",
    "            tensor_train_args=tensor_train_args,\n",
    "            frobenius_error_coef=frobenius_error_coef,\n",
    "            compression_ratio_coef=compression_ratio_coef,\n",
    "        )\n",
    "\n",
    "    def calculate_tt_bounds(tensor_shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculates the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor_shape : tuple or list\n",
    "            List or tuple of tensor dimensions. Each element represents the size of the tensor along that dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of rank bounds in the format [(1, 1), (1, r1_max), ..., (1, 1)].\n",
    "\n",
    "        \"\"\"\n",
    "        d = len(tensor_shape)\n",
    "        bounds = [(1, 1)]\n",
    "\n",
    "        for k in range(1, d):\n",
    "            prod_left = 1\n",
    "            for i in range(k):\n",
    "                prod_left *= tensor_shape[i]\n",
    "\n",
    "            prod_right = 1\n",
    "            for j in range(k, d):\n",
    "                prod_right *= tensor_shape[j]\n",
    "\n",
    "            rk_max = min(prod_left, prod_right)\n",
    "            bounds.append((1, rk_max))\n",
    "\n",
    "        bounds.append((1, 1))\n",
    "        return bounds\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            tensor_train_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "        tt_factors = tl.decomposition.tensor_train(tensor, rank=rank, **tensor_train_args)\n",
    "        reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "        target_compression_ratio_percent /= 100\n",
    "\n",
    "        frobenius_error = (tl.norm(reconstructed_tensor - tensor) / tl.norm(tensor)).item()\n",
    "        compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor)\n",
    "        compression_penalty = (target_compression_ratio_percent - compression_ratio) ** 2\n",
    "        loss = frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "\n",
    "        metrics = {\n",
    "            \"frobenius_error\": frobenius_error,\n",
    "            \"compression_ratio\": compression_ratio,\n",
    "            \"compression_penalty\": compression_penalty,\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                tensor_train_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.tensor_train_args = tensor_train_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                tensor_train_args=self.tensor_train_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, xk):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = [1] + list(np.round(xk).astype(int)) + [1]  # noqa: RUF005\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"raw_xk\": xk,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    free_rank = initial_rank[1:-1]\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"nelder-mead\",\n",
    "        \"l-bfgs-b\",\n",
    "        \"tnc\",\n",
    "        \"slsqp\",\n",
    "        \"powell\",\n",
    "        \"trust-constr\",\n",
    "        \"cobyla\",\n",
    "        \"cobyqa\",\n",
    "    ]\n",
    "\n",
    "    is_adaptive_variable_usable = [\"nelder-mead\"]\n",
    "\n",
    "    is_jac_variable_usable = [\n",
    "        \"cg\",\n",
    "        \"bfgs\",\n",
    "        \"newton-cg\",\n",
    "        \"l-bfgs-b\",\n",
    "        \"tnc\",\n",
    "        \"slsqp\",\n",
    "        \"trust-ncg\",\n",
    "        \"trust-krylov\",\n",
    "        \"trust-exact\",\n",
    "        \"trust-constr\",\n",
    "    ]\n",
    "\n",
    "    is_hess_variable_usable = [\"newton-cg\", \"dogleg\", \"trust-ncg\", \"trust-krylov\", \"trust-exact\", \" trust-constr\"]\n",
    "\n",
    "    is_callback_variable_not_usable = [\"tnc\", \"slsqp\", \"cobyla\"]\n",
    "\n",
    "    free_bounds = calculate_tt_bounds(tensor.shape)[1:-1] if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    adaptive = optimization_method.lower() in is_adaptive_variable_usable\n",
    "\n",
    "    jac = jac if optimization_method.lower() in is_jac_variable_usable else None\n",
    "\n",
    "    hess = hess if optimization_method.lower() in is_hess_variable_usable else None\n",
    "\n",
    "    minimize_kwargs = {\n",
    "        \"fun\": loss_wrapper,\n",
    "        \"x0\": free_rank,\n",
    "        \"method\": optimization_method,\n",
    "        \"jac\": jac,\n",
    "        \"hess\": hess,\n",
    "        \"bounds\": free_bounds,\n",
    "        \"callback\": callback_param,\n",
    "        \"options\": {\n",
    "            \"disp\": True,\n",
    "            # \"maxiter\": 1000,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if adaptive:\n",
    "        minimize_kwargs[\"options\"][\"adaptive\"] = adaptive\n",
    "\n",
    "    if jac:\n",
    "        minimize_kwargs[\"jac\"] = jac\n",
    "\n",
    "    if hess:\n",
    "        minimize_kwargs[\"hess\"] = hess\n",
    "\n",
    "    # params\n",
    "\n",
    "    result = minimize(**minimize_kwargs)\n",
    "\n",
    "    optimal_rank = [1] + list(np.clip(np.round(result.x).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "    final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "fd7c39a887c6e830"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### global optimization",
   "id": "24729bb13807d588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def loss_wrapper(\n",
    "        free_rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        frobenius_error_coef: float,\n",
    "        compression_ratio_coef: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    ") -> float:\n",
    "    full_rank = [1] + list(np.clip(np.round(free_rank).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "    try:\n",
    "        loss = loss_function(\n",
    "            rank=full_rank,\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio,\n",
    "            tensor_train_args=tensor_train_args,\n",
    "            frobenius_error_coef=frobenius_error_coef,\n",
    "            compression_ratio_coef=compression_ratio_coef,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        loss = float(\"inf\")\n",
    "    finally:\n",
    "        return loss"
   ],
   "id": "a5b90531f88bb212"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def global_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        initial_rank: list[int],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"differential_evolution\",\n",
    "        loss_function_fixed: Callable | None = None,\n",
    "):\n",
    "    def calculate_tt_bounds(tensor_shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculates the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor_shape : tuple or list\n",
    "            List or tuple of tensor dimensions. Each element represents the size of the tensor along that dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of rank bounds in the format [(1, 1), (1, r1_max), ..., (1, 1)].\n",
    "\n",
    "        \"\"\"\n",
    "        d = len(tensor_shape)\n",
    "        bounds = [(1, 1)]\n",
    "\n",
    "        for k in range(1, d):\n",
    "            prod_left = 1\n",
    "            for i in range(k):\n",
    "                prod_left *= tensor_shape[i]\n",
    "\n",
    "            prod_right = 1\n",
    "            for j in range(k, d):\n",
    "                prod_right *= tensor_shape[j]\n",
    "\n",
    "            rk_max = min(prod_left, prod_right)\n",
    "            bounds.append((1, rk_max))\n",
    "\n",
    "        bounds.append((1, 1))\n",
    "        return bounds\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            tensor_train_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "        tt_factors = tl.decomposition.tensor_train(tensor, rank=rank, **tensor_train_args)\n",
    "        reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "        target_compression_ratio_percent /= 100\n",
    "\n",
    "        frobenius_error = (tl.norm(reconstructed_tensor - tensor) / tl.norm(tensor)).item()\n",
    "        compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor)\n",
    "        compression_penalty = (target_compression_ratio_percent - compression_ratio) ** 2\n",
    "        loss = frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "\n",
    "        metrics = {\n",
    "            \"frobenius_error\": frobenius_error,\n",
    "            \"compression_ratio\": compression_ratio,\n",
    "            \"compression_penalty\": compression_penalty,\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                tensor_train_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.tensor_train_args = tensor_train_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                tensor_train_args=self.tensor_train_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, intermediate_result: OptimizeResult):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = [1] + list(np.round(intermediate_result.x).astype(int)) + [1]  # noqa: RUF005\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                    \"raw_results\": intermediate_result,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    loss_function_fixed = partial(\n",
    "        loss_wrapper,\n",
    "        tensor=tensor,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"differential_evolution\",\n",
    "    ]\n",
    "\n",
    "    is_callback_variable_not_usable = []\n",
    "\n",
    "    free_bounds = calculate_tt_bounds(tensor.shape)[1:-1] if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    if optimization_method == \"differential_evolution\":\n",
    "        optimization_kwargs_differential_evolution = {\n",
    "\n",
    "            \"func\": loss_function_fixed,\n",
    "            \"bounds\": free_bounds,\n",
    "\n",
    "            \"strategy\": \"best1bin\",\n",
    "            \"maxiter\": 50,\n",
    "            \"popsize\": 10,\n",
    "            \"tol\": 0.01,\n",
    "            \"atol\": 0.001,\n",
    "            \"mutation\": (0.3, 0.7),\n",
    "            \"recombination\": 0.9,\n",
    "            \"init\": \"latinhypercube\",\n",
    "            \"polish\": True,\n",
    "\n",
    "            \"workers\": -1,\n",
    "            \"updating\": \"deferred\",\n",
    "\n",
    "            \"callback\": callback_param,\n",
    "            \"disp\": True,\n",
    "        }\n",
    "\n",
    "        result = differential_evolution(**optimization_kwargs_differential_evolution)\n",
    "\n",
    "        optimal_rank = [1] + list(np.clip(np.round(result.x).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "        final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "a2515442ebd2fc67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### check algs",
   "id": "3f1f59256c467672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://docs.scipy.org/doc/scipy-1.15.0/tutorial/optimize.html#",
   "id": "2b3a14c9ca8891aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### nelder-mead",
   "id": "47302bb20af108a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# method = \"nelder-mead\"\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {example_tensor.shape}\",\n",
    "#     f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_nelder_mead, iteration_logs_nelder_mead = local_optimize_rank(\n",
    "#         tensor=example_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=example_tensor_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     # check final frobenius error and compression ratio\n",
    "#     tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "#     reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "# \n",
    "#     frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "#     compression_ratio = (\n",
    "#             100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "#     )\n",
    "# \n",
    "#     scipy_algs_results[method] = {\n",
    "#         \"final_results\": minimize_result_nelder_mead,\n",
    "#         \"steps_results\": iteration_logs_nelder_mead,\n",
    "#     }\n",
    "# \n",
    "#     print(\n",
    "#         f\"Optimal rank: {optimal_rank}\",\n",
    "#         f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "#         f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "#         f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "#         sep=\"\\n\",\n",
    "#         end=\"\\n\\n\",\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "6e659a5cf1fc85f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### powell",
   "id": "22b4dc9da590e2db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# method = \"powell\"\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {example_tensor.shape}\",\n",
    "#     f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_powell, iteration_logs_powell = local_optimize_rank(\n",
    "#         tensor=example_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=example_tensor_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     # check final frobenius error and compression ratio\n",
    "#     tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "#     reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "# \n",
    "#     frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "#     compression_ratio = (\n",
    "#             100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "#     )\n",
    "# \n",
    "#     scipy_algs_results[method] = {\n",
    "#         \"final_results\": minimize_result_powell,\n",
    "#         \"steps_results\": iteration_logs_powell,\n",
    "#     }\n",
    "# \n",
    "#     print(\n",
    "#         f\"Optimal rank: {optimal_rank}\",\n",
    "#         f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "#         f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "#         f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "#         sep=\"\\n\",\n",
    "#         end=\"\\n\\n\",\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "332b57f9b01dbdc5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SLSQP",
   "id": "bc618dc9bd894791"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# method = \"slsqp\"\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {example_tensor.shape}\",\n",
    "#     f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_slsqp, iteration_logs_slsqp = local_optimize_rank(\n",
    "#         tensor=example_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=example_tensor_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#         jac=None,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     # check final frobenius error and compression ratio\n",
    "#     tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "#     reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "# \n",
    "#     frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "#     compression_ratio = (\n",
    "#             100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "#     )\n",
    "# \n",
    "#     scipy_algs_results[method] = {\n",
    "#         \"final_results\": minimize_result_slsqp,\n",
    "#         \"steps_results\": iteration_logs_slsqp,\n",
    "#     }\n",
    "# \n",
    "#     print(\n",
    "#         f\"Optimal rank: {optimal_rank}\",\n",
    "#         f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "#         f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "#         f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "#         sep=\"\\n\",\n",
    "#         end=\"\\n\\n\",\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "1438dbd56e34fb3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### differential_evolution",
   "id": "c043c213b8d9a1c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# method = \"differential_evolution\"\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {example_tensor.shape}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "#         tensor=example_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=example_tensor_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     # check final frobenius error and compression ratio\n",
    "#     tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "#     reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "# \n",
    "#     frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "#     compression_ratio = (\n",
    "#             100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "#     )\n",
    "# \n",
    "#     scipy_algs_results[method] = {\n",
    "#         \"final_results\": minimize_result_differential_evolution,\n",
    "#         \"steps_results\": iteration_logs_differential_evolution,\n",
    "#     }\n",
    "# \n",
    "#     print(\n",
    "#         f\"Optimal rank: {optimal_rank}\",\n",
    "#         f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "#         f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "#         f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "#         sep=\"\\n\",\n",
    "#         end=\"\\n\\n\",\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "2527c08e405ac8cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SHGO",
   "id": "78ac863bc4f17d4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# method = \"shgo\"\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {example_tensor.shape}\",\n",
    "#     f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_shgo, iteration_logs_shgo = global_optimize_rank(\n",
    "#         tensor=example_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=example_tensor_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     # check final frobenius error and compression ratio\n",
    "#     tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "#     reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "# \n",
    "#     frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "#     compression_ratio = (\n",
    "#             100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "#     )\n",
    "# \n",
    "#     scipy_algs_results[method] = {\n",
    "#         \"final_results\": minimize_result_shgo,\n",
    "#         \"steps_results\": iteration_logs_shgo,\n",
    "#     }\n",
    "# \n",
    "#     print(\n",
    "#         f\"Optimal rank: {optimal_rank}\",\n",
    "#         f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "#         f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "#         f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "#         sep=\"\\n\",\n",
    "#         end=\"\\n\\n\",\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "b0197d8d2ffac164"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path of metrics in search area",
   "id": "c7a58c6bb73cc10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for method_name, method_results in scipy_algs_results.items():\n",
    "# \n",
    "#     metric_names = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "#     frobenius_error_from_method, compression_ratio_from_method, compression_penalty_from_method, loss_from_method = [], [], [], []\n",
    "#     for method_steps_logs in method_results['steps_results']:\n",
    "#         frobenius_error_from_method.append(method_steps_logs[\"metrics\"][\"frobenius_error\"])\n",
    "#         compression_ratio_from_method.append(method_steps_logs[\"metrics\"][\"compression_ratio\"])\n",
    "#         compression_penalty_from_method.append(method_steps_logs[\"metrics\"][\"compression_penalty\"])\n",
    "#         loss_from_method.append(method_steps_logs[\"metrics\"][\"loss\"])\n",
    "# \n",
    "#     figs = []\n",
    "# \n",
    "#     for metric, metric_data in zip(\n",
    "#             metric_names,\n",
    "#             [\n",
    "#                 frobenius_error_from_method,\n",
    "#                 compression_ratio_from_method,\n",
    "#                 compression_penalty_from_method,\n",
    "#                 loss_from_method,\n",
    "#             ],\n",
    "#             strict=False,\n",
    "#     ):\n",
    "#         z_values = np.array(\n",
    "#             [search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "#         x_indices = internal_indices[:, 0]\n",
    "#         y_indices = internal_indices[:, 1]\n",
    "# \n",
    "#         # Поиск локальных минимумов\n",
    "#         local_min_points = []\n",
    "# \n",
    "#         metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "# \n",
    "#         for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "#             z = z_values[i]\n",
    "# \n",
    "#             neighbors = [\n",
    "#                 (x - 1, y), (x + 1, y),  # По оси X\n",
    "#                 (x, y - 1), (x, y + 1)  # По оси Y\n",
    "#             ]\n",
    "# \n",
    "#             is_local_min = all(\n",
    "#                 (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "#                 for neighbor in neighbors\n",
    "#             )\n",
    "# \n",
    "#             if is_local_min:\n",
    "#                 local_min_points.append((x, y, z))\n",
    "# \n",
    "#         x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "# \n",
    "#         fig = go.Figure()\n",
    "# \n",
    "#         # Основные точки\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=x_indices,\n",
    "#             y=y_indices,\n",
    "#             z=z_values,\n",
    "#             mode=\"markers\",\n",
    "#             marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "#         ))\n",
    "# \n",
    "#         path_x = []\n",
    "#         path_y = []\n",
    "#         path_z = []\n",
    "# \n",
    "#         for i, log in enumerate(method_results['steps_results']):\n",
    "#             rank = log[\"rank\"]\n",
    "#             if metric == \"frobenius_error\":\n",
    "#                 z_value = frobenius_error_from_method[i]\n",
    "#             elif metric == \"compression_ratio\":\n",
    "#                 z_value = compression_ratio_from_method[i]\n",
    "#             elif metric == \"compression_penalty\":\n",
    "#                 z_value = compression_penalty_from_method[i]\n",
    "#             elif metric == \"loss_function_result\":\n",
    "#                 z_value = loss_from_method[i]\n",
    "# \n",
    "#             path_x.append(rank[1])\n",
    "#             path_y.append(rank[2])\n",
    "#             path_z.append(z_value)\n",
    "# \n",
    "#             fig.add_trace(\n",
    "#                 go.Scatter3d(\n",
    "#                     x=[rank[1]],\n",
    "#                     y=[rank[2]],\n",
    "#                     z=[z_value],\n",
    "#                     mode=\"markers\",\n",
    "#                     marker={\n",
    "#                         \"size\": 10 if i == 0 or i == len(method_results['steps_results']) - 1 else 5,\n",
    "#                         \"color\": \"yellow\" if i == 0 or i == len(method_results['steps_results']) - 1 else \"red\",\n",
    "#                         \"opacity\": 0.8,\n",
    "#                     },\n",
    "#                 )\n",
    "#             )\n",
    "# \n",
    "#         # Добавляем локальные минимумы (выделенные точки)\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=x_min,\n",
    "#             y=y_min,\n",
    "#             z=z_min,\n",
    "#             mode=\"markers+text\",\n",
    "#             marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "#             text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "#             textposition=\"top center\",\n",
    "#         ))\n",
    "# \n",
    "#         fig.add_trace(\n",
    "#             go.Scatter3d(\n",
    "#                 x=path_x,\n",
    "#                 y=path_y,\n",
    "#                 z=path_z,\n",
    "#                 mode=\"lines+markers\",\n",
    "#                 marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "#                 line={\"color\": \"red\", \"width\": 3},\n",
    "#             )\n",
    "#         )\n",
    "# \n",
    "#         fig.update_layout(\n",
    "#             title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with {method_name} alg path\",\n",
    "#             scene={\n",
    "#                 \"xaxis_title\": \"Rank Index 1\",\n",
    "#                 \"yaxis_title\": \"Rank Index 2\",\n",
    "#                 \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "#                 \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "#             },\n",
    "#             margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "#             template=\"plotly_white\",\n",
    "#             showlegend=False,\n",
    "#         )\n",
    "# \n",
    "#         figs.append(fig)\n",
    "# \n",
    "#     html_str = \"\"\n",
    "#     for fig in figs:\n",
    "#         html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "# \n",
    "#     html_file = f\"\"\"\n",
    "#     <!DOCTYPE html>\n",
    "#     <html>\n",
    "#     <head>\n",
    "#         <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "#     </head>\n",
    "#     <body>\n",
    "#     <h1>Search area by some metrics</h1>\n",
    "#     {html_str}\n",
    "#     </body>\n",
    "#     </html>\n",
    "#     \"\"\"\n",
    "# \n",
    "#     output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_{method_name}_alg.html\"\n",
    "#     with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "#         f.write(html_file)"
   ],
   "id": "8a3a2d6ab43e06f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimization alg for target tensor",
   "id": "9b5475496caef09d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculation",
   "id": "fa4ab92e29e43433"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.utils.eeg_controller import create_eeg_limo_data_tensor\n",
    "\n",
    "cache_dir_eeg = \"../.cache/eeg\"\n",
    "\n",
    "target_tensor = create_eeg_limo_data_tensor(cache_dir_eeg=cache_dir_eeg)\n",
    "target_initial_rank = calculate_tensor_train_initial_rank(calculate_tt_bounds(target_tensor.shape))"
   ],
   "id": "51bab3e1cd07fc74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "calculate_tt_bounds(target_tensor.shape)",
   "id": "979a4ee264cb50b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "method = \"differential_evolution\"\n",
    "\n",
    "scipy_target_tensor_results = {}\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {target_tensor.shape}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "        tensor=target_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=target_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    scipy_target_tensor_results[method] = {\n",
    "        \"final_results\": minimize_result_differential_evolution,\n",
    "        \"steps_results\": iteration_logs_differential_evolution,\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "1de98a8c72a9839d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
