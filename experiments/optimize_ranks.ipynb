{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "415b86a58f1eefa6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:10.227081Z",
     "start_time": "2025-06-07T16:41:10.163015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"src.utils.method_loggers\",\n",
    "    \"src.utils.method_runners\",\n",
    "    \"src.utils.metrics_calculators\",\n",
    "    \"src.utils.tensor_handlers\",\n",
    "    \"src.utils.trackers\",\n",
    "    \"src.utils.video_controller\",\n",
    "    \"src.utils.optimal_rank_finders\",\n",
    "]\n",
    "\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import argrelextrema\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "from torch.nn import Conv2d, ConvTranspose2d\n",
    "import re\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import tensorly as tl\n",
    "from dotenv import load_dotenv\n",
    "from scipy.optimize import OptimizeResult\n",
    "from scipy.optimize import minimize, differential_evolution, shgo\n",
    "\n",
    "from src.utils.image_controller import download_image, extract_image_frames\n",
    "from src.utils.metrics_calculators import IMetricCalculator\n",
    "from src.utils.optimal_rank_finders import (\n",
    "    find_optimal_rank_tensor_train_by_compression_ratio,\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "93fd96fe374eb7ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:10.394521Z",
     "start_time": "2025-06-07T16:41:10.350275Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_train_args = {\"svd\": \"truncated_svd\"}",
   "id": "5fa3f3a3df6b5e1d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get tensor",
   "id": "626b5425644480c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:10.551913Z",
     "start_time": "2025-06-07T16:41:10.484311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cache_dir_image = \"../.cache/image\"\n",
    "\n",
    "image_urls = [\n",
    "    \"https://i.pinimg.com/564x/04/b2/68/04b26838bdd5e2ba54d0144558685bae.jpg\",\n",
    "    \"https://cdnstatic.rg.ru/crop620x412/uploads/images/187/94/47/iStock-644032024.jpg\",\n",
    "    \"https://i.sstatic.net/uQggz.png\",\n",
    "]\n",
    "\n",
    "images = {}"
   ],
   "id": "a2d129f57bead309",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:10.633971Z",
     "start_time": "2025-06-07T16:41:10.574421Z"
    }
   },
   "cell_type": "code",
   "source": "image_paths = [download_image(image_url, cache_dir_image) for image_url in image_urls]",
   "id": "edd35419372de37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение уже загружено и закешировано: ../.cache/image/04b26838bdd5e2ba54d0144558685bae.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/iStock-644032024.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/uQggz.png\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:10.798711Z",
     "start_time": "2025-06-07T16:41:10.713691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for image_index, image_path in enumerate(image_paths):\n",
    "    image_frames = extract_image_frames(image_path)\n",
    "\n",
    "    images[f\"image-{image_index}\"] = {\n",
    "        \"image_url\": image_urls[image_index],\n",
    "        \"image_path\": image_path,\n",
    "        \"frames\": image_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"image-{image_index} - {image_frames.shape}\")"
   ],
   "id": "5c010beb08c35ab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 - (564, 564, 3)\n",
      "image-1 - (412, 620, 3)\n",
      "image-2 - (689, 1195, 3)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:10.934708Z",
     "start_time": "2025-06-07T16:41:10.885186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_name = \"image-1\"\n",
    "example_tensor = images[tensor_name][\"frames\"].copy().astype(np.float32)"
   ],
   "id": "66e55dddbf0a887d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get tensor - layer of NN",
   "id": "5cff8f20e16d1455"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:11.094066Z",
     "start_time": "2025-06-07T16:41:11.009196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=False)\n",
    "# \n",
    "# def SingleLayer(model):\n",
    "#     for name, child in model.named_children():\n",
    "#         if isinstance(child, Conv2d):\n",
    "#             return child\n",
    "#         elif isinstance(child, ConvTranspose2d):\n",
    "#             return child\n",
    "#         else:\n",
    "#             return SingleLayer(child)\n",
    "# \n",
    "# layer_weights_nn_in_array = SingleLayer(gan.netG).weight.detach().numpy()\n",
    "# size = layer_weights_nn_in_array.shape\n",
    "# layer_weights_nn_in_array = layer_weights_nn_in_array.reshape(size[0], size[1], size[2] * size[3])"
   ],
   "id": "b7681bd8aefb0b6d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:11.375004Z",
     "start_time": "2025-06-07T16:41:11.329896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example_tensor = layer_weights_nn_in_array\n",
    "# tensor_name = \"random_reshaped_layer_from_NN\""
   ],
   "id": "899cd32e6a99dc32",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# func for calculate bounds for tensor train factors",
   "id": "51b1f4234acc1853"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:11.459821Z",
     "start_time": "2025-06-07T16:41:11.409470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tt_bounds(shape: tuple | list) -> list:\n",
    "    \"\"\"\n",
    "    Calculate the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : tuple[int, ...] | list[int]\n",
    "        The shape of the tensor as a list or tuple of integers.\n",
    "        Each element represents the size of the tensor along a corresponding dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int]]\n",
    "        A list of rank bounds for the Tensor Train (TT) decomposition.\n",
    "        Each element is a tuple (r_min, r_max), where:\n",
    "        - r_min is always 1.\n",
    "        - r_max is the upper bound for the TT-rank at the corresponding position.\n",
    "\n",
    "    Examples\n",
    "    -------\n",
    "    >>> calculate_tt_bounds((3, 4, 5))\n",
    "    [(1, 1), (1, 3), (1, 12), (1, 1)]\n",
    "    \"\"\"\n",
    "    d = len(shape)\n",
    "    bounds = [(1, 1)]\n",
    "\n",
    "    for k in range(1, d):\n",
    "        prod_left = 1\n",
    "        for i in range(k):\n",
    "            prod_left *= shape[i]\n",
    "\n",
    "        prod_right = 1\n",
    "        for j in range(k, d):\n",
    "            prod_right *= shape[j]\n",
    "\n",
    "        rk_max = min(prod_left, prod_right)\n",
    "        bounds.append((1, rk_max))\n",
    "\n",
    "    bounds.append((1, 1))\n",
    "    return bounds"
   ],
   "id": "5f8a383ad76fde04",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# func for calculate optimal initial rank of tensor train",
   "id": "f27f6565d8fba675"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:11.528879Z",
     "start_time": "2025-06-07T16:41:11.488281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Выходит локальный минимум ;c\n",
    "# def calculate_tensor_train_initial_rank(bounds: tuple) -> list[int]:\n",
    "#     return [max(1, round(max_bound / 2)) for min_bound, max_bound in bounds]\n",
    "\n",
    "def calculate_tensor_train_initial_rank(bounds: tuple | list) -> list[int]:\n",
    "    return [min_bound for min_bound, max_bound in bounds]"
   ],
   "id": "968a81a8e244868",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# calculate search area",
   "id": "427f7a98321f8757"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:41:11.618179Z",
     "start_time": "2025-06-07T16:41:11.562918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tt_bounds_example_tensor = calculate_tt_bounds(example_tensor.shape)\n",
    "example_tensor_initial_rank = calculate_tensor_train_initial_rank(tt_bounds_example_tensor)\n",
    "\n",
    "print(\n",
    "    tt_bounds_example_tensor,\n",
    "    example_tensor_initial_rank,\n",
    "    sep='\\n'\n",
    ")"
   ],
   "id": "bf32a2ca0f025122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (1, 412), (1, 3), (1, 1)]\n",
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:46:31.895970Z",
     "start_time": "2025-06-07T16:41:11.692456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio_for_graphs = 50.0\n",
    "frobenius_error_coef_for_graphs = 1.0\n",
    "compression_ratio_coef_for_graphs = 10.0\n",
    "\n",
    "rank_ranges = [range(bound[0], bound[1] + 1) for bound in tt_bounds_example_tensor]\n",
    "\n",
    "tqdm_iterable = product(*rank_ranges)\n",
    "tqdm_total = np.prod([len(r) for r in rank_ranges])\n",
    "\n",
    "search_area_example_results = {}\n",
    "\n",
    "with tl.backend_context(\"pytorch\"):\n",
    "    example_tensor_cuda = tl.tensor(example_tensor).to(\"cuda\")\n",
    "\n",
    "    for rank_combination in tqdm(\n",
    "            iterable=tqdm_iterable, total=tqdm_total, desc=\"Processing Ranks\"\n",
    "    ):\n",
    "        test_rank = list(rank_combination)\n",
    "        internal_indices = test_rank[1:-1]\n",
    "\n",
    "        try:\n",
    "            method_result = tl.decomposition.tensor_train(example_tensor_cuda, rank=test_rank, **tensor_train_args)\n",
    "            tt_factors = method_result\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "            frobenius_error = (\n",
    "                    tl.norm(reconstructed_tensor - example_tensor_cuda) / tl.norm(example_tensor_cuda)\n",
    "            ).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(\n",
    "                example_tensor_cuda\n",
    "            )\n",
    "            compression_penalty = (target_compression_ratio_for_graphs / 100 - compression_ratio) ** 2\n",
    "            loss_function_result = (\n",
    "                    frobenius_error_coef_for_graphs * frobenius_error\n",
    "                    + compression_ratio_coef_for_graphs * compression_penalty\n",
    "            )\n",
    "\n",
    "            search_area_example_results[tuple(internal_indices)] = {\n",
    "                \"rank\": test_rank,\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss_function_result\": loss_function_result,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            search_area_example_results[tuple(internal_indices)] = {\"rank\": test_rank, \"error\": str(e)}\n",
    "        finally:\n",
    "            torch.cuda.synchronize()\n",
    "            del tt_factors, reconstructed_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    del example_tensor_cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ],
   "id": "f339e8ccc35dccaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ranks: 100%|██████████| 1236/1236 [05:19<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph of search area",
   "id": "7811549fbb28e032"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:46:32.436027Z",
     "start_time": "2025-06-07T16:46:31.933313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "internal_indices = np.array(list(search_area_example_results.keys()))\n",
    "metrics = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "\n",
    "metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "figs = []\n",
    "\n",
    "for metric in metrics:\n",
    "    z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "    x_indices = internal_indices[:, 0]\n",
    "    y_indices = internal_indices[:, 1]\n",
    "\n",
    "    local_min_points = []\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "        z = z_values[i]\n",
    "        neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]\n",
    "        is_local_min = all(\n",
    "            (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "            for neighbor in neighbors\n",
    "        )\n",
    "        if is_local_min:\n",
    "            local_min_points.append((x, y, z))\n",
    "\n",
    "    x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_indices,\n",
    "        y=y_indices,\n",
    "        z=z_values,\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "        name=metric\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_min,\n",
    "        y=y_min,\n",
    "        z=z_min,\n",
    "        mode=\"markers+text\",\n",
    "        marker={\"size\": 6, \"color\": \"red\", \"symbol\": \"diamond\"},\n",
    "        text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "        textposition=\"top center\",\n",
    "        name=\"Local Minima\"\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()}\",\n",
    "        height=800,\n",
    "        scene={\n",
    "            \"xaxis_title\": \"Rank Index 2\",\n",
    "            \"yaxis_title\": \"Rank Index 3\",\n",
    "            \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "            \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))}\n",
    "        },\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "internal_indices = np.array(list(search_area_example_results.keys()))\n",
    "metrics = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "\n",
    "metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "\n",
    "figs = []\n",
    "\n",
    "for metric in metrics:\n",
    "    z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "    x_indices = internal_indices[:, 0]\n",
    "    y_indices = internal_indices[:, 1]\n",
    "\n",
    "    local_min_points = []\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "        z = z_values[i]\n",
    "\n",
    "        neighbors = [\n",
    "            (x - 1, y), (x + 1, y),\n",
    "            (x, y - 1), (x, y + 1)\n",
    "        ]\n",
    "\n",
    "        is_local_min = all(\n",
    "            (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "            for neighbor in neighbors\n",
    "        )\n",
    "\n",
    "        if is_local_min:\n",
    "            local_min_points.append((x, y, z))\n",
    "\n",
    "    x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_indices,\n",
    "        y=y_indices,\n",
    "        z=z_values,\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "        name=metric\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_min,\n",
    "        y=y_min,\n",
    "        z=z_min,\n",
    "        mode=\"markers+text\",\n",
    "        marker={\"size\": 6, \"color\": \"red\", \"symbol\": \"diamond\"},\n",
    "        text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "        textposition=\"top center\",\n",
    "        name=\"Local Minima\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()}\",\n",
    "        height=800,\n",
    "        scene={\n",
    "            \"xaxis_title\": \"Rank Index 2\",\n",
    "            \"yaxis_title\": \"Rank Index 3\",\n",
    "            \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "            \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))}\n",
    "        },\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    figs.append(fig)\n",
    "\n",
    "html_str = \"\"\n",
    "for fig in figs:\n",
    "    html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "html_file = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Search area by some metrics</h1>\n",
    "{html_str}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}.html\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "    f.write(html_file)"
   ],
   "id": "85ac1d75df5d5146",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimization algs test",
   "id": "e69117e76cbef0a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## optimize with custom algorithm",
   "id": "23c74370dc54bcbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:47:20.363496Z",
     "start_time": "2025-06-07T16:46:32.571957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.perf_counter()\n",
    "best_rank, compression_ratio, frobenius_error, find_rank_logs = find_optimal_rank_tensor_train_by_compression_ratio(\n",
    "    tensor=example_tensor,\n",
    "    target_compression_ratio=50.0,\n",
    "    initial_rank_arg=example_tensor_initial_rank,\n",
    "    tensor_train_args=tensor_train_args,\n",
    "    search_strategy=\"custom\",\n",
    ")\n",
    "elapsed_time = time.perf_counter() - start_time"
   ],
   "id": "f5f43b23be34d57a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal rank search process for TensorTrain:\n",
      "step | rank | compression ratio (%) | frobenius error (%)\n",
      "1 | [1, 2, 1, 1] | 0.269731 % | 29.621759 %\n",
      "2 | [1, 3, 1, 1] | 0.404400 % | 27.258003 %\n",
      "3 | [1, 3, 2, 1] | 0.647510 % | 25.136411 %\n",
      "4 | [1, 4, 2, 1] | 0.863086 % | 22.779040 %\n",
      "5 | [1, 5, 2, 1] | 1.078662 % | 21.445341 %\n",
      "6 | [1, 6, 2, 1] | 1.294237 % | 20.110290 %\n",
      "7 | [1, 7, 2, 1] | 1.509813 % | 18.870835 %\n",
      "8 | [1, 8, 2, 1] | 1.725389 % | 17.982182 %\n",
      "9 | [1, 9, 2, 1] | 1.940965 % | 17.207886 %\n",
      "10 | [1, 10, 2, 1] | 2.156540 % | 16.597034 %\n",
      "11 | [1, 11, 2, 1] | 2.372116 % | 16.011199 %\n",
      "12 | [1, 12, 2, 1] | 2.587692 % | 15.534294 %\n",
      "13 | [1, 13, 2, 1] | 2.803268 % | 15.124343 %\n",
      "14 | [1, 14, 2, 1] | 3.018843 % | 14.732207 %\n",
      "15 | [1, 15, 2, 1] | 3.234419 % | 14.346740 %\n",
      "16 | [1, 16, 2, 1] | 3.449995 % | 14.027411 %\n",
      "17 | [1, 17, 2, 1] | 3.665571 % | 13.729918 %\n",
      "18 | [1, 18, 2, 1] | 3.881146 % | 13.445653 %\n",
      "19 | [1, 19, 2, 1] | 4.096722 % | 13.194573 %\n",
      "20 | [1, 20, 2, 1] | 4.312298 % | 12.950224 %\n",
      "21 | [1, 20, 3, 1] | 5.930812 % | 12.712772 %\n",
      "22 | [1, 21, 3, 1] | 6.227294 % | 12.508014 %\n",
      "23 | [1, 22, 3, 1] | 6.523776 % | 12.302200 %\n",
      "24 | [1, 23, 3, 1] | 6.820258 % | 12.104525 %\n",
      "25 | [1, 24, 3, 1] | 7.116740 % | 11.922307 %\n",
      "26 | [1, 25, 3, 1] | 7.413222 % | 11.755522 %\n",
      "27 | [1, 26, 3, 1] | 7.709704 % | 11.592122 %\n",
      "28 | [1, 27, 3, 1] | 8.006185 % | 11.438408 %\n",
      "29 | [1, 28, 3, 1] | 8.302667 % | 11.298113 %\n",
      "30 | [1, 29, 3, 1] | 8.599149 % | 11.160798 %\n",
      "31 | [1, 30, 3, 1] | 8.895631 % | 11.026436 %\n",
      "32 | [1, 31, 3, 1] | 9.192113 % | 10.900260 %\n",
      "33 | [1, 32, 3, 1] | 9.488595 % | 10.775432 %\n",
      "34 | [1, 33, 3, 1] | 9.785077 % | 10.654760 %\n",
      "35 | [1, 34, 3, 1] | 10.081559 % | 10.541265 %\n",
      "36 | [1, 35, 3, 1] | 10.378041 % | 10.434912 %\n",
      "37 | [1, 36, 3, 1] | 10.674522 % | 10.329264 %\n",
      "38 | [1, 37, 3, 1] | 10.971004 % | 10.226131 %\n",
      "39 | [1, 38, 3, 1] | 11.267486 % | 10.126611 %\n",
      "40 | [1, 39, 3, 1] | 11.563968 % | 10.029990 %\n",
      "41 | [1, 40, 3, 1] | 11.860450 % | 9.939349 %\n",
      "42 | [1, 41, 3, 1] | 12.156932 % | 9.850655 %\n",
      "43 | [1, 42, 3, 1] | 12.453414 % | 9.762556 %\n",
      "44 | [1, 43, 3, 1] | 12.749896 % | 9.677222 %\n",
      "45 | [1, 44, 3, 1] | 13.046377 % | 9.592225 %\n",
      "46 | [1, 45, 3, 1] | 13.342859 % | 9.508426 %\n",
      "47 | [1, 46, 3, 1] | 13.639341 % | 9.426131 %\n",
      "48 | [1, 47, 3, 1] | 13.935823 % | 9.346524 %\n",
      "49 | [1, 48, 3, 1] | 14.232305 % | 9.268223 %\n",
      "50 | [1, 49, 3, 1] | 14.528787 % | 9.191043 %\n",
      "51 | [1, 50, 3, 1] | 14.825269 % | 9.114980 %\n",
      "52 | [1, 51, 3, 1] | 15.121751 % | 9.040001 %\n",
      "53 | [1, 52, 3, 1] | 15.418233 % | 8.967372 %\n",
      "54 | [1, 53, 3, 1] | 15.714714 % | 8.894876 %\n",
      "55 | [1, 54, 3, 1] | 16.011196 % | 8.822325 %\n",
      "56 | [1, 55, 3, 1] | 16.307678 % | 8.751167 %\n",
      "57 | [1, 56, 3, 1] | 16.604160 % | 8.680351 %\n",
      "58 | [1, 57, 3, 1] | 16.900642 % | 8.611247 %\n",
      "59 | [1, 58, 3, 1] | 17.197124 % | 8.544043 %\n",
      "60 | [1, 59, 3, 1] | 17.493606 % | 8.477890 %\n",
      "61 | [1, 60, 3, 1] | 17.790088 % | 8.412957 %\n",
      "62 | [1, 61, 3, 1] | 18.086570 % | 8.348834 %\n",
      "63 | [1, 62, 3, 1] | 18.383051 % | 8.285146 %\n",
      "64 | [1, 63, 3, 1] | 18.679533 % | 8.222795 %\n",
      "65 | [1, 64, 3, 1] | 18.976015 % | 8.161360 %\n",
      "66 | [1, 65, 3, 1] | 19.272497 % | 8.099706 %\n",
      "67 | [1, 66, 3, 1] | 19.568979 % | 8.037996 %\n",
      "68 | [1, 67, 3, 1] | 19.865461 % | 7.977825 %\n",
      "69 | [1, 68, 3, 1] | 20.161943 % | 7.918075 %\n",
      "70 | [1, 69, 3, 1] | 20.458425 % | 7.858986 %\n",
      "71 | [1, 70, 3, 1] | 20.754907 % | 7.800163 %\n",
      "72 | [1, 71, 3, 1] | 21.051388 % | 7.742285 %\n",
      "73 | [1, 72, 3, 1] | 21.347870 % | 7.685497 %\n",
      "74 | [1, 73, 3, 1] | 21.644352 % | 7.628885 %\n",
      "75 | [1, 74, 3, 1] | 21.940834 % | 7.572083 %\n",
      "76 | [1, 75, 3, 1] | 22.237316 % | 7.516471 %\n",
      "77 | [1, 76, 3, 1] | 22.533798 % | 7.461444 %\n",
      "78 | [1, 77, 3, 1] | 22.830280 % | 7.406400 %\n",
      "79 | [1, 78, 3, 1] | 23.126762 % | 7.351533 %\n",
      "80 | [1, 79, 3, 1] | 23.423244 % | 7.297593 %\n",
      "81 | [1, 80, 3, 1] | 23.719725 % | 7.243806 %\n",
      "82 | [1, 81, 3, 1] | 24.016207 % | 7.191201 %\n",
      "83 | [1, 82, 3, 1] | 24.312689 % | 7.138944 %\n",
      "84 | [1, 83, 3, 1] | 24.609171 % | 7.086802 %\n",
      "85 | [1, 84, 3, 1] | 24.905653 % | 7.035438 %\n",
      "86 | [1, 85, 3, 1] | 25.202135 % | 6.984413 %\n",
      "87 | [1, 86, 3, 1] | 25.498617 % | 6.933878 %\n",
      "88 | [1, 87, 3, 1] | 25.795099 % | 6.883416 %\n",
      "89 | [1, 88, 3, 1] | 26.091581 % | 6.833094 %\n",
      "90 | [1, 89, 3, 1] | 26.388062 % | 6.782767 %\n",
      "91 | [1, 90, 3, 1] | 26.684544 % | 6.732797 %\n",
      "92 | [1, 91, 3, 1] | 26.981026 % | 6.683365 %\n",
      "93 | [1, 92, 3, 1] | 27.277508 % | 6.634369 %\n",
      "94 | [1, 93, 3, 1] | 27.573990 % | 6.585474 %\n",
      "95 | [1, 94, 3, 1] | 27.870472 % | 6.536668 %\n",
      "96 | [1, 95, 3, 1] | 28.166954 % | 6.488959 %\n",
      "97 | [1, 96, 3, 1] | 28.463436 % | 6.441812 %\n",
      "98 | [1, 97, 3, 1] | 28.759918 % | 6.394632 %\n",
      "99 | [1, 98, 3, 1] | 29.056399 % | 6.348146 %\n",
      "100 | [1, 99, 3, 1] | 29.352881 % | 6.301806 %\n",
      "101 | [1, 100, 3, 1] | 29.649363 % | 6.255622 %\n",
      "102 | [1, 101, 3, 1] | 29.945845 % | 6.209817 %\n",
      "103 | [1, 102, 3, 1] | 30.242327 % | 6.164092 %\n",
      "104 | [1, 103, 3, 1] | 30.538809 % | 6.118771 %\n",
      "105 | [1, 104, 3, 1] | 30.835291 % | 6.073993 %\n",
      "106 | [1, 105, 3, 1] | 31.131773 % | 6.029435 %\n",
      "107 | [1, 106, 3, 1] | 31.428255 % | 5.984833 %\n",
      "108 | [1, 107, 3, 1] | 31.724736 % | 5.940486 %\n",
      "109 | [1, 108, 3, 1] | 32.021218 % | 5.896218 %\n",
      "110 | [1, 109, 3, 1] | 32.317700 % | 5.852955 %\n",
      "111 | [1, 110, 3, 1] | 32.614182 % | 5.809986 %\n",
      "112 | [1, 111, 3, 1] | 32.910664 % | 5.767020 %\n",
      "113 | [1, 112, 3, 1] | 33.207146 % | 5.724295 %\n",
      "114 | [1, 113, 3, 1] | 33.503628 % | 5.681891 %\n",
      "115 | [1, 114, 3, 1] | 33.800110 % | 5.639576 %\n",
      "116 | [1, 115, 3, 1] | 34.096592 % | 5.597521 %\n",
      "117 | [1, 116, 3, 1] | 34.393073 % | 5.555362 %\n",
      "118 | [1, 117, 3, 1] | 34.689555 % | 5.513358 %\n",
      "119 | [1, 118, 3, 1] | 34.986037 % | 5.472033 %\n",
      "120 | [1, 119, 3, 1] | 35.282519 % | 5.430457 %\n",
      "121 | [1, 120, 3, 1] | 35.579001 % | 5.389382 %\n",
      "122 | [1, 121, 3, 1] | 35.875483 % | 5.348358 %\n",
      "123 | [1, 122, 3, 1] | 36.171965 % | 5.307645 %\n",
      "124 | [1, 123, 3, 1] | 36.468447 % | 5.266687 %\n",
      "125 | [1, 124, 3, 1] | 36.764928 % | 5.226452 %\n",
      "126 | [1, 125, 3, 1] | 37.061410 % | 5.186162 %\n",
      "127 | [1, 126, 3, 1] | 37.357892 % | 5.145882 %\n",
      "128 | [1, 127, 3, 1] | 37.654374 % | 5.106246 %\n",
      "129 | [1, 128, 3, 1] | 37.950856 % | 5.066545 %\n",
      "130 | [1, 129, 3, 1] | 38.247338 % | 5.027163 %\n",
      "131 | [1, 130, 3, 1] | 38.543820 % | 4.987920 %\n",
      "132 | [1, 131, 3, 1] | 38.840302 % | 4.949138 %\n",
      "133 | [1, 132, 3, 1] | 39.136784 % | 4.910306 %\n",
      "134 | [1, 133, 3, 1] | 39.433265 % | 4.871199 %\n",
      "135 | [1, 134, 3, 1] | 39.729747 % | 4.832635 %\n",
      "136 | [1, 135, 3, 1] | 40.026229 % | 4.794095 %\n",
      "137 | [1, 136, 3, 1] | 40.322711 % | 4.755665 %\n",
      "138 | [1, 137, 3, 1] | 40.619193 % | 4.717197 %\n",
      "139 | [1, 138, 3, 1] | 40.915675 % | 4.678768 %\n",
      "140 | [1, 139, 3, 1] | 41.212157 % | 4.640425 %\n",
      "141 | [1, 140, 3, 1] | 41.508639 % | 4.603129 %\n",
      "142 | [1, 141, 3, 1] | 41.805121 % | 4.566067 %\n",
      "143 | [1, 142, 3, 1] | 42.101602 % | 4.529051 %\n",
      "144 | [1, 143, 3, 1] | 42.398084 % | 4.492002 %\n",
      "145 | [1, 144, 3, 1] | 42.694566 % | 4.455505 %\n",
      "146 | [1, 145, 3, 1] | 42.991048 % | 4.418839 %\n",
      "147 | [1, 146, 3, 1] | 43.287530 % | 4.382719 %\n",
      "148 | [1, 147, 3, 1] | 43.584012 % | 4.347036 %\n",
      "149 | [1, 148, 3, 1] | 43.880494 % | 4.311583 %\n",
      "150 | [1, 149, 3, 1] | 44.176976 % | 4.276245 %\n",
      "151 | [1, 150, 3, 1] | 44.473458 % | 4.241220 %\n",
      "152 | [1, 151, 3, 1] | 44.769939 % | 4.206194 %\n",
      "153 | [1, 152, 3, 1] | 45.066421 % | 4.171613 %\n",
      "154 | [1, 153, 3, 1] | 45.362903 % | 4.136769 %\n",
      "155 | [1, 154, 3, 1] | 45.659385 % | 4.102377 %\n",
      "156 | [1, 155, 3, 1] | 45.955867 % | 4.067988 %\n",
      "157 | [1, 156, 3, 1] | 46.252349 % | 4.033931 %\n",
      "158 | [1, 157, 3, 1] | 46.548831 % | 4.000353 %\n",
      "159 | [1, 158, 3, 1] | 46.845313 % | 3.966596 %\n",
      "160 | [1, 159, 3, 1] | 47.141795 % | 3.932888 %\n",
      "161 | [1, 160, 3, 1] | 47.438276 % | 3.899239 %\n",
      "162 | [1, 161, 3, 1] | 47.734758 % | 3.866215 %\n",
      "163 | [1, 162, 3, 1] | 48.031240 % | 3.833579 %\n",
      "164 | [1, 163, 3, 1] | 48.327722 % | 3.800873 %\n",
      "165 | [1, 164, 3, 1] | 48.624204 % | 3.768086 %\n",
      "166 | [1, 165, 3, 1] | 48.920686 % | 3.735531 %\n",
      "167 | [1, 166, 3, 1] | 49.217168 % | 3.703087 %\n",
      "168 | [1, 167, 3, 1] | 49.513650 % | 3.671099 %\n",
      "169 | [1, 168, 3, 1] | 49.810132 % | 3.639231 %\n",
      "170 | [1, 169, 3, 1] | 50.106613 % | 3.607338 %\n",
      "Target compression ratio reached. Stopping search.\n",
      "Optimal rank: [1, 169, 3, 1], Compression: 50.10661342520096%, Error: 3.6073382943868637%\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:47:20.428411Z",
     "start_time": "2025-06-07T16:47:20.387920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Tensor shape = {list(example_tensor.shape)}\",\n",
    "    f\"Best Rank = {best_rank}\",\n",
    "    f\"Frobenius Error = {frobenius_error:.6f}%\",\n",
    "    f\"Compression Ratio = {compression_ratio:.6f}%\",\n",
    "    f\"Elapsed Time = {elapsed_time:.6f} seconds\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "# Tensor shape = [412, 620, 3]\n",
    "# Best Rank = [1, 169, 3, 1]\n",
    "# Frobenius Error = 3.607338%\n",
    "# Compression Ratio = 50.106613%\n",
    "# Elapsed Time = 46.066486 seconds"
   ],
   "id": "19e9ab98a4dbd989",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape = [412, 620, 3]\n",
      "Best Rank = [1, 169, 3, 1]\n",
      "Frobenius Error = 3.607338%\n",
      "Compression Ratio = 50.106613%\n",
      "Elapsed Time = 47.735504 seconds\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### calculate metrics",
   "id": "e27ef03b7ea9bc9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:48.860119Z",
     "start_time": "2025-06-06T17:16:48.804941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio_for_graphs_percent = 50.0\n",
    "frobenius_error_coef_for_graphs = 1.0\n",
    "compression_ratio_coef_for_graphs = 10.0\n",
    "\n",
    "(\n",
    "    custom_alg_compression_ratios,\n",
    "    custom_alg_frobenius_errors,\n",
    "    custom_alg_compression_penalties,\n",
    "    custom_alg_loss_function_results,\n",
    ") = [], [], [], []\n",
    "for element in find_rank_logs:\n",
    "    compression_ratio = element[\"compression_ratio\"] / 100.0\n",
    "    frobenius_error = element[\"frobenius_error\"] / 100.0\n",
    "    target_compression_ratio_for_graphs = target_compression_ratio_for_graphs_percent / 100.0\n",
    "\n",
    "    custom_alg_compression_ratios.append(compression_ratio)\n",
    "    custom_alg_frobenius_errors.append(frobenius_error)\n",
    "\n",
    "    compression_penalty = (target_compression_ratio_for_graphs - compression_ratio) ** 2\n",
    "    loss_function_result = (\n",
    "            frobenius_error_coef_for_graphs * frobenius_error + compression_ratio_coef_for_graphs * compression_penalty\n",
    "    )\n",
    "\n",
    "    custom_alg_compression_penalties.append(compression_penalty)\n",
    "    custom_alg_loss_function_results.append(loss_function_result)"
   ],
   "id": "fecad357155d054",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph of metrics path in search area",
   "id": "54942db9f2e6ff13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.342095Z",
     "start_time": "2025-06-06T17:16:48.925864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figs = []\n",
    "\n",
    "for metric, metric_data in zip(\n",
    "        metrics,\n",
    "        [\n",
    "            custom_alg_frobenius_errors,\n",
    "            custom_alg_compression_ratios,\n",
    "            custom_alg_compression_penalties,\n",
    "            custom_alg_loss_function_results,\n",
    "        ],\n",
    "        strict=False,\n",
    "):\n",
    "    z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "    x_indices = internal_indices[:, 0]\n",
    "    y_indices = internal_indices[:, 1]\n",
    "\n",
    "    # Поиск локальных минимумов\n",
    "    local_min_points = []\n",
    "\n",
    "    metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "        z = z_values[i]\n",
    "\n",
    "        neighbors = [\n",
    "            (x - 1, y), (x + 1, y),  # По оси X\n",
    "            (x, y - 1), (x, y + 1)  # По оси Y\n",
    "        ]\n",
    "\n",
    "        is_local_min = all(\n",
    "            (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "            for neighbor in neighbors\n",
    "        )\n",
    "\n",
    "        if is_local_min:\n",
    "            local_min_points.append((x, y, z))\n",
    "\n",
    "    x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Основные точки\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_indices,\n",
    "        y=y_indices,\n",
    "        z=z_values,\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "    ))\n",
    "\n",
    "    path_x = []\n",
    "    path_y = []\n",
    "    path_z = []\n",
    "\n",
    "    for i, log in enumerate(find_rank_logs):\n",
    "        rank = log[\"rank\"]\n",
    "        if metric == \"frobenius_error\":\n",
    "            z_value = custom_alg_frobenius_errors[i]\n",
    "        elif metric == \"compression_ratio\":\n",
    "            z_value = custom_alg_compression_ratios[i]\n",
    "        elif metric == \"compression_penalty\":\n",
    "            z_value = custom_alg_compression_penalties[i]\n",
    "        elif metric == \"loss_function_result\":\n",
    "            z_value = custom_alg_loss_function_results[i]\n",
    "\n",
    "        path_x.append(rank[1])\n",
    "        path_y.append(rank[2])\n",
    "        path_z.append(z_value)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[rank[1]],\n",
    "                y=[rank[2]],\n",
    "                z=[z_value],\n",
    "                mode=\"markers\",\n",
    "                marker={\n",
    "                    \"size\": 10 if i == 0 or i == len(find_rank_logs) - 1 else 5,\n",
    "                    \"color\": \"yellow\" if i == 0 or i == len(find_rank_logs) - 1 else \"red\",\n",
    "                    \"opacity\": 0.8,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Добавляем локальные минимумы (выделенные точки)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_min,\n",
    "        y=y_min,\n",
    "        z=z_min,\n",
    "        mode=\"markers+text\",\n",
    "        marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "        text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "        textposition=\"top center\",\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=path_x,\n",
    "            y=path_y,\n",
    "            z=path_z,\n",
    "            mode=\"lines+markers\",\n",
    "            marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "            line={\"color\": \"red\", \"width\": 3},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with custom alg path\",\n",
    "        height=800,\n",
    "        scene={\n",
    "            \"xaxis_title\": \"Rank Index 2\",\n",
    "            \"yaxis_title\": \"Rank Index 3\",\n",
    "            \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "            \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "        },\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    figs.append(fig)\n",
    "\n",
    "html_str = \"\"\n",
    "for fig in figs:\n",
    "    html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "html_file = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Search area by some metrics</h1>\n",
    "{html_str}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_custom_alg.html\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "    f.write(html_file)"
   ],
   "id": "9d1b32609db91a71",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## scipy algs",
   "id": "2651d78941d7d00d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### args for algs",
   "id": "4d64c4af94a47035"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.419104Z",
     "start_time": "2025-06-06T17:16:50.376017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    f\"TT args: {tensor_train_args}\",\n",
    "    sep='\\n',\n",
    ")\n",
    "\n",
    "frobenius_error_coef_algs = 1.0\n",
    "compression_ratio_coef_algs = 10.0\n",
    "\n",
    "target_compression_ratio_algs = 50.0"
   ],
   "id": "7fcbae2bed1a303b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "TT args: {'svd': 'truncated_svd'}\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.516381Z",
     "start_time": "2025-06-06T17:16:50.479214Z"
    }
   },
   "cell_type": "code",
   "source": "scipy_algs_results = {}",
   "id": "b9d65348e1010483",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funcs for check scipy algs",
   "id": "e00607b46194cb5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### loss function",
   "id": "b01d6e26d0f4bd81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.582918Z",
     "start_time": "2025-06-06T17:16:50.547045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_function(\n",
    "        rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "):\n",
    "    try:\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "            \n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "    \n",
    "            target_compression_ratio /= 100\n",
    "    \n",
    "            compression_penalty = (target_compression_ratio - compression_ratio) ** 2\n",
    "    \n",
    "            # compression_penalty = target_compression_ratio - compression_ratio\n",
    "            #\n",
    "            # if compression_ratio > 1.0 or compression_ratio < 0.0 or compression_penalty < 0.0 or compression_penalty > 1.0:\n",
    "            #     compression_penalty = float(\"inf\")\n",
    "    \n",
    "        return frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor, tensor_cuda, tt_factors, reconstructed_tensor, compression_ratio, compression_penalty\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "id": "765c541ff7f4fa73",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### local optimization",
   "id": "4138a6c01de98a43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.669267Z",
     "start_time": "2025-06-06T17:16:50.611265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def local_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        initial_rank: list[int],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"nelder-mead\",\n",
    "        jac: str | None = None,\n",
    "        hess: str | None = None,\n",
    "):\n",
    "    def loss_wrapper(free_rank: list):\n",
    "        full_rank = [1] + list(np.clip(np.round(free_rank).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "        return loss_function(\n",
    "            rank=full_rank,\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio,\n",
    "            tensor_train_args=tensor_train_args,\n",
    "            frobenius_error_coef=frobenius_error_coef,\n",
    "            compression_ratio_coef=compression_ratio_coef,\n",
    "        )\n",
    "\n",
    "    def calculate_tt_bounds(tensor_shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculates the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor_shape : tuple or list\n",
    "            List or tuple of tensor dimensions. Each element represents the size of the tensor along that dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of rank bounds in the format [(1, 1), (1, r1_max), ..., (1, 1)].\n",
    "\n",
    "        \"\"\"\n",
    "        d = len(tensor_shape)\n",
    "        bounds = [(1, 1)]\n",
    "\n",
    "        for k in range(1, d):\n",
    "            prod_left = 1\n",
    "            for i in range(k):\n",
    "                prod_left *= tensor_shape[i]\n",
    "\n",
    "            prod_right = 1\n",
    "            for j in range(k, d):\n",
    "                prod_right *= tensor_shape[j]\n",
    "\n",
    "            rk_max = min(prod_left, prod_right)\n",
    "            bounds.append((1, rk_max))\n",
    "\n",
    "        bounds.append((1, 1))\n",
    "        return bounds\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            tensor_train_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "            \n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            target_compression_ratio_percent /= 100\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "            compression_penalty = (target_compression_ratio_percent - compression_ratio) ** 2\n",
    "            loss = frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "    \n",
    "            metrics = {\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss\": loss,\n",
    "            }\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        del tensor_cuda, tensor, tt_factors, reconstructed_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                tensor_train_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.tensor_train_args = tensor_train_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                tensor_train_args=self.tensor_train_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, xk):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = [1] + list(np.round(xk).astype(int)) + [1]  # noqa: RUF005\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"raw_xk\": xk,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    free_rank = initial_rank[1:-1]\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"nelder-mead\",\n",
    "        \"l-bfgs-b\",\n",
    "        \"tnc\",\n",
    "        \"slsqp\",\n",
    "        \"powell\",\n",
    "        \"trust-constr\",\n",
    "        \"cobyla\",\n",
    "        \"cobyqa\",\n",
    "    ]\n",
    "\n",
    "    is_adaptive_variable_usable = [\"nelder-mead\"]\n",
    "\n",
    "    is_jac_variable_usable = [\n",
    "        \"cg\",\n",
    "        \"bfgs\",\n",
    "        \"newton-cg\",\n",
    "        \"l-bfgs-b\",\n",
    "        \"tnc\",\n",
    "        \"slsqp\",\n",
    "        \"trust-ncg\",\n",
    "        \"trust-krylov\",\n",
    "        \"trust-exact\",\n",
    "        \"trust-constr\",\n",
    "    ]\n",
    "\n",
    "    is_hess_variable_usable = [\"newton-cg\", \"dogleg\", \"trust-ncg\", \"trust-krylov\", \"trust-exact\", \" trust-constr\"]\n",
    "\n",
    "    is_callback_variable_not_usable = [\"tnc\", \"slsqp\", \"cobyla\"]\n",
    "\n",
    "    free_bounds = calculate_tt_bounds(tensor.shape)[1:-1] if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    adaptive = optimization_method.lower() in is_adaptive_variable_usable\n",
    "\n",
    "    jac = jac if optimization_method.lower() in is_jac_variable_usable else None\n",
    "    jac = None\n",
    "\n",
    "    hess = hess if optimization_method.lower() in is_hess_variable_usable else None\n",
    "\n",
    "    minimize_kwargs = {\n",
    "        \"fun\": loss_wrapper,\n",
    "        \"x0\": free_rank,\n",
    "        \"method\": optimization_method,\n",
    "        \"jac\": jac,\n",
    "        \"hess\": hess,\n",
    "        \"bounds\": free_bounds,\n",
    "        \"callback\": callback_param,\n",
    "        \"options\": {\n",
    "            \"disp\": True,\n",
    "            # \"maxiter\": 1000,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if adaptive:\n",
    "        minimize_kwargs[\"options\"][\"adaptive\"] = adaptive\n",
    "\n",
    "    if jac:\n",
    "        minimize_kwargs[\"jac\"] = jac\n",
    "\n",
    "    if hess:\n",
    "        minimize_kwargs[\"hess\"] = hess\n",
    "\n",
    "    # params\n",
    "\n",
    "    result = minimize(**minimize_kwargs)\n",
    "\n",
    "    optimal_rank = [1] + list(np.clip(np.round(result.x).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "    final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "fd7c39a887c6e830",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### global optimization",
   "id": "24729bb13807d588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.736754Z",
     "start_time": "2025-06-06T17:16:50.697746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_wrapper(\n",
    "        free_rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        frobenius_error_coef: float,\n",
    "        compression_ratio_coef: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    ") -> float:\n",
    "    full_rank = [1] + list(np.clip(np.round(free_rank).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "    try:\n",
    "        loss = loss_function(\n",
    "            rank=full_rank,\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio,\n",
    "            tensor_train_args=tensor_train_args,\n",
    "            frobenius_error_coef=frobenius_error_coef,\n",
    "            compression_ratio_coef=compression_ratio_coef,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        loss = float(\"inf\")\n",
    "    finally:\n",
    "        return loss"
   ],
   "id": "a5b90531f88bb212",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.809767Z",
     "start_time": "2025-06-06T17:16:50.765390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def global_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        initial_rank: list[int],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"differential_evolution\",\n",
    "        loss_function_fixed: Callable | None = None,\n",
    "):\n",
    "    def calculate_tt_bounds(tensor_shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculates the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor_shape : tuple or list\n",
    "            List or tuple of tensor dimensions. Each element represents the size of the tensor along that dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of rank bounds in the format [(1, 1), (1, r1_max), ..., (1, 1)].\n",
    "\n",
    "        \"\"\"\n",
    "        d = len(tensor_shape)\n",
    "        bounds = [(1, 1)]\n",
    "\n",
    "        for k in range(1, d):\n",
    "            prod_left = 1\n",
    "            for i in range(k):\n",
    "                prod_left *= tensor_shape[i]\n",
    "\n",
    "            prod_right = 1\n",
    "            for j in range(k, d):\n",
    "                prod_right *= tensor_shape[j]\n",
    "\n",
    "            rk_max = min(prod_left, prod_right)\n",
    "            bounds.append((1, rk_max))\n",
    "\n",
    "        bounds.append((1, 1))\n",
    "        return bounds\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            tensor_train_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "\n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            target_compression_ratio_percent /= 100\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "            compression_penalty = (target_compression_ratio_percent - compression_ratio) ** 2\n",
    "            loss = frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "    \n",
    "            metrics = {\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss\": loss,\n",
    "            }\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor_cuda, tensor, tt_factors, reconstructed_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                tensor_train_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.tensor_train_args = tensor_train_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                tensor_train_args=self.tensor_train_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, intermediate_result: OptimizeResult):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = [1] + list(np.round(intermediate_result.x).astype(int)) + [1]  # noqa: RUF005\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                    \"raw_results\": intermediate_result,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    loss_function_fixed = partial(\n",
    "        loss_wrapper,\n",
    "        tensor=tensor,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"differential_evolution\",\n",
    "    ]\n",
    "\n",
    "    is_callback_variable_not_usable = []\n",
    "\n",
    "    free_bounds = calculate_tt_bounds(tensor.shape)[1:-1] if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    if optimization_method == \"differential_evolution\":\n",
    "        optimization_kwargs_differential_evolution = {\n",
    "\n",
    "            \"func\": loss_function_fixed,\n",
    "            \"bounds\": free_bounds,\n",
    "\n",
    "            \"strategy\": \"best1bin\",\n",
    "            \"maxiter\": 50,\n",
    "            \"popsize\": 10,\n",
    "            \"tol\": 0.01,\n",
    "            \"atol\": 0.001,\n",
    "            \"mutation\": (0.3, 0.7),\n",
    "            \"recombination\": 0.9,\n",
    "            \"init\": \"latinhypercube\",\n",
    "            \"polish\": True,\n",
    "\n",
    "            \"workers\": 1,\n",
    "            \"updating\": \"immediate\", # {‘immediate’ - when 1 worker, ‘deferred’ - when more than 1 worker}\n",
    "\n",
    "            \"callback\": callback_param,\n",
    "            \"disp\": True,\n",
    "        }\n",
    "\n",
    "        result = differential_evolution(**optimization_kwargs_differential_evolution)\n",
    "\n",
    "        optimal_rank = [1] + list(np.clip(np.round(result.x).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "        final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "a2515442ebd2fc67",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### check algs",
   "id": "3f1f59256c467672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://docs.scipy.org/doc/scipy-1.15.0/tutorial/optimize.html#",
   "id": "2b3a14c9ca8891aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### nelder-mead",
   "id": "47302bb20af108a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:05.667011Z",
     "start_time": "2025-06-06T17:16:50.836514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"nelder-mead\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_nelder_mead, iteration_logs_nelder_mead = local_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_nelder_mead,\n",
    "        \"steps_results\": iteration_logs_nelder_mead,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "6e659a5cf1fc85f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: nelder-mead\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 3 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 4 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 5 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 6 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 7 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 8 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 9 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.908761\n",
      "         Iterations: 10\n",
      "         Function evaluations: 39\n",
      "Optimal rank: [1, 1, 1, 1]\n",
      "Elapsed time: 13.851103 seconds\n",
      "Frobenius Error: 41.639394%\n",
      "Compression Ratio: 0.076395%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### powell",
   "id": "22b4dc9da590e2db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:49.728793Z",
     "start_time": "2025-06-06T17:17:05.724634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"powell\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_powell, iteration_logs_powell = local_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_powell,\n",
    "        \"steps_results\": iteration_logs_powell,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "332b57f9b01dbdc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: powell\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [1, 656, 2, 1]\n",
      "\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [1, 401, 2, 1]\n",
      "\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [1, 401, 2, 1]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.215818\n",
      "         Iterations: 3\n",
      "         Function evaluations: 138\n",
      "Optimal rank: [1, 401, 2, 1]\n",
      "Elapsed time: 43.084818 seconds\n",
      "Frobenius Error: 21.581759%\n",
      "Compression Ratio: 49.985932%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SLSQP",
   "id": "bc618dc9bd894791"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:51.316754Z",
     "start_time": "2025-06-06T17:17:49.787765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"slsqp\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_slsqp, iteration_logs_slsqp = local_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "        jac=None,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_slsqp,\n",
    "        \"steps_results\": iteration_logs_slsqp,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "1438dbd56e34fb3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: slsqp\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 2.9087606543916573\n",
      "            Iterations: 1\n",
      "            Function evaluations: 3\n",
      "            Gradient evaluations: 1\n",
      "Optimal rank: [1, 1, 1, 1]\n",
      "Elapsed time: 0.775754 seconds\n",
      "Frobenius Error: 41.639394%\n",
      "Compression Ratio: 0.076395%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### differential_evolution",
   "id": "c043c213b8d9a1c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:34.220723Z",
     "start_time": "2025-06-06T17:17:51.378266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"differential_evolution\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    with tl.backend_context(\"pytorch\"):\n",
    "        tensor_cuda = tl.tensor(example_tensor).to(\"cuda\")\n",
    "        tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=optimal_rank, **tensor_train_args)\n",
    "        reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "        frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "        compression_ratio = (\n",
    "                100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "        )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_differential_evolution,\n",
    "        \"steps_results\": iteration_logs_differential_evolution,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "2527c08e405ac8cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: differential_evolution\n",
      "Tensor shape: (689, 1195, 3)\n",
      "differential_evolution step 1: f(x)= 0.00021813352015890506\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [1, 287, 3, 1]\n",
      "\n",
      "differential_evolution step 2: f(x)= 0.00021813352015890506\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [1, 287, 3, 1]\n",
      "\n",
      "differential_evolution step 3: f(x)= 0.00021813352015890506\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [1, 287, 3, 1]\n",
      "\n",
      "differential_evolution step 4: f(x)= 0.00010292673974682591\n",
      "\n",
      "=== Iteration 3 complete ===\n",
      "New rank estimate: [1, 289, 3, 1]\n",
      "\n",
      "differential_evolution step 5: f(x)= 0.00010292673974682591\n",
      "\n",
      "=== Iteration 4 complete ===\n",
      "New rank estimate: [1, 289, 3, 1]\n",
      "\n",
      "differential_evolution step 6: f(x)= 0.00010292673974682591\n",
      "\n",
      "=== Iteration 5 complete ===\n",
      "New rank estimate: [1, 289, 3, 1]\n",
      "\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "Optimal rank: [1, 289, 3, 1]\n",
      "Elapsed time: 42.662653 seconds\n",
      "Frobenius Error: 0.010288%\n",
      "Compression Ratio: 50.006579%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SHGO",
   "id": "78ac863bc4f17d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:34.292903Z",
     "start_time": "2025-06-06T17:18:34.254731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"shgo\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_shgo, iteration_logs_shgo = global_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_shgo,\n",
    "        \"steps_results\": iteration_logs_shgo,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "b0197d8d2ffac164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: shgo\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "Error with method shgo: cannot access local variable 'optimal_rank' where it is not associated with a value\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path of metrics in search area",
   "id": "c7a58c6bb73cc10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:34.988513Z",
     "start_time": "2025-06-06T17:18:34.320096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for method_name, method_results in scipy_algs_results.items():\n",
    "\n",
    "    metric_names = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "    frobenius_error_from_method, compression_ratio_from_method, compression_penalty_from_method, loss_from_method = [], [], [], []\n",
    "    for method_steps_logs in method_results['steps_results']:\n",
    "        frobenius_error_from_method.append(method_steps_logs[\"metrics\"][\"frobenius_error\"])\n",
    "        compression_ratio_from_method.append(method_steps_logs[\"metrics\"][\"compression_ratio\"])\n",
    "        compression_penalty_from_method.append(method_steps_logs[\"metrics\"][\"compression_penalty\"])\n",
    "        loss_from_method.append(method_steps_logs[\"metrics\"][\"loss\"])\n",
    "\n",
    "    figs = []\n",
    "\n",
    "    for metric, metric_data in zip(\n",
    "            metric_names,\n",
    "            [\n",
    "                frobenius_error_from_method,\n",
    "                compression_ratio_from_method,\n",
    "                compression_penalty_from_method,\n",
    "                loss_from_method,\n",
    "            ],\n",
    "            strict=False,\n",
    "    ):\n",
    "        z_values = np.array(\n",
    "            [search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "        x_indices = internal_indices[:, 0]\n",
    "        y_indices = internal_indices[:, 1]\n",
    "\n",
    "        # Поиск локальных минимумов\n",
    "        local_min_points = []\n",
    "\n",
    "        metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "\n",
    "        for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "            z = z_values[i]\n",
    "\n",
    "            neighbors = [\n",
    "                (x - 1, y), (x + 1, y),  # По оси X\n",
    "                (x, y - 1), (x, y + 1)  # По оси Y\n",
    "            ]\n",
    "\n",
    "            is_local_min = all(\n",
    "                (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "                for neighbor in neighbors\n",
    "            )\n",
    "\n",
    "            if is_local_min:\n",
    "                local_min_points.append((x, y, z))\n",
    "\n",
    "        x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Основные точки\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x_indices,\n",
    "            y=y_indices,\n",
    "            z=z_values,\n",
    "            mode=\"markers\",\n",
    "            marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "        ))\n",
    "\n",
    "        path_x = []\n",
    "        path_y = []\n",
    "        path_z = []\n",
    "\n",
    "        for i, log in enumerate(method_results['steps_results']):\n",
    "            rank = log[\"rank\"]\n",
    "            if metric == \"frobenius_error\":\n",
    "                z_value = frobenius_error_from_method[i]\n",
    "            elif metric == \"compression_ratio\":\n",
    "                z_value = compression_ratio_from_method[i]\n",
    "            elif metric == \"compression_penalty\":\n",
    "                z_value = compression_penalty_from_method[i]\n",
    "            elif metric == \"loss_function_result\":\n",
    "                z_value = loss_from_method[i]\n",
    "\n",
    "            path_x.append(rank[1])\n",
    "            path_y.append(rank[2])\n",
    "            path_z.append(z_value)\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=[rank[1]],\n",
    "                    y=[rank[2]],\n",
    "                    z=[z_value],\n",
    "                    mode=\"markers\",\n",
    "                    marker={\n",
    "                        \"size\": 10 if i == 0 or i == len(method_results['steps_results']) - 1 else 5,\n",
    "                        \"color\": \"yellow\" if i == 0 or i == len(method_results['steps_results']) - 1 else \"red\",\n",
    "                        \"opacity\": 0.8,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Добавляем локальные минимумы (выделенные точки)\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x_min,\n",
    "            y=y_min,\n",
    "            z=z_min,\n",
    "            mode=\"markers+text\",\n",
    "            marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "            text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "            textposition=\"top center\",\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=path_x,\n",
    "                y=path_y,\n",
    "                z=path_z,\n",
    "                mode=\"lines+markers\",\n",
    "                marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "                line={\"color\": \"red\", \"width\": 3},\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with {method_name} alg path\",\n",
    "            height=800,\n",
    "            scene={\n",
    "                \"xaxis_title\": \"Rank Index 2\",\n",
    "                \"yaxis_title\": \"Rank Index 3\",\n",
    "                \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "                \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "            },\n",
    "            margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "            template=\"plotly_white\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "        figs.append(fig)\n",
    "\n",
    "    html_str = \"\"\n",
    "    for fig in figs:\n",
    "        html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "    html_file = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Search area by some metrics</h1>\n",
    "    {html_str}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_{method_name}_alg.html\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "        f.write(html_file)"
   ],
   "id": "8a3a2d6ab43e06f1",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimization alg for target tensor",
   "id": "9b5475496caef09d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculation",
   "id": "fa4ab92e29e43433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:35.055242Z",
     "start_time": "2025-06-06T17:18:35.015550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.utils.eeg_controller import create_eeg_limo_data_tensor\n",
    "# \n",
    "# cache_dir_eeg = \"../.cache/eeg\"\n",
    "# \n",
    "# target_tensor = create_eeg_limo_data_tensor(cache_dir_eeg=cache_dir_eeg)\n",
    "# target_initial_rank = calculate_tensor_train_initial_rank(calculate_tt_bounds(target_tensor.shape))"
   ],
   "id": "51bab3e1cd07fc74",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:35.119002Z",
     "start_time": "2025-06-06T17:18:35.086228Z"
    }
   },
   "cell_type": "code",
   "source": "# calculate_tt_bounds(target_tensor.shape)",
   "id": "979a4ee264cb50b7",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:35.177355Z",
     "start_time": "2025-06-06T17:18:35.145281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# method = \"differential_evolution\"\n",
    "# \n",
    "# scipy_target_tensor_results = {}\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {target_tensor.shape}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "#         tensor=target_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=target_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     scipy_target_tensor_results[method] = {\n",
    "#         \"final_results\": minimize_result_differential_evolution,\n",
    "#         \"steps_results\": iteration_logs_differential_evolution,\n",
    "#     }\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "1de98a8c72a9839d",
   "outputs": [],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
