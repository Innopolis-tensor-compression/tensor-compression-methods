{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "415b86a58f1eefa6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:23.264242Z",
     "start_time": "2025-06-06T17:04:23.188008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"src.utils.method_loggers\",\n",
    "    \"src.utils.method_runners\",\n",
    "    \"src.utils.metrics_calculators\",\n",
    "    \"src.utils.tensor_handlers\",\n",
    "    \"src.utils.trackers\",\n",
    "    \"src.utils.video_controller\",\n",
    "    \"src.utils.optimal_rank_finders\",\n",
    "]\n",
    "\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import argrelextrema\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "from torch.nn import Conv2d, ConvTranspose2d\n",
    "import re\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import tensorly as tl\n",
    "from dotenv import load_dotenv\n",
    "from scipy.optimize import OptimizeResult\n",
    "from scipy.optimize import minimize, differential_evolution, shgo\n",
    "\n",
    "from src.utils.image_controller import download_image, extract_image_frames\n",
    "from src.utils.metrics_calculators import IMetricCalculator\n",
    "from src.utils.optimal_rank_finders import (\n",
    "    find_optimal_rank_tensor_train_by_compression_ratio,\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "93fd96fe374eb7ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:23.582679Z",
     "start_time": "2025-06-06T17:04:23.515447Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_train_args = {\"svd\": \"truncated_svd\"}",
   "id": "5fa3f3a3df6b5e1d",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get tensor",
   "id": "626b5425644480c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:23.657561Z",
     "start_time": "2025-06-06T17:04:23.591301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cache_dir_image = \"../.cache/image\"\n",
    "\n",
    "image_urls = [\n",
    "    \"https://i.pinimg.com/564x/04/b2/68/04b26838bdd5e2ba54d0144558685bae.jpg\",\n",
    "    \"https://cdnstatic.rg.ru/crop620x412/uploads/images/187/94/47/iStock-644032024.jpg\",\n",
    "    \"https://i.sstatic.net/uQggz.png\",\n",
    "]\n",
    "\n",
    "images = {}"
   ],
   "id": "a2d129f57bead309",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:23.816669Z",
     "start_time": "2025-06-06T17:04:23.749767Z"
    }
   },
   "cell_type": "code",
   "source": "image_paths = [download_image(image_url, cache_dir_image) for image_url in image_urls]",
   "id": "edd35419372de37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображение уже загружено и закешировано: ../.cache/image/04b26838bdd5e2ba54d0144558685bae.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/iStock-644032024.jpg\n",
      "Изображение уже загружено и закешировано: ../.cache/image/uQggz.png\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:23.979985Z",
     "start_time": "2025-06-06T17:04:23.920137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for image_index, image_path in enumerate(image_paths):\n",
    "    image_frames = extract_image_frames(image_path)\n",
    "\n",
    "    images[f\"image-{image_index}\"] = {\n",
    "        \"image_url\": image_urls[image_index],\n",
    "        \"image_path\": image_path,\n",
    "        \"frames\": image_frames,\n",
    "    }\n",
    "\n",
    "    print(f\"image-{image_index} - {image_frames.shape}\")"
   ],
   "id": "5c010beb08c35ab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-0 - (564, 564, 3)\n",
      "image-1 - (412, 620, 3)\n",
      "image-2 - (689, 1195, 3)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:24.190263Z",
     "start_time": "2025-06-06T17:04:24.149472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_name = \"image-2\"\n",
    "example_tensor = images[tensor_name][\"frames\"].copy().astype(np.float32)"
   ],
   "id": "66e55dddbf0a887d",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get tensor - layer of NN",
   "id": "5cff8f20e16d1455"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:24.325465Z",
     "start_time": "2025-06-06T17:04:24.247585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=False)\n",
    "# \n",
    "# def SingleLayer(model):\n",
    "#     for name, child in model.named_children():\n",
    "#         if isinstance(child, Conv2d):\n",
    "#             return child\n",
    "#         elif isinstance(child, ConvTranspose2d):\n",
    "#             return child\n",
    "#         else:\n",
    "#             return SingleLayer(child)\n",
    "# \n",
    "# layer_weights_nn_in_array = SingleLayer(gan.netG).weight.detach().numpy()\n",
    "# size = layer_weights_nn_in_array.shape\n",
    "# layer_weights_nn_in_array = layer_weights_nn_in_array.reshape(size[0], size[1], size[2] * size[3])"
   ],
   "id": "b7681bd8aefb0b6d",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:24.581950Z",
     "start_time": "2025-06-06T17:04:24.518058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example_tensor = layer_weights_nn_in_array\n",
    "# tensor_name = \"random_reshaped_layer_from_NN\""
   ],
   "id": "899cd32e6a99dc32",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# func for calculate bounds for tensor train factors",
   "id": "51b1f4234acc1853"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:24.645585Z",
     "start_time": "2025-06-06T17:04:24.589537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tt_bounds(shape: tuple | list) -> list:\n",
    "    \"\"\"\n",
    "    Calculate the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : tuple[int, ...] | list[int]\n",
    "        The shape of the tensor as a list or tuple of integers.\n",
    "        Each element represents the size of the tensor along a corresponding dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int]]\n",
    "        A list of rank bounds for the Tensor Train (TT) decomposition.\n",
    "        Each element is a tuple (r_min, r_max), where:\n",
    "        - r_min is always 1.\n",
    "        - r_max is the upper bound for the TT-rank at the corresponding position.\n",
    "\n",
    "    Examples\n",
    "    -------\n",
    "    >>> calculate_tt_bounds((3, 4, 5))\n",
    "    [(1, 1), (1, 3), (1, 12), (1, 1)]\n",
    "    \"\"\"\n",
    "    d = len(shape)\n",
    "    bounds = [(1, 1)]\n",
    "\n",
    "    for k in range(1, d):\n",
    "        prod_left = 1\n",
    "        for i in range(k):\n",
    "            prod_left *= shape[i]\n",
    "\n",
    "        prod_right = 1\n",
    "        for j in range(k, d):\n",
    "            prod_right *= shape[j]\n",
    "\n",
    "        rk_max = min(prod_left, prod_right)\n",
    "        bounds.append((1, rk_max))\n",
    "\n",
    "    bounds.append((1, 1))\n",
    "    return bounds"
   ],
   "id": "5f8a383ad76fde04",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# func for calculate optimal initial rank of tensor train",
   "id": "f27f6565d8fba675"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:24.746178Z",
     "start_time": "2025-06-06T17:04:24.689020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Выходит локальный минимум ;c\n",
    "# def calculate_tensor_train_initial_rank(bounds: tuple) -> list[int]:\n",
    "#     return [max(1, round(max_bound / 2)) for min_bound, max_bound in bounds]\n",
    "\n",
    "def calculate_tensor_train_initial_rank(bounds: tuple | list) -> list[int]:\n",
    "    return [min_bound for min_bound, max_bound in bounds]"
   ],
   "id": "968a81a8e244868",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# calculate search area",
   "id": "427f7a98321f8757"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:24.869014Z",
     "start_time": "2025-06-06T17:04:24.815147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tt_bounds_example_tensor = calculate_tt_bounds(example_tensor.shape)\n",
    "example_tensor_initial_rank = calculate_tensor_train_initial_rank(tt_bounds_example_tensor)\n",
    "\n",
    "print(\n",
    "    tt_bounds_example_tensor,\n",
    "    example_tensor_initial_rank,\n",
    "    sep='\\n'\n",
    ")"
   ],
   "id": "bf32a2ca0f025122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (1, 689), (1, 3), (1, 1)]\n",
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:15:17.218123Z",
     "start_time": "2025-06-06T17:04:24.921171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio_for_graphs = 50.0\n",
    "frobenius_error_coef_for_graphs = 1.0\n",
    "compression_ratio_coef_for_graphs = 10.0\n",
    "\n",
    "rank_ranges = [range(bound[0], bound[1] + 1) for bound in tt_bounds_example_tensor]\n",
    "\n",
    "tqdm_iterable = product(*rank_ranges)\n",
    "tqdm_total = np.prod([len(r) for r in rank_ranges])\n",
    "\n",
    "search_area_example_results = {}\n",
    "\n",
    "with tl.backend_context(\"pytorch\"):\n",
    "    example_tensor_cuda = tl.tensor(example_tensor).to(\"cuda\")\n",
    "\n",
    "    for rank_combination in tqdm(\n",
    "            iterable=tqdm_iterable, total=tqdm_total, desc=\"Processing Ranks\"\n",
    "    ):\n",
    "        test_rank = list(rank_combination)\n",
    "        internal_indices = test_rank[1:-1]\n",
    "\n",
    "        try:\n",
    "            method_result = tl.decomposition.tensor_train(example_tensor_cuda, rank=test_rank, **tensor_train_args)\n",
    "            tt_factors = method_result\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "            frobenius_error = (\n",
    "                    tl.norm(reconstructed_tensor - example_tensor_cuda) / tl.norm(example_tensor_cuda)\n",
    "            ).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(\n",
    "                example_tensor_cuda\n",
    "            )\n",
    "            compression_penalty = (target_compression_ratio_for_graphs / 100 - compression_ratio) ** 2\n",
    "            loss_function_result = (\n",
    "                    frobenius_error_coef_for_graphs * frobenius_error\n",
    "                    + compression_ratio_coef_for_graphs * compression_penalty\n",
    "            )\n",
    "\n",
    "            search_area_example_results[tuple(internal_indices)] = {\n",
    "                \"rank\": test_rank,\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss_function_result\": loss_function_result,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            search_area_example_results[tuple(internal_indices)] = {\"rank\": test_rank, \"error\": str(e)}\n",
    "        finally:\n",
    "            torch.cuda.synchronize()\n",
    "            del tt_factors, reconstructed_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    del example_tensor_cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ],
   "id": "f339e8ccc35dccaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ranks: 100%|██████████| 2067/2067 [10:52<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph of search area",
   "id": "7811549fbb28e032"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:15:17.624827Z",
     "start_time": "2025-06-06T17:15:17.261996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "internal_indices = np.array(list(search_area_example_results.keys()))\n",
    "metrics = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "\n",
    "metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "figs = []\n",
    "\n",
    "for metric in metrics:\n",
    "    z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "    x_indices = internal_indices[:, 0]\n",
    "    y_indices = internal_indices[:, 1]\n",
    "\n",
    "    local_min_points = []\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "        z = z_values[i]\n",
    "        neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]\n",
    "        is_local_min = all(\n",
    "            (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "            for neighbor in neighbors\n",
    "        )\n",
    "        if is_local_min:\n",
    "            local_min_points.append((x, y, z))\n",
    "\n",
    "    x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_indices,\n",
    "        y=y_indices,\n",
    "        z=z_values,\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "        name=metric\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_min,\n",
    "        y=y_min,\n",
    "        z=z_min,\n",
    "        mode=\"markers+text\",\n",
    "        marker={\"size\": 6, \"color\": \"red\", \"symbol\": \"diamond\"},\n",
    "        text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "        textposition=\"top center\",\n",
    "        name=\"Local Minima\"\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()}\",\n",
    "        height=800,\n",
    "        scene={\n",
    "            \"xaxis_title\": \"Rank Index 2\",\n",
    "            \"yaxis_title\": \"Rank Index 3\",\n",
    "            \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "            \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))}\n",
    "        },\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "internal_indices = np.array(list(search_area_example_results.keys()))\n",
    "metrics = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "\n",
    "metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "\n",
    "figs = []\n",
    "\n",
    "for metric in metrics:\n",
    "    z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "    x_indices = internal_indices[:, 0]\n",
    "    y_indices = internal_indices[:, 1]\n",
    "\n",
    "    local_min_points = []\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "        z = z_values[i]\n",
    "\n",
    "        neighbors = [\n",
    "            (x - 1, y), (x + 1, y),\n",
    "            (x, y - 1), (x, y + 1)\n",
    "        ]\n",
    "\n",
    "        is_local_min = all(\n",
    "            (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "            for neighbor in neighbors\n",
    "        )\n",
    "\n",
    "        if is_local_min:\n",
    "            local_min_points.append((x, y, z))\n",
    "\n",
    "    x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_indices,\n",
    "        y=y_indices,\n",
    "        z=z_values,\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "        name=metric\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_min,\n",
    "        y=y_min,\n",
    "        z=z_min,\n",
    "        mode=\"markers+text\",\n",
    "        marker={\"size\": 6, \"color\": \"red\", \"symbol\": \"diamond\"},\n",
    "        text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "        textposition=\"top center\",\n",
    "        name=\"Local Minima\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()}\",\n",
    "        height=800,\n",
    "        scene={\n",
    "            \"xaxis_title\": \"Rank Index 2\",\n",
    "            \"yaxis_title\": \"Rank Index 3\",\n",
    "            \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "            \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))}\n",
    "        },\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    figs.append(fig)\n",
    "\n",
    "html_str = \"\"\n",
    "for fig in figs:\n",
    "    html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "html_file = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Search area by some metrics</h1>\n",
    "{html_str}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}.html\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "    f.write(html_file)"
   ],
   "id": "85ac1d75df5d5146",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimization algs test",
   "id": "e69117e76cbef0a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## optimize with custom algorithm",
   "id": "23c74370dc54bcbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:48.553848Z",
     "start_time": "2025-06-06T17:15:17.660778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.perf_counter()\n",
    "best_rank, compression_ratio, frobenius_error, find_rank_logs = find_optimal_rank_tensor_train_by_compression_ratio(\n",
    "    tensor=example_tensor,\n",
    "    target_compression_ratio=50.0,\n",
    "    initial_rank_arg=example_tensor_initial_rank,\n",
    "    tensor_train_args=tensor_train_args,\n",
    "    search_strategy=\"custom\",\n",
    ")\n",
    "elapsed_time = time.perf_counter() - start_time"
   ],
   "id": "f5f43b23be34d57a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal rank search process for TensorTrain:\n",
      "step | rank | compression ratio (%) | frobenius error (%)\n",
      "1 | [1, 2, 1, 1] | 0.152668 % | 40.194961 %\n",
      "2 | [1, 2, 2, 1] | 0.249548 % | 25.621590 %\n",
      "3 | [1, 3, 2, 1] | 0.374201 % | 22.926879 %\n",
      "4 | [1, 3, 3, 1] | 0.519460 % | 8.690936 %\n",
      "5 | [1, 4, 3, 1] | 0.692492 % | 6.977586 %\n",
      "6 | [1, 5, 3, 1] | 0.865524 % | 6.360334 %\n",
      "7 | [1, 6, 3, 1] | 1.038556 % | 5.764327 %\n",
      "8 | [1, 7, 3, 1] | 1.211588 % | 5.361496 %\n",
      "9 | [1, 8, 3, 1] | 1.384619 % | 5.057926 %\n",
      "10 | [1, 9, 3, 1] | 1.557651 % | 4.793444 %\n",
      "11 | [1, 10, 3, 1] | 1.730683 % | 4.531646 %\n",
      "12 | [1, 11, 3, 1] | 1.903715 % | 4.337652 %\n",
      "13 | [1, 12, 3, 1] | 2.076747 % | 4.144634 %\n",
      "14 | [1, 13, 3, 1] | 2.249779 % | 3.987119 %\n",
      "15 | [1, 14, 3, 1] | 2.422811 % | 3.841257 %\n",
      "16 | [1, 15, 3, 1] | 2.595843 % | 3.700722 %\n",
      "17 | [1, 16, 3, 1] | 2.768875 % | 3.558835 %\n",
      "18 | [1, 17, 3, 1] | 2.941906 % | 3.425606 %\n",
      "19 | [1, 18, 3, 1] | 3.114938 % | 3.308032 %\n",
      "20 | [1, 19, 3, 1] | 3.287970 % | 3.201620 %\n",
      "21 | [1, 20, 3, 1] | 3.461002 % | 3.097698 %\n",
      "22 | [1, 21, 3, 1] | 3.634034 % | 2.997855 %\n",
      "23 | [1, 22, 3, 1] | 3.807066 % | 2.901325 %\n",
      "24 | [1, 23, 3, 1] | 3.980098 % | 2.814870 %\n",
      "25 | [1, 24, 3, 1] | 4.153130 % | 2.727560 %\n",
      "26 | [1, 25, 3, 1] | 4.326161 % | 2.642103 %\n",
      "27 | [1, 26, 3, 1] | 4.499193 % | 2.562929 %\n",
      "28 | [1, 27, 3, 1] | 4.672225 % | 2.485874 %\n",
      "29 | [1, 28, 3, 1] | 4.845257 % | 2.415005 %\n",
      "30 | [1, 29, 3, 1] | 5.018289 % | 2.344955 %\n",
      "31 | [1, 30, 3, 1] | 5.191321 % | 2.277290 %\n",
      "32 | [1, 31, 3, 1] | 5.364353 % | 2.212568 %\n",
      "33 | [1, 32, 3, 1] | 5.537385 % | 2.148784 %\n",
      "34 | [1, 33, 3, 1] | 5.710417 % | 2.084205 %\n",
      "35 | [1, 34, 3, 1] | 5.883448 % | 2.026916 %\n",
      "36 | [1, 35, 3, 1] | 6.056480 % | 1.968612 %\n",
      "37 | [1, 36, 3, 1] | 6.229512 % | 1.913317 %\n",
      "38 | [1, 37, 3, 1] | 6.402544 % | 1.858428 %\n",
      "39 | [1, 38, 3, 1] | 6.575576 % | 1.806282 %\n",
      "40 | [1, 39, 3, 1] | 6.748608 % | 1.755301 %\n",
      "41 | [1, 40, 3, 1] | 6.921640 % | 1.704329 %\n",
      "42 | [1, 41, 3, 1] | 7.094672 % | 1.654154 %\n",
      "43 | [1, 42, 3, 1] | 7.267703 % | 1.606781 %\n",
      "44 | [1, 43, 3, 1] | 7.440735 % | 1.558694 %\n",
      "45 | [1, 44, 3, 1] | 7.613767 % | 1.513635 %\n",
      "46 | [1, 45, 3, 1] | 7.786799 % | 1.473751 %\n",
      "47 | [1, 46, 3, 1] | 7.959831 % | 1.435911 %\n",
      "48 | [1, 47, 3, 1] | 8.132863 % | 1.398494 %\n",
      "49 | [1, 48, 3, 1] | 8.305895 % | 1.362580 %\n",
      "50 | [1, 49, 3, 1] | 8.478927 % | 1.326482 %\n",
      "51 | [1, 50, 3, 1] | 8.651959 % | 1.292172 %\n",
      "52 | [1, 51, 3, 1] | 8.824990 % | 1.258401 %\n",
      "53 | [1, 52, 3, 1] | 8.998022 % | 1.225063 %\n",
      "54 | [1, 53, 3, 1] | 9.171054 % | 1.191436 %\n",
      "55 | [1, 54, 3, 1] | 9.344086 % | 1.158783 %\n",
      "56 | [1, 55, 3, 1] | 9.517118 % | 1.126746 %\n",
      "57 | [1, 56, 3, 1] | 9.690150 % | 1.094735 %\n",
      "58 | [1, 57, 3, 1] | 9.863182 % | 1.063696 %\n",
      "59 | [1, 58, 3, 1] | 10.036214 % | 1.033450 %\n",
      "60 | [1, 59, 3, 1] | 10.209246 % | 1.005684 %\n",
      "61 | [1, 60, 3, 1] | 10.382277 % | 0.977936 %\n",
      "62 | [1, 61, 3, 1] | 10.555309 % | 0.950186 %\n",
      "63 | [1, 62, 3, 1] | 10.728341 % | 0.922813 %\n",
      "64 | [1, 63, 3, 1] | 10.901373 % | 0.896570 %\n",
      "65 | [1, 64, 3, 1] | 11.074405 % | 0.871038 %\n",
      "66 | [1, 65, 3, 1] | 11.247437 % | 0.845632 %\n",
      "67 | [1, 66, 3, 1] | 11.420469 % | 0.820134 %\n",
      "68 | [1, 67, 3, 1] | 11.593501 % | 0.794992 %\n",
      "69 | [1, 68, 3, 1] | 11.766532 % | 0.770424 %\n",
      "70 | [1, 69, 3, 1] | 11.939564 % | 0.747083 %\n",
      "71 | [1, 70, 3, 1] | 12.112596 % | 0.723828 %\n",
      "72 | [1, 71, 3, 1] | 12.285628 % | 0.701984 %\n",
      "73 | [1, 72, 3, 1] | 12.458660 % | 0.681914 %\n",
      "74 | [1, 73, 3, 1] | 12.631692 % | 0.662093 %\n",
      "75 | [1, 74, 3, 1] | 12.804724 % | 0.641836 %\n",
      "76 | [1, 75, 3, 1] | 12.977756 % | 0.622666 %\n",
      "77 | [1, 76, 3, 1] | 13.150788 % | 0.603566 %\n",
      "78 | [1, 77, 3, 1] | 13.323819 % | 0.584023 %\n",
      "79 | [1, 78, 3, 1] | 13.496851 % | 0.565382 %\n",
      "80 | [1, 79, 3, 1] | 13.669883 % | 0.547456 %\n",
      "81 | [1, 80, 3, 1] | 13.842915 % | 0.529640 %\n",
      "82 | [1, 81, 3, 1] | 14.015947 % | 0.512334 %\n",
      "83 | [1, 82, 3, 1] | 14.188979 % | 0.495818 %\n",
      "84 | [1, 83, 3, 1] | 14.362011 % | 0.479840 %\n",
      "85 | [1, 84, 3, 1] | 14.535043 % | 0.464172 %\n",
      "86 | [1, 85, 3, 1] | 14.708074 % | 0.449829 %\n",
      "87 | [1, 86, 3, 1] | 14.881106 % | 0.435549 %\n",
      "88 | [1, 87, 3, 1] | 15.054138 % | 0.421281 %\n",
      "89 | [1, 88, 3, 1] | 15.227170 % | 0.407531 %\n",
      "90 | [1, 89, 3, 1] | 15.400202 % | 0.394226 %\n",
      "91 | [1, 90, 3, 1] | 15.573234 % | 0.381686 %\n",
      "92 | [1, 91, 3, 1] | 15.746266 % | 0.370411 %\n",
      "93 | [1, 92, 3, 1] | 15.919298 % | 0.359377 %\n",
      "94 | [1, 93, 3, 1] | 16.092330 % | 0.348694 %\n",
      "95 | [1, 94, 3, 1] | 16.265361 % | 0.338249 %\n",
      "96 | [1, 95, 3, 1] | 16.438393 % | 0.327745 %\n",
      "97 | [1, 96, 3, 1] | 16.611425 % | 0.317138 %\n",
      "98 | [1, 97, 3, 1] | 16.784457 % | 0.306641 %\n",
      "99 | [1, 98, 3, 1] | 16.957489 % | 0.296213 %\n",
      "100 | [1, 99, 3, 1] | 17.130521 % | 0.286592 %\n",
      "101 | [1, 100, 3, 1] | 17.303553 % | 0.276986 %\n",
      "102 | [1, 101, 3, 1] | 17.476585 % | 0.268074 %\n",
      "103 | [1, 102, 3, 1] | 17.649617 % | 0.259546 %\n",
      "104 | [1, 103, 3, 1] | 17.822648 % | 0.250923 %\n",
      "105 | [1, 104, 3, 1] | 17.995680 % | 0.242479 %\n",
      "106 | [1, 105, 3, 1] | 18.168712 % | 0.234173 %\n",
      "107 | [1, 106, 3, 1] | 18.341744 % | 0.226115 %\n",
      "108 | [1, 107, 3, 1] | 18.514776 % | 0.218584 %\n",
      "109 | [1, 108, 3, 1] | 18.687808 % | 0.211161 %\n",
      "110 | [1, 109, 3, 1] | 18.860840 % | 0.203873 %\n",
      "111 | [1, 110, 3, 1] | 19.033872 % | 0.196455 %\n",
      "112 | [1, 111, 3, 1] | 19.206903 % | 0.189339 %\n",
      "113 | [1, 112, 3, 1] | 19.379935 % | 0.182243 %\n",
      "114 | [1, 113, 3, 1] | 19.552967 % | 0.175377 %\n",
      "115 | [1, 114, 3, 1] | 19.725999 % | 0.168529 %\n",
      "116 | [1, 115, 3, 1] | 19.899031 % | 0.161814 %\n",
      "117 | [1, 116, 3, 1] | 20.072063 % | 0.155895 %\n",
      "118 | [1, 117, 3, 1] | 20.245095 % | 0.149916 %\n",
      "119 | [1, 118, 3, 1] | 20.418127 % | 0.144469 %\n",
      "120 | [1, 119, 3, 1] | 20.591159 % | 0.139223 %\n",
      "121 | [1, 120, 3, 1] | 20.764190 % | 0.134216 %\n",
      "122 | [1, 121, 3, 1] | 20.937222 % | 0.129157 %\n",
      "123 | [1, 122, 3, 1] | 21.110254 % | 0.124527 %\n",
      "124 | [1, 123, 3, 1] | 21.283286 % | 0.119953 %\n",
      "125 | [1, 124, 3, 1] | 21.456318 % | 0.115438 %\n",
      "126 | [1, 125, 3, 1] | 21.629350 % | 0.111404 %\n",
      "127 | [1, 126, 3, 1] | 21.802382 % | 0.107624 %\n",
      "128 | [1, 127, 3, 1] | 21.975414 % | 0.104037 %\n",
      "129 | [1, 128, 3, 1] | 22.148445 % | 0.100352 %\n",
      "130 | [1, 129, 3, 1] | 22.321477 % | 0.096939 %\n",
      "131 | [1, 130, 3, 1] | 22.494509 % | 0.093538 %\n",
      "132 | [1, 131, 3, 1] | 22.667541 % | 0.090210 %\n",
      "133 | [1, 132, 3, 1] | 22.840573 % | 0.086968 %\n",
      "134 | [1, 133, 3, 1] | 23.013605 % | 0.083739 %\n",
      "135 | [1, 134, 3, 1] | 23.186637 % | 0.080611 %\n",
      "136 | [1, 135, 3, 1] | 23.359669 % | 0.077427 %\n",
      "137 | [1, 136, 3, 1] | 23.532701 % | 0.074213 %\n",
      "138 | [1, 137, 3, 1] | 23.705732 % | 0.071301 %\n",
      "139 | [1, 138, 3, 1] | 23.878764 % | 0.068376 %\n",
      "140 | [1, 139, 3, 1] | 24.051796 % | 0.065508 %\n",
      "141 | [1, 140, 3, 1] | 24.224828 % | 0.062522 %\n",
      "142 | [1, 141, 3, 1] | 24.397860 % | 0.059610 %\n",
      "143 | [1, 142, 3, 1] | 24.570892 % | 0.056833 %\n",
      "144 | [1, 143, 3, 1] | 24.743924 % | 0.054064 %\n",
      "145 | [1, 144, 3, 1] | 24.916956 % | 0.051417 %\n",
      "146 | [1, 145, 3, 1] | 25.089988 % | 0.048773 %\n",
      "147 | [1, 146, 3, 1] | 25.263019 % | 0.046091 %\n",
      "148 | [1, 147, 3, 1] | 25.436051 % | 0.043715 %\n",
      "149 | [1, 148, 3, 1] | 25.609083 % | 0.041384 %\n",
      "150 | [1, 149, 3, 1] | 25.782115 % | 0.039143 %\n",
      "151 | [1, 150, 3, 1] | 25.955147 % | 0.036985 %\n",
      "152 | [1, 151, 3, 1] | 26.128179 % | 0.034987 %\n",
      "153 | [1, 152, 3, 1] | 26.301211 % | 0.033149 %\n",
      "154 | [1, 153, 3, 1] | 26.474243 % | 0.031342 %\n",
      "155 | [1, 154, 3, 1] | 26.647274 % | 0.029862 %\n",
      "156 | [1, 155, 3, 1] | 26.820306 % | 0.028512 %\n",
      "157 | [1, 156, 3, 1] | 26.993338 % | 0.027238 %\n",
      "158 | [1, 157, 3, 1] | 27.166370 % | 0.025963 %\n",
      "159 | [1, 158, 3, 1] | 27.339402 % | 0.024726 %\n",
      "160 | [1, 159, 3, 1] | 27.512434 % | 0.023528 %\n",
      "161 | [1, 160, 3, 1] | 27.685466 % | 0.022321 %\n",
      "162 | [1, 161, 3, 1] | 27.858498 % | 0.021135 %\n",
      "163 | [1, 162, 3, 1] | 28.031530 % | 0.019953 %\n",
      "164 | [1, 163, 3, 1] | 28.204561 % | 0.018904 %\n",
      "165 | [1, 164, 3, 1] | 28.377593 % | 0.017806 %\n",
      "166 | [1, 165, 3, 1] | 28.550625 % | 0.016745 %\n",
      "167 | [1, 166, 3, 1] | 28.723657 % | 0.015906 %\n",
      "168 | [1, 167, 3, 1] | 28.896689 % | 0.015134 %\n",
      "169 | [1, 168, 3, 1] | 29.069721 % | 0.014482 %\n",
      "170 | [1, 169, 3, 1] | 29.242753 % | 0.013805 %\n",
      "171 | [1, 170, 3, 1] | 29.415785 % | 0.013175 %\n",
      "172 | [1, 171, 3, 1] | 29.588816 % | 0.012597 %\n",
      "173 | [1, 172, 3, 1] | 29.761848 % | 0.012005 %\n",
      "174 | [1, 173, 3, 1] | 29.934880 % | 0.011537 %\n",
      "175 | [1, 174, 3, 1] | 30.107912 % | 0.011277 %\n",
      "176 | [1, 175, 3, 1] | 30.280944 % | 0.011036 %\n",
      "177 | [1, 176, 3, 1] | 30.453976 % | 0.010800 %\n",
      "178 | [1, 177, 3, 1] | 30.627008 % | 0.010597 %\n",
      "179 | [1, 178, 3, 1] | 30.800040 % | 0.010407 %\n",
      "180 | [1, 179, 3, 1] | 30.973072 % | 0.010286 %\n",
      "181 | [1, 180, 3, 1] | 31.146103 % | 0.010288 %\n",
      "182 | [1, 181, 3, 1] | 31.319135 % | 0.010288 %\n",
      "183 | [1, 182, 3, 1] | 31.492167 % | 0.010288 %\n",
      "184 | [1, 183, 3, 1] | 31.665199 % | 0.010288 %\n",
      "185 | [1, 184, 3, 1] | 31.838231 % | 0.010288 %\n",
      "186 | [1, 185, 3, 1] | 32.011263 % | 0.010288 %\n",
      "187 | [1, 186, 3, 1] | 32.184295 % | 0.010288 %\n",
      "188 | [1, 187, 3, 1] | 32.357327 % | 0.010288 %\n",
      "189 | [1, 188, 3, 1] | 32.530359 % | 0.010288 %\n",
      "190 | [1, 189, 3, 1] | 32.703390 % | 0.010288 %\n",
      "191 | [1, 190, 3, 1] | 32.876422 % | 0.010288 %\n",
      "192 | [1, 191, 3, 1] | 33.049454 % | 0.010288 %\n",
      "193 | [1, 192, 3, 1] | 33.222486 % | 0.010288 %\n",
      "194 | [1, 193, 3, 1] | 33.395518 % | 0.010288 %\n",
      "195 | [1, 194, 3, 1] | 33.568550 % | 0.010288 %\n",
      "196 | [1, 195, 3, 1] | 33.741582 % | 0.010288 %\n",
      "197 | [1, 196, 3, 1] | 33.914614 % | 0.010288 %\n",
      "198 | [1, 197, 3, 1] | 34.087645 % | 0.010288 %\n",
      "199 | [1, 198, 3, 1] | 34.260677 % | 0.010288 %\n",
      "200 | [1, 199, 3, 1] | 34.433709 % | 0.010288 %\n",
      "201 | [1, 200, 3, 1] | 34.606741 % | 0.010288 %\n",
      "202 | [1, 201, 3, 1] | 34.779773 % | 0.010288 %\n",
      "203 | [1, 202, 3, 1] | 34.952805 % | 0.010288 %\n",
      "204 | [1, 203, 3, 1] | 35.125837 % | 0.010288 %\n",
      "205 | [1, 204, 3, 1] | 35.298869 % | 0.010288 %\n",
      "206 | [1, 205, 3, 1] | 35.471901 % | 0.010288 %\n",
      "207 | [1, 206, 3, 1] | 35.644932 % | 0.010288 %\n",
      "208 | [1, 207, 3, 1] | 35.817964 % | 0.010288 %\n",
      "209 | [1, 208, 3, 1] | 35.990996 % | 0.010288 %\n",
      "210 | [1, 209, 3, 1] | 36.164028 % | 0.010288 %\n",
      "211 | [1, 210, 3, 1] | 36.337060 % | 0.010288 %\n",
      "212 | [1, 211, 3, 1] | 36.510092 % | 0.010288 %\n",
      "213 | [1, 212, 3, 1] | 36.683124 % | 0.010288 %\n",
      "214 | [1, 213, 3, 1] | 36.856156 % | 0.010288 %\n",
      "215 | [1, 214, 3, 1] | 37.029187 % | 0.010288 %\n",
      "216 | [1, 215, 3, 1] | 37.202219 % | 0.010288 %\n",
      "217 | [1, 216, 3, 1] | 37.375251 % | 0.010288 %\n",
      "218 | [1, 217, 3, 1] | 37.548283 % | 0.010288 %\n",
      "219 | [1, 218, 3, 1] | 37.721315 % | 0.010288 %\n",
      "220 | [1, 219, 3, 1] | 37.894347 % | 0.010288 %\n",
      "221 | [1, 220, 3, 1] | 38.067379 % | 0.010288 %\n",
      "222 | [1, 221, 3, 1] | 38.240411 % | 0.010288 %\n",
      "223 | [1, 222, 3, 1] | 38.413443 % | 0.010288 %\n",
      "224 | [1, 223, 3, 1] | 38.586474 % | 0.010288 %\n",
      "225 | [1, 224, 3, 1] | 38.759506 % | 0.010288 %\n",
      "226 | [1, 225, 3, 1] | 38.932538 % | 0.010288 %\n",
      "227 | [1, 226, 3, 1] | 39.105570 % | 0.010288 %\n",
      "228 | [1, 227, 3, 1] | 39.278602 % | 0.010288 %\n",
      "229 | [1, 228, 3, 1] | 39.451634 % | 0.010288 %\n",
      "230 | [1, 229, 3, 1] | 39.624666 % | 0.010288 %\n",
      "231 | [1, 230, 3, 1] | 39.797698 % | 0.010288 %\n",
      "232 | [1, 231, 3, 1] | 39.970730 % | 0.010288 %\n",
      "233 | [1, 232, 3, 1] | 40.143761 % | 0.010288 %\n",
      "234 | [1, 233, 3, 1] | 40.316793 % | 0.010288 %\n",
      "235 | [1, 234, 3, 1] | 40.489825 % | 0.010288 %\n",
      "236 | [1, 235, 3, 1] | 40.662857 % | 0.010288 %\n",
      "237 | [1, 236, 3, 1] | 40.835889 % | 0.010288 %\n",
      "238 | [1, 237, 3, 1] | 41.008921 % | 0.010288 %\n",
      "239 | [1, 238, 3, 1] | 41.181953 % | 0.010288 %\n",
      "240 | [1, 239, 3, 1] | 41.354985 % | 0.010288 %\n",
      "241 | [1, 240, 3, 1] | 41.528016 % | 0.010288 %\n",
      "242 | [1, 241, 3, 1] | 41.701048 % | 0.010288 %\n",
      "243 | [1, 242, 3, 1] | 41.874080 % | 0.010288 %\n",
      "244 | [1, 243, 3, 1] | 42.047112 % | 0.010288 %\n",
      "245 | [1, 244, 3, 1] | 42.220144 % | 0.010288 %\n",
      "246 | [1, 245, 3, 1] | 42.393176 % | 0.010288 %\n",
      "247 | [1, 246, 3, 1] | 42.566208 % | 0.010288 %\n",
      "248 | [1, 247, 3, 1] | 42.739240 % | 0.010288 %\n",
      "249 | [1, 248, 3, 1] | 42.912272 % | 0.010288 %\n",
      "250 | [1, 249, 3, 1] | 43.085303 % | 0.010288 %\n",
      "251 | [1, 250, 3, 1] | 43.258335 % | 0.010288 %\n",
      "252 | [1, 251, 3, 1] | 43.431367 % | 0.010288 %\n",
      "253 | [1, 252, 3, 1] | 43.604399 % | 0.010288 %\n",
      "254 | [1, 253, 3, 1] | 43.777431 % | 0.010288 %\n",
      "255 | [1, 254, 3, 1] | 43.950463 % | 0.010288 %\n",
      "256 | [1, 255, 3, 1] | 44.123495 % | 0.010288 %\n",
      "257 | [1, 256, 3, 1] | 44.296527 % | 0.010288 %\n",
      "258 | [1, 257, 3, 1] | 44.469558 % | 0.010288 %\n",
      "259 | [1, 258, 3, 1] | 44.642590 % | 0.010288 %\n",
      "260 | [1, 259, 3, 1] | 44.815622 % | 0.010288 %\n",
      "261 | [1, 260, 3, 1] | 44.988654 % | 0.010288 %\n",
      "262 | [1, 261, 3, 1] | 45.161686 % | 0.010288 %\n",
      "263 | [1, 262, 3, 1] | 45.334718 % | 0.010288 %\n",
      "264 | [1, 263, 3, 1] | 45.507750 % | 0.010288 %\n",
      "265 | [1, 264, 3, 1] | 45.680782 % | 0.010288 %\n",
      "266 | [1, 265, 3, 1] | 45.853814 % | 0.010288 %\n",
      "267 | [1, 266, 3, 1] | 46.026845 % | 0.010288 %\n",
      "268 | [1, 267, 3, 1] | 46.199877 % | 0.010288 %\n",
      "269 | [1, 268, 3, 1] | 46.372909 % | 0.010288 %\n",
      "270 | [1, 269, 3, 1] | 46.545941 % | 0.010288 %\n",
      "271 | [1, 270, 3, 1] | 46.718973 % | 0.010288 %\n",
      "272 | [1, 271, 3, 1] | 46.892005 % | 0.010288 %\n",
      "273 | [1, 272, 3, 1] | 47.065037 % | 0.010288 %\n",
      "274 | [1, 273, 3, 1] | 47.238069 % | 0.010288 %\n",
      "275 | [1, 274, 3, 1] | 47.411101 % | 0.010288 %\n",
      "276 | [1, 275, 3, 1] | 47.584132 % | 0.010288 %\n",
      "277 | [1, 276, 3, 1] | 47.757164 % | 0.010288 %\n",
      "278 | [1, 277, 3, 1] | 47.930196 % | 0.010288 %\n",
      "279 | [1, 278, 3, 1] | 48.103228 % | 0.010288 %\n",
      "280 | [1, 279, 3, 1] | 48.276260 % | 0.010288 %\n",
      "281 | [1, 280, 3, 1] | 48.449292 % | 0.010288 %\n",
      "282 | [1, 281, 3, 1] | 48.622324 % | 0.010288 %\n",
      "283 | [1, 282, 3, 1] | 48.795356 % | 0.010288 %\n",
      "284 | [1, 283, 3, 1] | 48.968387 % | 0.010288 %\n",
      "285 | [1, 284, 3, 1] | 49.141419 % | 0.010288 %\n",
      "286 | [1, 285, 3, 1] | 49.314451 % | 0.010288 %\n",
      "287 | [1, 286, 3, 1] | 49.487483 % | 0.010288 %\n",
      "288 | [1, 287, 3, 1] | 49.660515 % | 0.010288 %\n",
      "289 | [1, 288, 3, 1] | 49.833547 % | 0.010288 %\n",
      "290 | [1, 289, 3, 1] | 50.006579 % | 0.010288 %\n",
      "Target compression ratio reached. Stopping search.\n",
      "Optimal rank: [1, 289, 3, 1], Compression: 50.00657877424278%, Error: 0.01028834594762884%\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:48.720670Z",
     "start_time": "2025-06-06T17:16:48.644863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Tensor shape = {list(example_tensor.shape)}\",\n",
    "    f\"Best Rank = {best_rank}\",\n",
    "    f\"Frobenius Error = {frobenius_error:.6f}%\",\n",
    "    f\"Compression Ratio = {compression_ratio:.6f}%\",\n",
    "    f\"Elapsed Time = {elapsed_time:.6f} seconds\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "# Tensor shape = [412, 620, 3]\n",
    "# Best Rank = [1, 169, 3, 1]\n",
    "# Frobenius Error = 3.607338%\n",
    "# Compression Ratio = 50.106613%\n",
    "# Elapsed Time = 46.066486 seconds"
   ],
   "id": "19e9ab98a4dbd989",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape = [689, 1195, 3]\n",
      "Best Rank = [1, 289, 3, 1]\n",
      "Frobenius Error = 0.010288%\n",
      "Compression Ratio = 50.006579%\n",
      "Elapsed Time = 90.843168 seconds\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### calculate metrics",
   "id": "e27ef03b7ea9bc9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:48.860119Z",
     "start_time": "2025-06-06T17:16:48.804941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio_for_graphs_percent = 50.0\n",
    "frobenius_error_coef_for_graphs = 1.0\n",
    "compression_ratio_coef_for_graphs = 10.0\n",
    "\n",
    "(\n",
    "    custom_alg_compression_ratios,\n",
    "    custom_alg_frobenius_errors,\n",
    "    custom_alg_compression_penalties,\n",
    "    custom_alg_loss_function_results,\n",
    ") = [], [], [], []\n",
    "for element in find_rank_logs:\n",
    "    compression_ratio = element[\"compression_ratio\"] / 100.0\n",
    "    frobenius_error = element[\"frobenius_error\"] / 100.0\n",
    "    target_compression_ratio_for_graphs = target_compression_ratio_for_graphs_percent / 100.0\n",
    "\n",
    "    custom_alg_compression_ratios.append(compression_ratio)\n",
    "    custom_alg_frobenius_errors.append(frobenius_error)\n",
    "\n",
    "    compression_penalty = (target_compression_ratio_for_graphs - compression_ratio) ** 2\n",
    "    loss_function_result = (\n",
    "            frobenius_error_coef_for_graphs * frobenius_error + compression_ratio_coef_for_graphs * compression_penalty\n",
    "    )\n",
    "\n",
    "    custom_alg_compression_penalties.append(compression_penalty)\n",
    "    custom_alg_loss_function_results.append(loss_function_result)"
   ],
   "id": "fecad357155d054",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph of metrics path in search area",
   "id": "54942db9f2e6ff13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.342095Z",
     "start_time": "2025-06-06T17:16:48.925864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figs = []\n",
    "\n",
    "for metric, metric_data in zip(\n",
    "        metrics,\n",
    "        [\n",
    "            custom_alg_frobenius_errors,\n",
    "            custom_alg_compression_ratios,\n",
    "            custom_alg_compression_penalties,\n",
    "            custom_alg_loss_function_results,\n",
    "        ],\n",
    "        strict=False,\n",
    "):\n",
    "    z_values = np.array([search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "    x_indices = internal_indices[:, 0]\n",
    "    y_indices = internal_indices[:, 1]\n",
    "\n",
    "    # Поиск локальных минимумов\n",
    "    local_min_points = []\n",
    "\n",
    "    metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "        z = z_values[i]\n",
    "\n",
    "        neighbors = [\n",
    "            (x - 1, y), (x + 1, y),  # По оси X\n",
    "            (x, y - 1), (x, y + 1)  # По оси Y\n",
    "        ]\n",
    "\n",
    "        is_local_min = all(\n",
    "            (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "            for neighbor in neighbors\n",
    "        )\n",
    "\n",
    "        if is_local_min:\n",
    "            local_min_points.append((x, y, z))\n",
    "\n",
    "    x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Основные точки\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_indices,\n",
    "        y=y_indices,\n",
    "        z=z_values,\n",
    "        mode=\"markers\",\n",
    "        marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "    ))\n",
    "\n",
    "    path_x = []\n",
    "    path_y = []\n",
    "    path_z = []\n",
    "\n",
    "    for i, log in enumerate(find_rank_logs):\n",
    "        rank = log[\"rank\"]\n",
    "        if metric == \"frobenius_error\":\n",
    "            z_value = custom_alg_frobenius_errors[i]\n",
    "        elif metric == \"compression_ratio\":\n",
    "            z_value = custom_alg_compression_ratios[i]\n",
    "        elif metric == \"compression_penalty\":\n",
    "            z_value = custom_alg_compression_penalties[i]\n",
    "        elif metric == \"loss_function_result\":\n",
    "            z_value = custom_alg_loss_function_results[i]\n",
    "\n",
    "        path_x.append(rank[1])\n",
    "        path_y.append(rank[2])\n",
    "        path_z.append(z_value)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[rank[1]],\n",
    "                y=[rank[2]],\n",
    "                z=[z_value],\n",
    "                mode=\"markers\",\n",
    "                marker={\n",
    "                    \"size\": 10 if i == 0 or i == len(find_rank_logs) - 1 else 5,\n",
    "                    \"color\": \"yellow\" if i == 0 or i == len(find_rank_logs) - 1 else \"red\",\n",
    "                    \"opacity\": 0.8,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Добавляем локальные минимумы (выделенные точки)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=x_min,\n",
    "        y=y_min,\n",
    "        z=z_min,\n",
    "        mode=\"markers+text\",\n",
    "        marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "        text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "        textposition=\"top center\",\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=path_x,\n",
    "            y=path_y,\n",
    "            z=path_z,\n",
    "            mode=\"lines+markers\",\n",
    "            marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "            line={\"color\": \"red\", \"width\": 3},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with custom alg path\",\n",
    "        height=800,\n",
    "        scene={\n",
    "            \"xaxis_title\": \"Rank Index 2\",\n",
    "            \"yaxis_title\": \"Rank Index 3\",\n",
    "            \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "            \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "        },\n",
    "        margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    figs.append(fig)\n",
    "\n",
    "html_str = \"\"\n",
    "for fig in figs:\n",
    "    html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "html_file = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Search area by some metrics</h1>\n",
    "{html_str}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_custom_alg.html\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "    f.write(html_file)"
   ],
   "id": "9d1b32609db91a71",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## scipy algs",
   "id": "2651d78941d7d00d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### args for algs",
   "id": "4d64c4af94a47035"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.419104Z",
     "start_time": "2025-06-06T17:16:50.376017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    f\"TT args: {tensor_train_args}\",\n",
    "    sep='\\n',\n",
    ")\n",
    "\n",
    "frobenius_error_coef_algs = 1.0\n",
    "compression_ratio_coef_algs = 10.0\n",
    "\n",
    "target_compression_ratio_algs = 50.0"
   ],
   "id": "7fcbae2bed1a303b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "TT args: {'svd': 'truncated_svd'}\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.516381Z",
     "start_time": "2025-06-06T17:16:50.479214Z"
    }
   },
   "cell_type": "code",
   "source": "scipy_algs_results = {}",
   "id": "b9d65348e1010483",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funcs for check scipy algs",
   "id": "e00607b46194cb5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### loss function",
   "id": "b01d6e26d0f4bd81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.582918Z",
     "start_time": "2025-06-06T17:16:50.547045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_function(\n",
    "        rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "):\n",
    "    try:\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "            \n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "    \n",
    "            target_compression_ratio /= 100\n",
    "    \n",
    "            compression_penalty = (target_compression_ratio - compression_ratio) ** 2\n",
    "    \n",
    "            # compression_penalty = target_compression_ratio - compression_ratio\n",
    "            #\n",
    "            # if compression_ratio > 1.0 or compression_ratio < 0.0 or compression_penalty < 0.0 or compression_penalty > 1.0:\n",
    "            #     compression_penalty = float(\"inf\")\n",
    "    \n",
    "        return frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor, tensor_cuda, tt_factors, reconstructed_tensor, compression_ratio, compression_penalty\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "id": "765c541ff7f4fa73",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### local optimization",
   "id": "4138a6c01de98a43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.669267Z",
     "start_time": "2025-06-06T17:16:50.611265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def local_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        initial_rank: list[int],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"nelder-mead\",\n",
    "        jac: str | None = None,\n",
    "        hess: str | None = None,\n",
    "):\n",
    "    def loss_wrapper(free_rank: list):\n",
    "        full_rank = [1] + list(np.clip(np.round(free_rank).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "        return loss_function(\n",
    "            rank=full_rank,\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio,\n",
    "            tensor_train_args=tensor_train_args,\n",
    "            frobenius_error_coef=frobenius_error_coef,\n",
    "            compression_ratio_coef=compression_ratio_coef,\n",
    "        )\n",
    "\n",
    "    def calculate_tt_bounds(tensor_shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculates the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor_shape : tuple or list\n",
    "            List or tuple of tensor dimensions. Each element represents the size of the tensor along that dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of rank bounds in the format [(1, 1), (1, r1_max), ..., (1, 1)].\n",
    "\n",
    "        \"\"\"\n",
    "        d = len(tensor_shape)\n",
    "        bounds = [(1, 1)]\n",
    "\n",
    "        for k in range(1, d):\n",
    "            prod_left = 1\n",
    "            for i in range(k):\n",
    "                prod_left *= tensor_shape[i]\n",
    "\n",
    "            prod_right = 1\n",
    "            for j in range(k, d):\n",
    "                prod_right *= tensor_shape[j]\n",
    "\n",
    "            rk_max = min(prod_left, prod_right)\n",
    "            bounds.append((1, rk_max))\n",
    "\n",
    "        bounds.append((1, 1))\n",
    "        return bounds\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            tensor_train_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "            \n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            target_compression_ratio_percent /= 100\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "            compression_penalty = (target_compression_ratio_percent - compression_ratio) ** 2\n",
    "            loss = frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "    \n",
    "            metrics = {\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss\": loss,\n",
    "            }\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        del tensor_cuda, tensor, tt_factors, reconstructed_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                tensor_train_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.tensor_train_args = tensor_train_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                tensor_train_args=self.tensor_train_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, xk):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = [1] + list(np.round(xk).astype(int)) + [1]  # noqa: RUF005\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"raw_xk\": xk,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    free_rank = initial_rank[1:-1]\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"nelder-mead\",\n",
    "        \"l-bfgs-b\",\n",
    "        \"tnc\",\n",
    "        \"slsqp\",\n",
    "        \"powell\",\n",
    "        \"trust-constr\",\n",
    "        \"cobyla\",\n",
    "        \"cobyqa\",\n",
    "    ]\n",
    "\n",
    "    is_adaptive_variable_usable = [\"nelder-mead\"]\n",
    "\n",
    "    is_jac_variable_usable = [\n",
    "        \"cg\",\n",
    "        \"bfgs\",\n",
    "        \"newton-cg\",\n",
    "        \"l-bfgs-b\",\n",
    "        \"tnc\",\n",
    "        \"slsqp\",\n",
    "        \"trust-ncg\",\n",
    "        \"trust-krylov\",\n",
    "        \"trust-exact\",\n",
    "        \"trust-constr\",\n",
    "    ]\n",
    "\n",
    "    is_hess_variable_usable = [\"newton-cg\", \"dogleg\", \"trust-ncg\", \"trust-krylov\", \"trust-exact\", \" trust-constr\"]\n",
    "\n",
    "    is_callback_variable_not_usable = [\"tnc\", \"slsqp\", \"cobyla\"]\n",
    "\n",
    "    free_bounds = calculate_tt_bounds(tensor.shape)[1:-1] if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    adaptive = optimization_method.lower() in is_adaptive_variable_usable\n",
    "\n",
    "    jac = jac if optimization_method.lower() in is_jac_variable_usable else None\n",
    "    jac = None\n",
    "\n",
    "    hess = hess if optimization_method.lower() in is_hess_variable_usable else None\n",
    "\n",
    "    minimize_kwargs = {\n",
    "        \"fun\": loss_wrapper,\n",
    "        \"x0\": free_rank,\n",
    "        \"method\": optimization_method,\n",
    "        \"jac\": jac,\n",
    "        \"hess\": hess,\n",
    "        \"bounds\": free_bounds,\n",
    "        \"callback\": callback_param,\n",
    "        \"options\": {\n",
    "            \"disp\": True,\n",
    "            # \"maxiter\": 1000,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if adaptive:\n",
    "        minimize_kwargs[\"options\"][\"adaptive\"] = adaptive\n",
    "\n",
    "    if jac:\n",
    "        minimize_kwargs[\"jac\"] = jac\n",
    "\n",
    "    if hess:\n",
    "        minimize_kwargs[\"hess\"] = hess\n",
    "\n",
    "    # params\n",
    "\n",
    "    result = minimize(**minimize_kwargs)\n",
    "\n",
    "    optimal_rank = [1] + list(np.clip(np.round(result.x).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "    final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "fd7c39a887c6e830",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### global optimization",
   "id": "24729bb13807d588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.736754Z",
     "start_time": "2025-06-06T17:16:50.697746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_wrapper(\n",
    "        free_rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        frobenius_error_coef: float,\n",
    "        compression_ratio_coef: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    ") -> float:\n",
    "    full_rank = [1] + list(np.clip(np.round(free_rank).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "    try:\n",
    "        loss = loss_function(\n",
    "            rank=full_rank,\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio,\n",
    "            tensor_train_args=tensor_train_args,\n",
    "            frobenius_error_coef=frobenius_error_coef,\n",
    "            compression_ratio_coef=compression_ratio_coef,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        loss = float(\"inf\")\n",
    "    finally:\n",
    "        return loss"
   ],
   "id": "a5b90531f88bb212",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:16:50.809767Z",
     "start_time": "2025-06-06T17:16:50.765390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def global_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        tensor_train_args: dict[str, str],\n",
    "        initial_rank: list[int],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"differential_evolution\",\n",
    "        loss_function_fixed: Callable | None = None,\n",
    "):\n",
    "    def calculate_tt_bounds(tensor_shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculates the bounds for TT-ranks of a tensor based on its shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor_shape : tuple or list\n",
    "            List or tuple of tensor dimensions. Each element represents the size of the tensor along that dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of rank bounds in the format [(1, 1), (1, r1_max), ..., (1, 1)].\n",
    "\n",
    "        \"\"\"\n",
    "        d = len(tensor_shape)\n",
    "        bounds = [(1, 1)]\n",
    "\n",
    "        for k in range(1, d):\n",
    "            prod_left = 1\n",
    "            for i in range(k):\n",
    "                prod_left *= tensor_shape[i]\n",
    "\n",
    "            prod_right = 1\n",
    "            for j in range(k, d):\n",
    "                prod_right *= tensor_shape[j]\n",
    "\n",
    "            rk_max = min(prod_left, prod_right)\n",
    "            bounds.append((1, rk_max))\n",
    "\n",
    "        bounds.append((1, 1))\n",
    "        return bounds\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            tensor_train_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "\n",
    "            tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=rank, **tensor_train_args)\n",
    "            reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "            target_compression_ratio_percent /= 100\n",
    "    \n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "            compression_penalty = (target_compression_ratio_percent - compression_ratio) ** 2\n",
    "            loss = frobenius_error_coef * frobenius_error + compression_ratio_coef * compression_penalty\n",
    "    \n",
    "            metrics = {\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss\": loss,\n",
    "            }\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor_cuda, tensor, tt_factors, reconstructed_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                tensor_train_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.tensor_train_args = tensor_train_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                tensor_train_args=self.tensor_train_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, intermediate_result: OptimizeResult):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = [1] + list(np.round(intermediate_result.x).astype(int)) + [1]  # noqa: RUF005\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                    \"raw_results\": intermediate_result,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    loss_function_fixed = partial(\n",
    "        loss_wrapper,\n",
    "        tensor=tensor,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"differential_evolution\",\n",
    "    ]\n",
    "\n",
    "    is_callback_variable_not_usable = []\n",
    "\n",
    "    free_bounds = calculate_tt_bounds(tensor.shape)[1:-1] if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    if optimization_method == \"differential_evolution\":\n",
    "        optimization_kwargs_differential_evolution = {\n",
    "\n",
    "            \"func\": loss_function_fixed,\n",
    "            \"bounds\": free_bounds,\n",
    "\n",
    "            \"strategy\": \"best1bin\",\n",
    "            \"maxiter\": 50,\n",
    "            \"popsize\": 10,\n",
    "            \"tol\": 0.01,\n",
    "            \"atol\": 0.001,\n",
    "            \"mutation\": (0.3, 0.7),\n",
    "            \"recombination\": 0.9,\n",
    "            \"init\": \"latinhypercube\",\n",
    "            \"polish\": True,\n",
    "\n",
    "            \"workers\": 1,\n",
    "            \"updating\": \"immediate\", # {‘immediate’ - when 1 worker, ‘deferred’ - when more than 1 worker}\n",
    "\n",
    "            \"callback\": callback_param,\n",
    "            \"disp\": True,\n",
    "        }\n",
    "\n",
    "        result = differential_evolution(**optimization_kwargs_differential_evolution)\n",
    "\n",
    "        optimal_rank = [1] + list(np.clip(np.round(result.x).astype(int), 1, None)) + [1]  # noqa: RUF005\n",
    "        final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "a2515442ebd2fc67",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### check algs",
   "id": "3f1f59256c467672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://docs.scipy.org/doc/scipy-1.15.0/tutorial/optimize.html#",
   "id": "2b3a14c9ca8891aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### nelder-mead",
   "id": "47302bb20af108a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:05.667011Z",
     "start_time": "2025-06-06T17:16:50.836514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"nelder-mead\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_nelder_mead, iteration_logs_nelder_mead = local_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_nelder_mead,\n",
    "        \"steps_results\": iteration_logs_nelder_mead,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "6e659a5cf1fc85f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: nelder-mead\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 3 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 4 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 5 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 6 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 7 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 8 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "\n",
      "=== Iteration 9 complete ===\n",
      "New rank estimate: [1, 1, 1, 1]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.908761\n",
      "         Iterations: 10\n",
      "         Function evaluations: 39\n",
      "Optimal rank: [1, 1, 1, 1]\n",
      "Elapsed time: 13.851103 seconds\n",
      "Frobenius Error: 41.639394%\n",
      "Compression Ratio: 0.076395%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### powell",
   "id": "22b4dc9da590e2db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:49.728793Z",
     "start_time": "2025-06-06T17:17:05.724634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"powell\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_powell, iteration_logs_powell = local_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_powell,\n",
    "        \"steps_results\": iteration_logs_powell,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "332b57f9b01dbdc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: powell\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [1, 656, 2, 1]\n",
      "\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [1, 401, 2, 1]\n",
      "\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [1, 401, 2, 1]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.215818\n",
      "         Iterations: 3\n",
      "         Function evaluations: 138\n",
      "Optimal rank: [1, 401, 2, 1]\n",
      "Elapsed time: 43.084818 seconds\n",
      "Frobenius Error: 21.581759%\n",
      "Compression Ratio: 49.985932%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SLSQP",
   "id": "bc618dc9bd894791"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:51.316754Z",
     "start_time": "2025-06-06T17:17:49.787765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"slsqp\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_slsqp, iteration_logs_slsqp = local_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "        jac=None,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_slsqp,\n",
    "        \"steps_results\": iteration_logs_slsqp,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "1438dbd56e34fb3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: slsqp\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 2.9087606543916573\n",
      "            Iterations: 1\n",
      "            Function evaluations: 3\n",
      "            Gradient evaluations: 1\n",
      "Optimal rank: [1, 1, 1, 1]\n",
      "Elapsed time: 0.775754 seconds\n",
      "Frobenius Error: 41.639394%\n",
      "Compression Ratio: 0.076395%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### differential_evolution",
   "id": "c043c213b8d9a1c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:34.220723Z",
     "start_time": "2025-06-06T17:17:51.378266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"differential_evolution\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    with tl.backend_context(\"pytorch\"):\n",
    "        tensor_cuda = tl.tensor(example_tensor).to(\"cuda\")\n",
    "        tt_factors = tl.decomposition.tensor_train(tensor_cuda, rank=optimal_rank, **tensor_train_args)\n",
    "        reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "    \n",
    "        frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "        compression_ratio = (\n",
    "                100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(tensor_cuda)\n",
    "        )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_differential_evolution,\n",
    "        \"steps_results\": iteration_logs_differential_evolution,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "2527c08e405ac8cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: differential_evolution\n",
      "Tensor shape: (689, 1195, 3)\n",
      "differential_evolution step 1: f(x)= 0.00021813352015890506\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [1, 287, 3, 1]\n",
      "\n",
      "differential_evolution step 2: f(x)= 0.00021813352015890506\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [1, 287, 3, 1]\n",
      "\n",
      "differential_evolution step 3: f(x)= 0.00021813352015890506\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [1, 287, 3, 1]\n",
      "\n",
      "differential_evolution step 4: f(x)= 0.00010292673974682591\n",
      "\n",
      "=== Iteration 3 complete ===\n",
      "New rank estimate: [1, 289, 3, 1]\n",
      "\n",
      "differential_evolution step 5: f(x)= 0.00010292673974682591\n",
      "\n",
      "=== Iteration 4 complete ===\n",
      "New rank estimate: [1, 289, 3, 1]\n",
      "\n",
      "differential_evolution step 6: f(x)= 0.00010292673974682591\n",
      "\n",
      "=== Iteration 5 complete ===\n",
      "New rank estimate: [1, 289, 3, 1]\n",
      "\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "Optimal rank: [1, 289, 3, 1]\n",
      "Elapsed time: 42.662653 seconds\n",
      "Frobenius Error: 0.010288%\n",
      "Compression Ratio: 50.006579%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SHGO",
   "id": "78ac863bc4f17d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:34.292903Z",
     "start_time": "2025-06-06T17:18:34.254731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"shgo\"\n",
    "\n",
    "print(\n",
    "    f\"Testing optimization method: {method}\",\n",
    "    f\"Tensor shape: {example_tensor.shape}\",\n",
    "    f\"Initial rank: {example_tensor_initial_rank}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "try:\n",
    "    # check optimizer method\n",
    "    start_time = time.perf_counter()\n",
    "    optimal_rank, final_loss, minimize_result_shgo, iteration_logs_shgo = global_optimize_rank(\n",
    "        tensor=example_tensor,\n",
    "        target_compression_ratio=target_compression_ratio_algs,\n",
    "        tensor_train_args=tensor_train_args,\n",
    "        initial_rank=example_tensor_initial_rank,\n",
    "        optimization_method=method,\n",
    "        frobenius_error_coef=frobenius_error_coef_algs,\n",
    "        compression_ratio_coef=compression_ratio_coef_algs,\n",
    "    )\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    # check final frobenius error and compression ratio\n",
    "    tt_factors = tl.decomposition.tensor_train(example_tensor, rank=optimal_rank, **tensor_train_args)\n",
    "    reconstructed_tensor = tl.tt_to_tensor(tt_factors)\n",
    "\n",
    "    frobenius_error = 100.0 * (tl.norm(reconstructed_tensor - example_tensor) / tl.norm(example_tensor)).item()\n",
    "    compression_ratio = (\n",
    "            100.0 * IMetricCalculator.get_tensors_size(*tt_factors) / IMetricCalculator.get_tensors_size(example_tensor)\n",
    "    )\n",
    "\n",
    "    scipy_algs_results[method] = {\n",
    "        \"final_results\": minimize_result_shgo,\n",
    "        \"steps_results\": iteration_logs_shgo,\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"Optimal rank: {optimal_rank}\",\n",
    "        f\"Elapsed time: {elapsed_time:.6f} seconds\",\n",
    "        f\"Frobenius Error: {frobenius_error:.6f}%\",\n",
    "        f\"Compression Ratio: {compression_ratio:.6f}%\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error with method {method}: {e}\")"
   ],
   "id": "b0197d8d2ffac164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization method: shgo\n",
      "Tensor shape: (689, 1195, 3)\n",
      "Initial rank: [1, 1, 1, 1]\n",
      "Error with method shgo: cannot access local variable 'optimal_rank' where it is not associated with a value\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path of metrics in search area",
   "id": "c7a58c6bb73cc10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:34.988513Z",
     "start_time": "2025-06-06T17:18:34.320096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for method_name, method_results in scipy_algs_results.items():\n",
    "\n",
    "    metric_names = [\"frobenius_error\", \"compression_ratio\", \"compression_penalty\", \"loss_function_result\"]\n",
    "    frobenius_error_from_method, compression_ratio_from_method, compression_penalty_from_method, loss_from_method = [], [], [], []\n",
    "    for method_steps_logs in method_results['steps_results']:\n",
    "        frobenius_error_from_method.append(method_steps_logs[\"metrics\"][\"frobenius_error\"])\n",
    "        compression_ratio_from_method.append(method_steps_logs[\"metrics\"][\"compression_ratio\"])\n",
    "        compression_penalty_from_method.append(method_steps_logs[\"metrics\"][\"compression_penalty\"])\n",
    "        loss_from_method.append(method_steps_logs[\"metrics\"][\"loss\"])\n",
    "\n",
    "    figs = []\n",
    "\n",
    "    for metric, metric_data in zip(\n",
    "            metric_names,\n",
    "            [\n",
    "                frobenius_error_from_method,\n",
    "                compression_ratio_from_method,\n",
    "                compression_penalty_from_method,\n",
    "                loss_from_method,\n",
    "            ],\n",
    "            strict=False,\n",
    "    ):\n",
    "        z_values = np.array(\n",
    "            [search_area_example_results[key].get(metric, np.nan) for key in search_area_example_results])\n",
    "        x_indices = internal_indices[:, 0]\n",
    "        y_indices = internal_indices[:, 1]\n",
    "\n",
    "        # Поиск локальных минимумов\n",
    "        local_min_points = []\n",
    "\n",
    "        metric_dict = {tuple(idx): search_area_example_results[idx] for idx in search_area_example_results}\n",
    "\n",
    "        for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "            z = z_values[i]\n",
    "\n",
    "            neighbors = [\n",
    "                (x - 1, y), (x + 1, y),  # По оси X\n",
    "                (x, y - 1), (x, y + 1)  # По оси Y\n",
    "            ]\n",
    "\n",
    "            is_local_min = all(\n",
    "                (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "                for neighbor in neighbors\n",
    "            )\n",
    "\n",
    "            if is_local_min:\n",
    "                local_min_points.append((x, y, z))\n",
    "\n",
    "        x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Основные точки\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x_indices,\n",
    "            y=y_indices,\n",
    "            z=z_values,\n",
    "            mode=\"markers\",\n",
    "            marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "        ))\n",
    "\n",
    "        path_x = []\n",
    "        path_y = []\n",
    "        path_z = []\n",
    "\n",
    "        for i, log in enumerate(method_results['steps_results']):\n",
    "            rank = log[\"rank\"]\n",
    "            if metric == \"frobenius_error\":\n",
    "                z_value = frobenius_error_from_method[i]\n",
    "            elif metric == \"compression_ratio\":\n",
    "                z_value = compression_ratio_from_method[i]\n",
    "            elif metric == \"compression_penalty\":\n",
    "                z_value = compression_penalty_from_method[i]\n",
    "            elif metric == \"loss_function_result\":\n",
    "                z_value = loss_from_method[i]\n",
    "\n",
    "            path_x.append(rank[1])\n",
    "            path_y.append(rank[2])\n",
    "            path_z.append(z_value)\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=[rank[1]],\n",
    "                    y=[rank[2]],\n",
    "                    z=[z_value],\n",
    "                    mode=\"markers\",\n",
    "                    marker={\n",
    "                        \"size\": 10 if i == 0 or i == len(method_results['steps_results']) - 1 else 5,\n",
    "                        \"color\": \"yellow\" if i == 0 or i == len(method_results['steps_results']) - 1 else \"red\",\n",
    "                        \"opacity\": 0.8,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Добавляем локальные минимумы (выделенные точки)\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x_min,\n",
    "            y=y_min,\n",
    "            z=z_min,\n",
    "            mode=\"markers+text\",\n",
    "            marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "            text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "            textposition=\"top center\",\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=path_x,\n",
    "                y=path_y,\n",
    "                z=path_z,\n",
    "                mode=\"lines+markers\",\n",
    "                marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "                line={\"color\": \"red\", \"width\": 3},\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with {method_name} alg path\",\n",
    "            height=800,\n",
    "            scene={\n",
    "                \"xaxis_title\": \"Rank Index 2\",\n",
    "                \"yaxis_title\": \"Rank Index 3\",\n",
    "                \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "                \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "            },\n",
    "            margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "            template=\"plotly_white\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "        figs.append(fig)\n",
    "\n",
    "    html_str = \"\"\n",
    "    for fig in figs:\n",
    "        html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "    html_file = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Search area by some metrics</h1>\n",
    "    {html_str}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_{method_name}_alg.html\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "        f.write(html_file)"
   ],
   "id": "8a3a2d6ab43e06f1",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimization alg for target tensor",
   "id": "9b5475496caef09d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculation",
   "id": "fa4ab92e29e43433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:35.055242Z",
     "start_time": "2025-06-06T17:18:35.015550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.utils.eeg_controller import create_eeg_limo_data_tensor\n",
    "# \n",
    "# cache_dir_eeg = \"../.cache/eeg\"\n",
    "# \n",
    "# target_tensor = create_eeg_limo_data_tensor(cache_dir_eeg=cache_dir_eeg)\n",
    "# target_initial_rank = calculate_tensor_train_initial_rank(calculate_tt_bounds(target_tensor.shape))"
   ],
   "id": "51bab3e1cd07fc74",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:35.119002Z",
     "start_time": "2025-06-06T17:18:35.086228Z"
    }
   },
   "cell_type": "code",
   "source": "# calculate_tt_bounds(target_tensor.shape)",
   "id": "979a4ee264cb50b7",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:18:35.177355Z",
     "start_time": "2025-06-06T17:18:35.145281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# method = \"differential_evolution\"\n",
    "# \n",
    "# scipy_target_tensor_results = {}\n",
    "# \n",
    "# print(\n",
    "#     f\"Testing optimization method: {method}\",\n",
    "#     f\"Tensor shape: {target_tensor.shape}\",\n",
    "#     sep=\"\\n\",\n",
    "# )\n",
    "# try:\n",
    "#     # check optimizer method\n",
    "#     start_time = time.perf_counter()\n",
    "#     optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "#         tensor=target_tensor,\n",
    "#         target_compression_ratio=target_compression_ratio_algs,\n",
    "#         tensor_train_args=tensor_train_args,\n",
    "#         initial_rank=target_initial_rank,\n",
    "#         optimization_method=method,\n",
    "#         frobenius_error_coef=frobenius_error_coef_algs,\n",
    "#         compression_ratio_coef=compression_ratio_coef_algs,\n",
    "#     )\n",
    "#     elapsed_time = time.perf_counter() - start_time\n",
    "# \n",
    "#     scipy_target_tensor_results[method] = {\n",
    "#         \"final_results\": minimize_result_differential_evolution,\n",
    "#         \"steps_results\": iteration_logs_differential_evolution,\n",
    "#     }\n",
    "# except Exception as e:\n",
    "#     print(f\"Error with method {method}: {e}\")"
   ],
   "id": "1de98a8c72a9839d",
   "outputs": [],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
