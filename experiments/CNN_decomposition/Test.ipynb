{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.314657Z",
     "start_time": "2025-01-30T16:28:24.478837Z"
    }
   },
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import tensorly as tl\n",
    "from torchvision.models import resnet18\n",
    "from tensorly.decomposition import tucker, parafac\n",
    "from flopco import FlopCo\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "tl.set_backend(\"pytorch\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.322793Z",
     "start_time": "2025-01-30T16:28:26.320479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "in_channels = 64\n",
    "out_channels = 128\n",
    "kernel_size = (3, 3)\n",
    "tensor_size = 7\n",
    "# rank_CPD = 9\n",
    "# rank_TKD = (256, 101, 9)\n",
    "number_of_images = 128"
   ],
   "id": "8ec3a4fccab9ae2e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Original conv",
   "id": "2632cd96f97354b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.377829Z",
     "start_time": "2025-01-30T16:28:26.374390Z"
    }
   },
   "cell_type": "code",
   "source": "full_conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size, dtype=torch.float32)",
   "id": "58fb7c4b8f71ef99",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.422664Z",
     "start_time": "2025-01-30T16:28:26.418547Z"
    }
   },
   "cell_type": "code",
   "source": "random_tensor = torch.rand(number_of_images, in_channels, tensor_size, tensor_size, dtype=torch.float32)",
   "id": "95f188119b444e70",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.468892Z",
     "start_time": "2025-01-30T16:28:26.466306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%timeit -r 10 -n 10000\n",
    "# full_conv(random_tensor)"
   ],
   "id": "a5f829a66d39fbe8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CPD-only conv",
   "id": "73eeb2a54e252730"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.516960Z",
     "start_time": "2025-01-30T16:28:26.512497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def SVD_conv(conv_layer: torch.nn.Conv2d, rank_CPD: int = None) -> (torch.nn.Sequential, float):\n",
    "    out_channels = conv_layer.out_channels\n",
    "    in_channels = conv_layer.in_channels\n",
    "    stride = conv_layer.stride\n",
    "    matrix = conv_layer.weight.squeeze().squeeze()\n",
    "    if rank_CPD is None:\n",
    "        rank_CPD = min(matrix.shape)\n",
    "        \n",
    "    core, factors = parafac(matrix, rank_CPD, init=\"random\")\n",
    "    norm = tl.norm(matrix - tl.cp_to_tensor((core, factors))) / tl.norm(matrix)\n",
    "    print(f\"SVD ({in_channels}, {out_channels}, (1, 1)): {norm}\")\n",
    "\n",
    "    factor_CPD_input = factors[1].permute([1, 0]).unsqueeze(2).unsqueeze(3)\n",
    "    factor_CPD_output = factors[0].unsqueeze(2).unsqueeze(3)\n",
    "    \n",
    "\n",
    "    conv1 = torch.nn.Conv2d(in_channels, rank_CPD, 1, stride=stride, dtype=torch.float32)\n",
    "    conv2 = torch.nn.Conv2d(rank_CPD, out_channels, 1, dtype=torch.float32)\n",
    "    conv1.weight = torch.nn.parameter.Parameter(factor_CPD_input)\n",
    "    conv2.weight = torch.nn.parameter.Parameter(factor_CPD_output)\n",
    "    return torch.nn.Sequential(conv1, conv2), norm"
   ],
   "id": "d582b8c41f99710e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.569863Z",
     "start_time": "2025-01-30T16:28:26.565456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def CPD_conv(conv_layer: torch.nn.Conv2d, rank_CPD: int = None) -> (torch.nn.Sequential, float):\n",
    "    if conv_layer.kernel_size == (1, 1):\n",
    "        return SVD_conv(conv_layer, rank_CPD)\n",
    "    # Params of source conv_layer\n",
    "    out_channels = conv_layer.out_channels\n",
    "    in_channels = conv_layer.in_channels\n",
    "    kernel_size_x = conv_layer.kernel_size[0]\n",
    "    kernel_size_y = conv_layer.kernel_size[1]\n",
    "    stride = conv_layer.stride\n",
    "    padding = conv_layer.padding\n",
    "    dilation = conv_layer.dilation\n",
    "    conv_weight = conv_layer.weight.reshape(out_channels, in_channels, kernel_size_x * kernel_size_y)\n",
    "    \n",
    "    if rank_CPD is None:\n",
    "        rank_CPD = sorted(conv_weight.size())[0]\n",
    "    # elif rank_CPD > sorted(conv_weight.size())[0]:\n",
    "    #     rank_CPD = sorted(conv_weight.size())[0]\n",
    "    #     warnings.warn(\n",
    "    #         f\"\"\"\n",
    "    #         rank_CPD > min(f{conv_weight.size()})\n",
    "    #         rank_CPD is bigger than the smallest size of tensor dimension\n",
    "    #         rank_CPD is set to min(f{conv_weight.size()})\n",
    "    #         \"\"\"\n",
    "    #     )\n",
    "\n",
    "    core_CPD, factors_CPD = parafac(conv_weight, rank_CPD, init=\"random\", svd=\"randomized_svd\")\n",
    "    norm = tl.norm(conv_weight - tl.cp_to_tensor((core_CPD, factors_CPD))) / tl.norm(conv_weight)\n",
    "    print(f\"CPD ({in_channels}, {out_channels}, ({kernel_size_x}, {kernel_size_y})): {norm}\")\n",
    "\n",
    "    factor_CPD_input = factors_CPD[1].permute([1, 0]).unsqueeze(2).unsqueeze(3)\n",
    "    factor_CPD_hidden = factors_CPD[2].permute([1, 0]).unsqueeze(1).reshape(rank_CPD, 1, kernel_size_x, kernel_size_y)\n",
    "    factor_CPD_output = factors_CPD[0].unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    conv1_CPD = torch.nn.Conv2d(in_channels, rank_CPD, 1, dtype=torch.float32)\n",
    "    conv2_CPD = torch.nn.Conv2d(rank_CPD, rank_CPD, (kernel_size_x, kernel_size_y), groups=rank_CPD, stride=stride, padding=padding, dilation=dilation, dtype=torch.float32)\n",
    "    conv3_CPD = torch.nn.Conv2d(rank_CPD, out_channels, 1, dtype=torch.float32)\n",
    "    conv1_CPD.weight = torch.nn.parameter.Parameter(factor_CPD_input)\n",
    "    conv2_CPD.weight = torch.nn.parameter.Parameter(factor_CPD_hidden)\n",
    "    conv3_CPD.weight = torch.nn.parameter.Parameter(factor_CPD_output)\n",
    "    \n",
    "    return torch.nn.Sequential(conv1_CPD, conv2_CPD, conv3_CPD), norm"
   ],
   "id": "f789a24ecd535cad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.949543Z",
     "start_time": "2025-01-30T16:28:26.621055Z"
    }
   },
   "cell_type": "code",
   "source": "conv_CPD = CPD_conv(full_conv, rank_CPD=64)[0]",
   "id": "9d96b2f2763f8798",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD (64, 128, (3, 3)): 0.820536732673645\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:26.964565Z",
     "start_time": "2025-01-30T16:28:26.963116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%timeit -r 10 -n 10000\n",
    "# conv_CPD(random_tensor)"
   ],
   "id": "395d60af8b37159a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:27.130903Z",
     "start_time": "2025-01-30T16:28:27.049372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del conv_CPD\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "b998b3f40e2e3d3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TKD-only conv",
   "id": "295e757180b65a91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:27.253900Z",
     "start_time": "2025-01-30T16:28:27.249220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def TKD_conv(conv_layer: torch.nn.Conv2d, rank_TKD: tuple[int, int, int]=None) -> (torch.nn.Sequential, float):\n",
    "    if conv_layer.kernel_size == (1, 1):\n",
    "        return SVD_conv(conv_layer, min(rank_TKD))\n",
    "    # Params of source conv_layer\n",
    "    out_channels = conv_layer.out_channels\n",
    "    in_channels = conv_layer.in_channels\n",
    "    kernel_size_x = conv_layer.kernel_size[0]\n",
    "    kernel_size_y = conv_layer.kernel_size[1]\n",
    "    stride = conv_layer.stride\n",
    "    padding = conv_layer.padding\n",
    "    dilation = conv_layer.dilation\n",
    "    conv_weight = conv_layer.weight.reshape(out_channels, in_channels, kernel_size_x * kernel_size_y)\n",
    "    \n",
    "    if rank_TKD is None:\n",
    "        rank_TKD = (out_channels, in_channels, kernel_size_x * kernel_size_y)\n",
    "    else:\n",
    "        if rank_TKD[0] > out_channels:\n",
    "            rank_TKD = (out_channels, rank_TKD[1], rank_TKD[2])\n",
    "            warnings.warn(\"rank_TKD[0] is bigger then out_channels\")\n",
    "        if rank_TKD[1] > in_channels:\n",
    "            rank_TKD = (rank_TKD[0], in_channels, rank_TKD[2])\n",
    "            warnings.warn(\"rank_TKD[1] is bigger then in_channels\")\n",
    "        if rank_TKD[2] > kernel_size_x * kernel_size_y:\n",
    "            rank_TKD = (rank_TKD[0], rank_TKD[1], kernel_size_x * kernel_size_y)\n",
    "            warnings.warn(\"rank_TKD[2] is bigger then kernel_size_x * kernel_size_y\")\n",
    "    \n",
    "    core_TKD, factors_TKD = tucker(conv_weight, rank_TKD)\n",
    "    norm = tl.norm(conv_weight - tl.tucker_to_tensor((core_TKD, factors_TKD))) / tl.norm(conv_weight)\n",
    "    print(f\"TKD ({in_channels}, {out_channels}, ({kernel_size_x}, {kernel_size_y})): {norm}\")\n",
    "\n",
    "    factor_TKD_input = factors_TKD[1].permute([1, 0]).unsqueeze(2).unsqueeze(3)\n",
    "    factor_TKD_hidden = torch.tensordot(factors_TKD[2], core_TKD, dims=([1], [2])).permute([1, 2, 0]).reshape(rank_TKD[0], rank_TKD[1], kernel_size_x, kernel_size_y)\n",
    "    factor_TKD_output = factors_TKD[0].unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    conv1_TKD = torch.nn.Conv2d(in_channels, rank_TKD[1], 1, dtype=torch.float32)\n",
    "    conv2_TKD = torch.nn.Conv2d(rank_TKD[1], rank_TKD[0], (kernel_size_x, kernel_size_y), stride=stride, padding=padding, dilation=dilation, dtype=torch.float32)\n",
    "    conv3_TKD = torch.nn.Conv2d(rank_TKD[0], out_channels, 1, dtype=torch.float32)\n",
    "    conv1_TKD.weight = torch.nn.parameter.Parameter(factor_TKD_input)\n",
    "    conv2_TKD.weight = torch.nn.parameter.Parameter(factor_TKD_hidden)\n",
    "    conv3_TKD.weight = torch.nn.parameter.Parameter(factor_TKD_output)\n",
    "    \n",
    "    return torch.nn.Sequential(conv1_TKD, conv2_TKD, conv3_TKD), norm"
   ],
   "id": "749545e8bc911909",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:27.694020Z",
     "start_time": "2025-01-30T16:28:27.392788Z"
    }
   },
   "cell_type": "code",
   "source": "conv_TKD = TKD_conv(full_conv)[0]",
   "id": "536029f3d0eb1dea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TKD (64, 128, (3, 3)): 1.2182272257632576e-06\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:27.840802Z",
     "start_time": "2025-01-30T16:28:27.838401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%timeit -r 10 -n 10000\n",
    "# conv_TKD(random_tensor)"
   ],
   "id": "76b07880bb3ac725",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:28.036838Z",
     "start_time": "2025-01-30T16:28:27.954421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del conv_TKD\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "e7e4b16a6d5adf58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TKD-CPD conv",
   "id": "fa38d51e70535fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:28.161451Z",
     "start_time": "2025-01-30T16:28:28.157042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def TKDCPD_conv(conv_layer: torch.nn.Conv2d, rank_TKD:tuple[int, int, int] = None, rank_CPD: int = None) -> (torch.nn.Sequential, float):\n",
    "    if conv_layer.kernel_size == (1, 1):\n",
    "        return SVD_conv(conv_layer, rank_CPD)\n",
    "    # Params of source conv_layer\n",
    "    out_channels = conv_layer.out_channels\n",
    "    in_channels = conv_layer.in_channels\n",
    "    kernel_size_x = conv_layer.kernel_size[0]\n",
    "    kernel_size_y = conv_layer.kernel_size[1]\n",
    "    stride = conv_layer.stride\n",
    "    padding = conv_layer.padding\n",
    "    dilation = conv_layer.dilation\n",
    "    conv_weight = conv_layer.weight.reshape(out_channels, in_channels, kernel_size_x * kernel_size_y)\n",
    "\n",
    "    if rank_TKD is None:\n",
    "        rank_TKD = (out_channels, in_channels, kernel_size_x * kernel_size_y)\n",
    "    else:\n",
    "        if rank_TKD[0] > out_channels:\n",
    "            rank_TKD = (out_channels, rank_TKD[1], rank_TKD[2])\n",
    "            warnings.warn(f\"rank_TKD[0] is bigger then out_channels\\n\\nrank_TKD[0]={rank_TKD[0]}\\nout_channels={out_channels}\")\n",
    "        if rank_TKD[1] > in_channels:\n",
    "            rank_TKD = (rank_TKD[0], in_channels, rank_TKD[2])\n",
    "            warnings.warn(f\"rank_TKD[1] is bigger then in_channels\\n\\nrank_TKD[1]={rank_TKD[1]}\\nin_channels={in_channels}\")\n",
    "        if rank_TKD[2] > kernel_size_x * kernel_size_y:\n",
    "            rank_TKD = (rank_TKD[0], rank_TKD[1], kernel_size_x * kernel_size_y)\n",
    "            warnings.warn(f\"rank_TKD[2] is bigger then kernel_size_x * kernel_size_y\\nrank_TKD[2]={rank_TKD[2]}\\nkernel_size_x * kernel_size_y={kernel_size_x * kernel_size_y}\")\n",
    "    \n",
    "    core_TKD, factors_TKD = tucker(conv_weight, rank_TKD)\n",
    "    norm = tl.norm(conv_weight - tl.tucker_to_tensor((core_TKD, factors_TKD))) / tl.norm(conv_weight)\n",
    "    print(f\"TKDCPD ({in_channels}, {out_channels}, ({kernel_size_x}, {kernel_size_y})): {norm}\")\n",
    "\n",
    "    factor_TKD_input = factors_TKD[1].permute([1, 0]).unsqueeze(2).unsqueeze(3)\n",
    "    factor_TKD_hidden = torch.tensordot(factors_TKD[2], core_TKD, dims=([1], [2])).permute([1, 2, 0]).reshape(rank_TKD[0], rank_TKD[1], kernel_size_x, kernel_size_y)\n",
    "    factor_TKD_output = factors_TKD[0].unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    conv2_TKD = torch.nn.Conv2d(rank_TKD[1], rank_TKD[0], (kernel_size_x, kernel_size_y), stride=stride, padding=padding, dilation=dilation, dtype=torch.float32)\n",
    "    conv2_TKD.weight = torch.nn.parameter.Parameter(factor_TKD_hidden)\n",
    "    conv2_TKD = CPD_conv(conv2_TKD, rank_CPD=rank_CPD)\n",
    "    norm = conv2_TKD[1]\n",
    "    conv2_TKD = conv2_TKD[0]\n",
    "\n",
    "    conv1_TKD = torch.nn.Conv2d(in_channels, rank_TKD[1], 1, dtype=torch.float32)\n",
    "    conv3_TKD = torch.nn.Conv2d(rank_TKD[0], out_channels, 1, dtype=torch.float32)\n",
    "    conv1_TKD.weight = torch.nn.parameter.Parameter(factor_TKD_input)\n",
    "    conv3_TKD.weight = torch.nn.parameter.Parameter(factor_TKD_output)\n",
    "\n",
    "    return torch.nn.Sequential(conv1_TKD, conv2_TKD, conv3_TKD), norm"
   ],
   "id": "eee719b0679f783f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:28.571145Z",
     "start_time": "2025-01-30T16:28:28.327078Z"
    }
   },
   "cell_type": "code",
   "source": "conv_TKDCPD = TKDCPD_conv(full_conv)",
   "id": "b49f5dd3624b5249",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TKDCPD (64, 128, (3, 3)): 1.2182272257632576e-06\n",
      "CPD (64, 128, (3, 3)): 0.9747201800346375\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:28.674775Z",
     "start_time": "2025-01-30T16:28:28.672700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%timeit -r 10 -n 10000\n",
    "# conv_TKDCPD(random_tensor)"
   ],
   "id": "c6a4dad5910286ec",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:28.830567Z",
     "start_time": "2025-01-30T16:28:28.746694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del conv_TKDCPD\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "80824388dbba9eb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## STATS",
   "id": "15c183b7aa323f1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:28.979901Z",
     "start_time": "2025-01-30T16:28:28.977740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# stats_conv = FlopCo(full_conv, img_size=[number_of_images, in_channels, tensor_size, tensor_size], device=device)\n",
    "# stats_CPD = FlopCo(conv_CPD, img_size=[number_of_images, in_channels, tensor_size, tensor_size], device=device)\n",
    "# stats_TKD = FlopCo(conv_TKD, img_size=[number_of_images, in_channels, tensor_size, tensor_size], device=device)\n",
    "# stats_TKDCPD = FlopCo(conv_TKDCPD, img_size=[number_of_images, in_channels, tensor_size, tensor_size], device=device)"
   ],
   "id": "2f006490f3ce86e3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:29.295007Z",
     "start_time": "2025-01-30T16:28:29.292841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"Normal conv:\")\n",
    "# print(stats_conv)\n",
    "# print(\"\\nCPD:\")\n",
    "# print(stats_CPD)\n",
    "# print(\"\\nTKD:\")\n",
    "# print(stats_TKD)\n",
    "# print(\"\\nTKDCPD:\")\n",
    "# print(stats_TKDCPD)"
   ],
   "id": "e49648e695050cf9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:29.489411Z",
     "start_time": "2025-01-30T16:28:29.487909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"FLOPS\")\n",
    "# print(f\"{stats_conv.total_flops/10e6}e6; {stats_CPD.total_flops/10e6}e6; {stats_TKD.total_flops/10e6}e6; {stats_TKDCPD.total_flops/10e6}e6\")\n",
    "# print(\"\\nRelative Flops\")\n",
    "# print(f\"{stats_conv.relative_flops}\\n{stats_CPD.relative_flops}\\n{stats_TKD.relative_flops}\\n{stats_TKDCPD.relative_flops}\")\n",
    "# print(\"\\nParameters\")\n",
    "# print(f\"{stats_conv.total_params}; {stats_CPD.total_params}; {stats_TKD.total_params}; {stats_TKDCPD.total_params}\")\n",
    "# print(\"\\nRelative parameters\")\n",
    "# print(f\"{stats_conv.relative_params}\\n{stats_CPD.relative_params}\\n{stats_TKD.relative_params}\\n{stats_TKDCPD.relative_params}\")"
   ],
   "id": "ae1dff131a0edfca",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Convert RESNET",
   "id": "e301d434441caecf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:29.533923Z",
     "start_time": "2025-01-30T16:28:29.531209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def replace_conv_layers(module, conv_func):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Conv2d):\n",
    "            weight = child.weight.size()\n",
    "            TKD, _ = conv_func(child, [max(weight[0], 1), max(weight[1], 1), weight[2] * weight[3]])\n",
    "            setattr(module, name, TKD)\n",
    "        else:\n",
    "            replace_conv_layers(child, conv_func)"
   ],
   "id": "4e7e4c3af219bca",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:37.209695Z",
     "start_time": "2025-01-30T16:28:29.584782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def save_results(conv_func_name, rank, stats, norms):\n",
    "    # Define the directory structure\n",
    "    dir_path = f\"./{conv_func_name}/{rank}/\"\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Save FLOPS and parameter counts\n",
    "    stats_data = {\n",
    "        \"total_flops\": stats.total_flops,\n",
    "        \"total_params\": stats.total_params,\n",
    "        \"relative_flops\": stats.relative_flops,\n",
    "        \"relative_params\": stats.relative_params\n",
    "    }\n",
    "    with open(f\"{dir_path}flops_params.json\", \"w\") as f:\n",
    "        json.dump(stats_data, f, indent=4)\n",
    "\n",
    "    # Save norms of each layer\n",
    "    with open(f\"{dir_path}layer_norms.txt\", \"w\") as f:\n",
    "        for layer_name, norm_value in norms.items():\n",
    "            f.write(f\"{layer_name}: {norm_value}\\n\")\n",
    "    print(f\"Results saved in {dir_path}\")\n",
    "\n",
    "# Define the range of ranks you want to iterate over\n",
    "rank_range = range(41, 42)\n",
    "\n",
    "# Initialize your ResNet model\n",
    "resnet_model = resnet18(weights='DEFAULT')\n",
    "\n",
    "# Loop over the specified ranks and compress the ResNet with each rank\n",
    "for rank in rank_range:\n",
    "    print(f\"Compressing with rank_CPD = {rank}\")\n",
    "\n",
    "    # Clone the model to avoid overwriting the original\n",
    "    model_copy = resnet18(weights='DEFAULT')\n",
    "    \n",
    "    # Compress the model, storing norms of each layer\n",
    "    replace_conv_layers(model_copy, TKD_conv)\n",
    "\n",
    "    # Capture statistics with FlopCo\n",
    "    stats_CPD = FlopCo(model_copy, device=\"cpu\")\n",
    "\n",
    "    # Save the results\n",
    "    # save_results(\"CPD_conv\", rank, stats_CPD, 0)\n",
    "\n",
    "    # Clear cache\n",
    "    del model_copy\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ],
   "id": "dac1adf11de21356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing with rank_CPD = 41\n",
      "TKD (3, 64, (7, 7)): 9.743340569912107e-07\n",
      "TKD (64, 64, (3, 3)): 1.1181640502400114e-06\n",
      "TKD (64, 64, (3, 3)): 1.1904247685379232e-06\n",
      "TKD (64, 64, (3, 3)): 1.0448459306644509e-06\n",
      "TKD (64, 64, (3, 3)): 1.1266018873357098e-06\n",
      "TKD (64, 128, (3, 3)): 1.2282486068215803e-06\n",
      "TKD (128, 128, (3, 3)): 1.2825962585338857e-06\n",
      "SVD (64, 128, (1, 1)): 0.9541822075843811\n",
      "TKD (128, 128, (3, 3)): 1.3969146266390453e-06\n",
      "TKD (128, 128, (3, 3)): 1.3236360700830119e-06\n",
      "TKD (128, 256, (3, 3)): 1.5402448525492218e-06\n",
      "TKD (256, 256, (3, 3)): 1.656385620663059e-06\n",
      "SVD (128, 256, (1, 1)): 0.9790937304496765\n",
      "TKD (256, 256, (3, 3)): 1.7054817362804897e-06\n",
      "TKD (256, 256, (3, 3)): 1.6958357491603238e-06\n",
      "TKD (256, 512, (3, 3)): 1.793696469576389e-06\n",
      "TKD (512, 512, (3, 3)): 1.972041218323284e-06\n",
      "SVD (256, 512, (1, 1)): 0.9850214719772339\n",
      "TKD (512, 512, (3, 3)): 1.971262690858566e-06\n",
      "TKD (512, 512, (3, 3)): 1.927569201143342e-06\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test compressed",
   "id": "533b687ad8a4f43c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:50.592875Z",
     "start_time": "2025-01-30T16:28:37.232472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compressed_resnet18 = resnet18(weights='DEFAULT')\n",
    "replace_conv_layers(compressed_resnet18, TKDCPD_conv)"
   ],
   "id": "4d12e7b399626971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TKDCPD (3, 64, (7, 7)): 9.743340569912107e-07\n",
      "CPD (3, 64, (7, 7)): 0.8474209904670715\n",
      "TKDCPD (64, 64, (3, 3)): 1.1181640502400114e-06\n",
      "CPD (64, 64, (3, 3)): 0.7477900385856628\n",
      "TKDCPD (64, 64, (3, 3)): 1.1904247685379232e-06\n",
      "CPD (64, 64, (3, 3)): 0.8478550910949707\n",
      "TKDCPD (64, 64, (3, 3)): 1.0448459306644509e-06\n",
      "CPD (64, 64, (3, 3)): 0.8203519582748413\n",
      "TKDCPD (64, 64, (3, 3)): 1.1266018873357098e-06\n",
      "CPD (64, 64, (3, 3)): 0.8956947922706604\n",
      "TKDCPD (64, 128, (3, 3)): 1.2282486068215803e-06\n",
      "CPD (64, 128, (3, 3)): 0.9195433855056763\n",
      "TKDCPD (128, 128, (3, 3)): 1.2825962585338857e-06\n",
      "CPD (128, 128, (3, 3)): 0.894120454788208\n",
      "SVD (64, 128, (1, 1)): 0.0019077861215919256\n",
      "TKDCPD (128, 128, (3, 3)): 1.3969146266390453e-06\n",
      "CPD (128, 128, (3, 3)): 0.932137131690979\n",
      "TKDCPD (128, 128, (3, 3)): 1.3236360700830119e-06\n",
      "CPD (128, 128, (3, 3)): 0.9149534702301025\n",
      "TKDCPD (128, 256, (3, 3)): 1.5402448525492218e-06\n",
      "CPD (128, 256, (3, 3)): 0.9266303181648254\n",
      "TKDCPD (256, 256, (3, 3)): 1.656385620663059e-06\n",
      "CPD (256, 256, (3, 3)): 0.9544380307197571\n",
      "SVD (128, 256, (1, 1)): 0.002942524151876569\n",
      "TKDCPD (256, 256, (3, 3)): 1.7054817362804897e-06\n",
      "CPD (256, 256, (3, 3)): 0.9555202722549438\n",
      "TKDCPD (256, 256, (3, 3)): 1.6958357491603238e-06\n",
      "CPD (256, 256, (3, 3)): 0.9389451146125793\n",
      "TKDCPD (256, 512, (3, 3)): 1.793696469576389e-06\n",
      "CPD (256, 512, (3, 3)): 0.9548648595809937\n",
      "TKDCPD (512, 512, (3, 3)): 1.972041218323284e-06\n",
      "CPD (512, 512, (3, 3)): 0.974004328250885\n",
      "SVD (256, 512, (1, 1)): 0.0013117233756929636\n",
      "TKDCPD (512, 512, (3, 3)): 1.971262690858566e-06\n",
      "CPD (512, 512, (3, 3)): 0.9497768878936768\n",
      "TKDCPD (512, 512, (3, 3)): 1.927569201143342e-06\n",
      "CPD (512, 512, (3, 3)): 0.9610151648521423\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:50.813015Z",
     "start_time": "2025-01-30T16:28:50.623324Z"
    }
   },
   "cell_type": "code",
   "source": "test_tensor = torch.rand(128, 3, 224, 224).to(device)",
   "id": "88f357d39fadf5f4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:50.922912Z",
     "start_time": "2025-01-30T16:28:50.816444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uncompressed_resnet18 = resnet18(weights='DEFAULT').to(device).eval()\n",
    "compressed_resnet18 = compressed_resnet18.to(device).eval()"
   ],
   "id": "68ac53856c03959f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:50.979817Z",
     "start_time": "2025-01-30T16:28:50.978085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%timeit -r 10 -n 100\n",
    "# with torch.amp.autocast('cuda'):\n",
    "#     uncompressed_resnet18(test_tensor)"
   ],
   "id": "4b6003e6bcc08782",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.022628Z",
     "start_time": "2025-01-30T16:28:51.020790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%timeit -r 10 -n 100\n",
    "# with torch.amp.autocast('cuda'):\n",
    "#     compressed_resnet18(test_tensor)"
   ],
   "id": "4ae3f4e0866051ea",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.224577Z",
     "start_time": "2025-01-30T16:28:51.076774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stats_uncompressed = FlopCo(uncompressed_resnet18, device=device)\n",
    "stats_compressed = FlopCo(compressed_resnet18, device=device)"
   ],
   "id": "eadf673556ffe5cf",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.249663Z",
     "start_time": "2025-01-30T16:28:51.247131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"FLOPS\")\n",
    "print(f\"{stats_uncompressed.total_flops/10e6}e6; {stats_compressed.total_flops/10e6}e6\")\n",
    "print(\"\\nParameters\")\n",
    "print(f\"{stats_uncompressed.total_params}; {stats_compressed.total_params}\")"
   ],
   "id": "de5eac3e6c22e03e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS\n",
      "362.81472e6; 106.1259415e6\n",
      "\n",
      "Parameters\n",
      "11679912; 3381958\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.296779Z",
     "start_time": "2025-01-30T16:28:51.293109Z"
    }
   },
   "cell_type": "code",
   "source": "compressed_resnet18",
   "id": "8b6308c3a6117155",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(3, 3, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=3)\n",
       "      (2): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(512, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(512, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(512, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9)\n",
       "          (2): Conv2d(9, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.380981Z",
     "start_time": "2025-01-30T16:28:51.376791Z"
    }
   },
   "cell_type": "code",
   "source": "dict(sorted(stats_uncompressed.relative_params.items(), key=lambda item: item[1], reverse=True))",
   "id": "d5bc58e30501a63c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer4.0.conv2': 0.20199604243593616,\n",
       " 'layer4.1.conv1': 0.20199604243593616,\n",
       " 'layer4.1.conv2': 0.20199604243593616,\n",
       " 'layer4.0.conv1': 0.10099802121796808,\n",
       " 'layer3.0.conv2': 0.05049901060898404,\n",
       " 'layer3.1.conv1': 0.05049901060898404,\n",
       " 'layer3.1.conv2': 0.05049901060898404,\n",
       " 'fc': 0.04392156379260392,\n",
       " 'layer3.0.conv1': 0.02524950530449202,\n",
       " 'layer2.0.conv2': 0.01262475265224601,\n",
       " 'layer2.1.conv1': 0.01262475265224601,\n",
       " 'layer2.1.conv2': 0.01262475265224601,\n",
       " 'layer4.0.downsample.0': 0.011222002357552009,\n",
       " 'layer2.0.conv1': 0.006312376326123005,\n",
       " 'layer1.0.conv1': 0.0031561881630615025,\n",
       " 'layer1.0.conv2': 0.0031561881630615025,\n",
       " 'layer1.1.conv1': 0.0031561881630615025,\n",
       " 'layer1.1.conv2': 0.0031561881630615025,\n",
       " 'layer3.0.downsample.0': 0.002805500589388002,\n",
       " 'conv1': 0.0008054855207813209,\n",
       " 'layer2.0.downsample.0': 0.0007013751473470006}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.537341Z",
     "start_time": "2025-01-30T16:28:51.532596Z"
    }
   },
   "cell_type": "code",
   "source": "dict(sorted(stats_compressed.relative_params.items(), key=lambda item: item[1], reverse=True))",
   "id": "26c8b85881cc6ba1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc': 0.1516872770152675,\n",
       " 'layer4.0.conv1.2': 0.07766388583181695,\n",
       " 'layer4.0.conv2.0': 0.07766388583181695,\n",
       " 'layer4.0.conv2.2': 0.07766388583181695,\n",
       " 'layer4.1.conv1.0': 0.07766388583181695,\n",
       " 'layer4.1.conv1.2': 0.07766388583181695,\n",
       " 'layer4.1.conv2.0': 0.07766388583181695,\n",
       " 'layer4.1.conv2.2': 0.07766388583181695,\n",
       " 'layer4.0.downsample.0.1': 0.03890763871106619,\n",
       " 'layer3.0.conv1.2': 0.019453819355533097,\n",
       " 'layer3.0.conv2.0': 0.019453819355533097,\n",
       " 'layer3.0.conv2.2': 0.019453819355533097,\n",
       " 'layer3.1.conv1.0': 0.019453819355533097,\n",
       " 'layer3.1.conv1.2': 0.019453819355533097,\n",
       " 'layer3.1.conv2.0': 0.019453819355533097,\n",
       " 'layer3.1.conv2.2': 0.019453819355533097,\n",
       " 'layer4.0.conv1.0': 0.019453819355533097,\n",
       " 'layer4.0.downsample.0.0': 0.019453819355533097,\n",
       " 'layer3.0.downsample.0.1': 0.009764757575345406,\n",
       " 'layer2.0.conv1.2': 0.004882378787672703,\n",
       " 'layer2.0.conv2.0': 0.004882378787672703,\n",
       " 'layer2.0.conv2.2': 0.004882378787672703,\n",
       " 'layer2.1.conv1.0': 0.004882378787672703,\n",
       " 'layer2.1.conv1.2': 0.004882378787672703,\n",
       " 'layer2.1.conv2.0': 0.004882378787672703,\n",
       " 'layer2.1.conv2.2': 0.004882378787672703,\n",
       " 'layer3.0.conv1.0': 0.004882378787672703,\n",
       " 'layer3.0.downsample.0.0': 0.004882378787672703,\n",
       " 'layer2.0.downsample.0.1': 0.0024601133426257805,\n",
       " 'layer4.0.conv1.1.2': 0.0015139159031543265,\n",
       " 'layer4.0.conv2.1.2': 0.0015139159031543265,\n",
       " 'layer4.1.conv1.1.2': 0.0015139159031543265,\n",
       " 'layer4.1.conv2.1.2': 0.0015139159031543265,\n",
       " 'layer4.0.conv2.1.0': 0.0013651854931374073,\n",
       " 'layer4.1.conv1.1.0': 0.0013651854931374073,\n",
       " 'layer4.1.conv2.1.0': 0.0013651854931374073,\n",
       " 'conv1.2': 0.0012300566713128902,\n",
       " 'layer1.0.conv1.0': 0.0012300566713128902,\n",
       " 'layer1.0.conv1.2': 0.0012300566713128902,\n",
       " 'layer1.0.conv2.0': 0.0012300566713128902,\n",
       " 'layer1.0.conv2.2': 0.0012300566713128902,\n",
       " 'layer1.1.conv1.0': 0.0012300566713128902,\n",
       " 'layer1.1.conv1.2': 0.0012300566713128902,\n",
       " 'layer1.1.conv2.0': 0.0012300566713128902,\n",
       " 'layer1.1.conv2.2': 0.0012300566713128902,\n",
       " 'layer2.0.conv1.0': 0.0012300566713128902,\n",
       " 'layer2.0.downsample.0.0': 0.0012300566713128902,\n",
       " 'layer3.0.conv1.1.2': 0.0007569579515771633,\n",
       " 'layer3.0.conv2.1.2': 0.0007569579515771633,\n",
       " 'layer3.1.conv1.1.2': 0.0007569579515771633,\n",
       " 'layer3.1.conv2.1.2': 0.0007569579515771633,\n",
       " 'layer3.0.conv2.1.0': 0.0006839233367179604,\n",
       " 'layer3.1.conv1.1.0': 0.0006839233367179604,\n",
       " 'layer3.1.conv2.1.0': 0.0006839233367179604,\n",
       " 'layer4.0.conv1.1.0': 0.0006839233367179604,\n",
       " 'layer2.0.conv1.1.2': 0.00037847897578858163,\n",
       " 'layer2.0.conv2.1.2': 0.00037847897578858163,\n",
       " 'layer2.1.conv1.1.2': 0.00037847897578858163,\n",
       " 'layer2.1.conv2.1.2': 0.00037847897578858163,\n",
       " 'layer2.0.conv2.1.0': 0.00034329225850823693,\n",
       " 'layer2.1.conv1.1.0': 0.00034329225850823693,\n",
       " 'layer2.1.conv2.1.0': 0.00034329225850823693,\n",
       " 'layer3.0.conv1.1.0': 0.00034329225850823693,\n",
       " 'layer1.0.conv1.1.2': 0.00018923948789429081,\n",
       " 'layer1.0.conv2.1.2': 0.00018923948789429081,\n",
       " 'layer1.1.conv1.1.2': 0.00018923948789429081,\n",
       " 'layer1.1.conv2.1.2': 0.00018923948789429081,\n",
       " 'layer1.0.conv1.1.0': 0.0001729767194033752,\n",
       " 'layer1.0.conv2.1.0': 0.0001729767194033752,\n",
       " 'layer1.1.conv1.1.0': 0.0001729767194033752,\n",
       " 'layer1.1.conv2.1.0': 0.0001729767194033752,\n",
       " 'layer2.0.conv1.1.0': 0.0001729767194033752,\n",
       " 'conv1.1.2': 7.569579515771632e-05,\n",
       " 'conv1.1.1': 4.435300497522441e-05,\n",
       " 'layer1.0.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer1.0.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer1.1.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer1.1.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer2.0.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer2.0.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer2.1.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer2.1.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer3.0.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer3.0.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer3.1.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer3.1.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer4.0.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer4.0.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'layer4.1.conv1.1.1': 2.6611802985134646e-05,\n",
       " 'layer4.1.conv2.1.1': 2.6611802985134646e-05,\n",
       " 'conv1.0': 3.548240398017953e-06,\n",
       " 'conv1.1.0': 3.548240398017953e-06}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate",
   "id": "5f8b8119add2e9a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.843315Z",
     "start_time": "2025-01-30T16:28:51.772155Z"
    }
   },
   "cell_type": "code",
   "source": "test = torch.randn([128, 3, 224, 224]).to(device)",
   "id": "aac4454e27f98d94",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:51.932139Z",
     "start_time": "2025-01-30T16:28:51.853784Z"
    }
   },
   "cell_type": "code",
   "source": "a = torch.argmax(uncompressed_resnet18(test).cpu().detach(), dim=1)",
   "id": "550c1e1b97379d06",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:52.079825Z",
     "start_time": "2025-01-30T16:28:51.976433Z"
    }
   },
   "cell_type": "code",
   "source": "b = torch.argmax(compressed_resnet18(test).cpu().detach(), dim=1)",
   "id": "9387acc856336e25",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:28:52.116817Z",
     "start_time": "2025-01-30T16:28:52.114627Z"
    }
   },
   "cell_type": "code",
   "source": "torch.sum(a == b)",
   "id": "d03f02505740af44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Try to finetune model",
   "id": "fef3dc3c02f6c43c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:29:29.662046Z",
     "start_time": "2025-01-30T16:28:52.181558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Instantiate models\n",
    "reference_model = uncompressed_resnet18.eval()\n",
    "trainable_model = compressed_resnet18.train()\n",
    "\n",
    "# Loss function: CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer for the trainable model\n",
    "optimizer = optim.Adam(trainable_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop without a dataset\n",
    "epochs = 1\n",
    "batch_size = 256\n",
    "input_shape = (3, 224, 224)  # Image-like input (channels, height, width)\n",
    "batches = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    # Use tqdm to track progress\n",
    "    with tqdm(total=batches, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for _ in range(batches):  # Simulate 100 batches per epoch\n",
    "            # Generate random input data (like random images)\n",
    "            inputs = torch.randn(batch_size, *input_shape, device=device)\n",
    "\n",
    "            # Get the reference model's output (detach to avoid backprop on reference model)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                with torch.no_grad():\n",
    "                    reference_outputs = reference_model(inputs)\n",
    "\n",
    "                # Forward pass of the trainable model\n",
    "                model_outputs = trainable_model(inputs)\n",
    "\n",
    "            # Compute the loss between the two model outputs\n",
    "            # We need to find the class with maximum probability in the reference outputs for CrossEntropy\n",
    "            # Assuming reference outputs are logits (not probabilities)\n",
    "            _, target_indices = torch.max(reference_outputs, dim=1)  # Get class indices for the targets\n",
    "\n",
    "            # Compute the Cross-Entropy loss\n",
    "            loss = criterion(model_outputs, target_indices)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)  # Increment the progress bar by 1\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    avg_loss = running_loss / batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ],
   "id": "67b62bed14234b94",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|| 100/100 [00:37<00:00,  2.67batch/s, loss=0.0553]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Average Loss: 1.2854\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate",
   "id": "f837a0ad3301e6eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:29:29.865168Z",
     "start_time": "2025-01-30T16:29:29.753634Z"
    }
   },
   "cell_type": "code",
   "source": "test = torch.randn([128, 3, 224, 224]).to(device)",
   "id": "a90192c656c301fb",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:29:30.029484Z",
     "start_time": "2025-01-30T16:29:29.961462Z"
    }
   },
   "cell_type": "code",
   "source": "a = torch.argmax(reference_model(test).cpu().detach(), dim=1)",
   "id": "2ecb84999d8dbfc8",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:29:30.352947Z",
     "start_time": "2025-01-30T16:29:30.245910Z"
    }
   },
   "cell_type": "code",
   "source": "b = torch.argmax(trainable_model(test).cpu().detach(), dim=1)",
   "id": "45551822946306dd",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:29:30.370677Z",
     "start_time": "2025-01-30T16:29:30.367663Z"
    }
   },
   "cell_type": "code",
   "source": "torch.sum(a.eq(b))",
   "id": "756cf6d4bba2e958",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test with model_compressor",
   "id": "c966710a638216df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:55:22.562872Z",
     "start_time": "2025-03-13T11:55:20.869312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.model_compressor import model_compressor\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_tensor = torch.randn([64, 3, 224, 224])"
   ],
   "id": "83bac828bb242b85",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:55:22.674427Z",
     "start_time": "2025-03-13T11:55:22.568025Z"
    }
   },
   "cell_type": "code",
   "source": "resnet_original = resnet18(weights='DEFAULT')",
   "id": "9c4eedc8e37eb267",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:55:22.734100Z",
     "start_time": "2025-03-13T11:55:22.725138Z"
    }
   },
   "cell_type": "code",
   "source": "resnet_compressed = deepcopy(resnet_original)",
   "id": "6cb15c6716bb93bd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:58:41.007886Z",
     "start_time": "2025-03-13T11:55:22.770976Z"
    }
   },
   "cell_type": "code",
   "source": "model_compressor.compress_model(resnet_compressed, conv_compression_method=\"TKDCPD\", rank_cpd=2, finetune=True, epochs=1, batch_size=64, number_of_iterations=100, data_size=[3, 224, 224], finetune_device=device, loss_function=nn.CrossEntropyLoss, optimizer=optim.Adam, lr=0.0001, task=\"classification\")",
   "id": "703a07ac7643b026",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 0.10055490507503358\n",
      "differential_evolution step 2: f(x)= 0.10055490507503358\n",
      "differential_evolution step 3: f(x)= 0.10055490507503358\n",
      "differential_evolution step 4: f(x)= 0.10055490507503358\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "2.2516214330007642\n",
      "[np.int64(33), np.int64(3), np.int64(49)]\n",
      "differential_evolution step 1: f(x)= 0.2150981566052378\n",
      "differential_evolution step 2: f(x)= 0.2112575950891102\n",
      "differential_evolution step 3: f(x)= 0.2112575950891102\n",
      "differential_evolution step 4: f(x)= 0.2112575950891102\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "2.3581607340001938\n",
      "[np.int64(52), np.int64(40), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.34126967271641434\n",
      "differential_evolution step 2: f(x)= 0.32210522404514313\n",
      "differential_evolution step 3: f(x)= 0.32210522404514313\n",
      "differential_evolution step 4: f(x)= 0.32210522404514313\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "2.4207167599997774\n",
      "[np.int64(46), np.int64(45), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.3388924616772379\n",
      "differential_evolution step 2: f(x)= 0.32959780587126725\n",
      "differential_evolution step 3: f(x)= 0.32641746225271295\n",
      "differential_evolution step 4: f(x)= 0.32641746225271295\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "2.3809179939999012\n",
      "[np.int64(48), np.int64(43), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.3851926697634139\n",
      "differential_evolution step 2: f(x)= 0.3794081970206704\n",
      "differential_evolution step 3: f(x)= 0.3794081970206704\n",
      "differential_evolution step 4: f(x)= 0.3794081970206704\n",
      "differential_evolution step 5: f(x)= 0.3794081970206704\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "2.8653851189992565\n",
      "[np.int64(44), np.int64(48), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.34621448596155036\n",
      "differential_evolution step 2: f(x)= 0.33789726313231394\n",
      "differential_evolution step 3: f(x)= 0.33379795816209584\n",
      "differential_evolution step 4: f(x)= 0.32879332760869867\n",
      "differential_evolution step 5: f(x)= 0.32879332760869867\n",
      "differential_evolution step 6: f(x)= 0.32866531998405113\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "4.916344911000124\n",
      "[np.int64(92), np.int64(45), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.3349858775560021\n",
      "differential_evolution step 2: f(x)= 0.33417252941300385\n",
      "differential_evolution step 3: f(x)= 0.33417252941300385\n",
      "differential_evolution step 4: f(x)= 0.33417252941300385\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "4.524829681000483\n",
      "[np.int64(101), np.int64(83), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.5347161889076233\n",
      "differential_evolution step 2: f(x)= 0.45474886894226074\n",
      "differential_evolution step 3: f(x)= 0.45474886894226074\n",
      "differential_evolution step 4: f(x)= 0.45474886894226074\n",
      "differential_evolution step 5: f(x)= 0.45474886894226074\n",
      "differential_evolution step 6: f(x)= 0.45474886894226074\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "1.63451133000126\n",
      "[np.int64(20), np.int64(20), np.int64(1)]\n",
      "differential_evolution step 1: f(x)= 0.37099205401612934\n",
      "differential_evolution step 2: f(x)= 0.37099205401612934\n",
      "differential_evolution step 3: f(x)= 0.37099205401612934\n",
      "differential_evolution step 4: f(x)= 0.37099205401612934\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "4.540713967000556\n",
      "[np.int64(99), np.int64(85), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.4114252310669235\n",
      "differential_evolution step 2: f(x)= 0.3977409498384224\n",
      "differential_evolution step 3: f(x)= 0.3977409498384224\n",
      "differential_evolution step 4: f(x)= 0.39730841070504436\n",
      "differential_evolution step 5: f(x)= 0.3964725693148677\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "5.648515099999713\n",
      "[np.int64(88), np.int64(95), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.3331774274156127\n",
      "differential_evolution step 2: f(x)= 0.31808044807410535\n",
      "differential_evolution step 3: f(x)= 0.31808044807410535\n",
      "differential_evolution step 4: f(x)= 0.3178953776370823\n",
      "differential_evolution step 5: f(x)= 0.3178953776370823\n",
      "differential_evolution step 6: f(x)= 0.3178953776370823\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "8.851952901999539\n",
      "[np.int64(154), np.int64(108), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.35922300195012846\n",
      "differential_evolution step 2: f(x)= 0.35694295208946025\n",
      "differential_evolution step 3: f(x)= 0.35653693023851885\n",
      "differential_evolution step 4: f(x)= 0.35651289149211773\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "9.262655073000133\n",
      "[np.int64(195), np.int64(171), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.6341968774795532\n",
      "differential_evolution step 2: f(x)= 0.6341968774795532\n",
      "differential_evolution step 3: f(x)= 0.630427747964859\n",
      "differential_evolution step 4: f(x)= 0.5776877403259277\n",
      "differential_evolution step 5: f(x)= 0.5578616261482239\n",
      "differential_evolution step 6: f(x)= 0.5578616261482239\n",
      "differential_evolution step 7: f(x)= 0.5545987579971552\n",
      "differential_evolution step 8: f(x)= 0.5545987579971552\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "3.7863377180001407\n",
      "[np.int64(41), np.int64(41), np.int64(1)]\n",
      "differential_evolution step 1: f(x)= 0.37100887845851327\n",
      "differential_evolution step 2: f(x)= 0.37100887845851327\n",
      "differential_evolution step 3: f(x)= 0.37100887845851327\n",
      "differential_evolution step 4: f(x)= 0.37100887845851327\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "9.462952812998992\n",
      "[np.int64(201), np.int64(166), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.379480048321384\n",
      "differential_evolution step 2: f(x)= 0.3781312587725632\n",
      "differential_evolution step 3: f(x)= 0.3781312587725632\n",
      "differential_evolution step 4: f(x)= 0.3780769489874765\n",
      "differential_evolution step 5: f(x)= 0.37807151278677625\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "11.433151715998974\n",
      "[np.int64(176), np.int64(190), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.3492589240763555\n",
      "differential_evolution step 2: f(x)= 0.3476842343139532\n",
      "differential_evolution step 3: f(x)= 0.34591532795960195\n",
      "differential_evolution step 4: f(x)= 0.3455240924417805\n",
      "differential_evolution step 5: f(x)= 0.3455240924417805\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "20.378888863999236\n",
      "[np.int64(306), np.int64(218), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.41405826326018413\n",
      "differential_evolution step 2: f(x)= 0.4125903354706593\n",
      "differential_evolution step 3: f(x)= 0.4120583498246191\n",
      "differential_evolution step 4: f(x)= 0.41196756779154203\n",
      "differential_evolution step 5: f(x)= 0.41191268338447223\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "32.39952500700019\n",
      "[np.int64(365), np.int64(368), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.49655445443931967\n",
      "differential_evolution step 2: f(x)= 0.49655445443931967\n",
      "differential_evolution step 3: f(x)= 0.49266574962530285\n",
      "differential_evolution step 4: f(x)= 0.49222679960075766\n",
      "differential_evolution step 5: f(x)= 0.4883751372108236\n",
      "differential_evolution step 6: f(x)= 0.48714042641222477\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "5.556354381000347\n",
      "[np.int64(82), np.int64(82), np.int64(1)]\n",
      "differential_evolution step 1: f(x)= 0.39008006377935517\n",
      "differential_evolution step 2: f(x)= 0.38124667996650197\n",
      "differential_evolution step 3: f(x)= 0.3810851250322627\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "23.772686842999974\n",
      "[np.int64(372), np.int64(361), np.int64(9)]\n",
      "differential_evolution step 1: f(x)= 0.20943649778059054\n",
      "differential_evolution step 2: f(x)= 0.2093292125341047\n",
      "differential_evolution step 3: f(x)= 0.2093024361144619\n",
      "Polishing solution with 'L-BFGS-B'\n",
      "20.2422688810002\n",
      "[np.int64(348), np.int64(379), np.int64(9)]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:59:25.393297Z",
     "start_time": "2025-03-13T11:59:25.387791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_original.cpu()\n",
    "resnet_compressed.cpu()\n",
    "resnet_original.eval()\n",
    "resnet_compressed.eval()"
   ],
   "id": "402d05996d770980",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(\n",
       "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(3, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): Conv2d(2, 2, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=2, bias=False)\n",
       "        (2): Conv2d(2, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Conv2d(33, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(64, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(40, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(52, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(64, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(45, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 46, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(46, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(64, 43, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(43, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(48, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(44, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(64, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(45, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(92, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(128, 83, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(83, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 101, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(101, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): Conv2d(2, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(128, 85, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(85, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 99, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(99, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(128, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(95, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(88, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(128, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(108, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 154, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(256, 171, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(171, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 195, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(195, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(128, 2, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): Conv2d(2, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(256, 166, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(166, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 201, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(201, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(256, 190, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(190, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(176, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(256, 218, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(218, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 306, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(306, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(512, 368, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(368, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 365, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(365, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(256, 2, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): Conv2d(2, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(512, 361, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(361, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 372, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(372, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(512, 379, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(379, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "            (2): Conv2d(2, 348, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): Conv2d(348, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:58:42.701688Z",
     "start_time": "2025-03-13T11:58:41.368423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_original = resnet_original(random_tensor)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "result_compressed = resnet_compressed(random_tensor)"
   ],
   "id": "ae11eccc59cc6277",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:58:42.724551Z",
     "start_time": "2025-03-13T11:58:42.720708Z"
    }
   },
   "cell_type": "code",
   "source": "torch.mean(torch.abs(result_original - result_compressed))",
   "id": "8f1731fa82d773de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9369, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:58:42.771683Z",
     "start_time": "2025-03-13T11:58:42.768444Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmax(result_original, dim=1).isclose(torch.argmax(result_compressed, dim=1))",
   "id": "7bb3a7d7cca31ace",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T13:25:08.478696Z",
     "start_time": "2025-03-06T13:25:08.477215Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e2f475595514dd19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1dc9f2241e2fef76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
