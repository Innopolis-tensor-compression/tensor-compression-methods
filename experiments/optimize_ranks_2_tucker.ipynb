{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "da827a785863fdb2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T15:00:51.242538Z",
     "start_time": "2025-02-13T15:00:51.191834Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "from sympy.testing.runtests import method\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"src.utils.method_loggers\",\n",
    "    \"src.utils.method_runners\",\n",
    "    \"src.utils.metrics_calculators\",\n",
    "    \"src.utils.tensor_handlers\",\n",
    "    \"src.utils.trackers\",\n",
    "    \"src.utils.video_controller\",\n",
    "    \"src.utils.optimal_rank_finders\",\n",
    "]\n",
    "\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.nn import Conv2d, ConvTranspose2d\n",
    "from itertools import product\n",
    "from src.utils.metrics_calculators import IMetricCalculator, CompressionRatioTensorLyTuckerCalculator\n",
    "from functools import partial\n",
    "from scipy.optimize import OptimizeResult\n",
    "from scipy.optimize import differential_evolution\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "import tensorly as tl\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tucker_args = {\n",
    "    \"svd\": \"truncated_svd\",\n",
    "    \"init\": \"svd\",\n",
    "    \"random_state\": 42,\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get tensor - layers of NN",
   "id": "1571929b4a25e2dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e163e7e3094d465d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:00:51.816548Z",
     "start_time": "2025-02-13T15:00:51.350657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=False)\n",
    "\n",
    "\n",
    "def extract_layers(model, tensors=None) -> list[torch.Tensor]:\n",
    "    if tensors is None: tensors = []\n",
    "\n",
    "    for child in model.children():\n",
    "        if isinstance(child, (Conv2d, ConvTranspose2d)):\n",
    "            layer_weights = child.weight\n",
    "            size = layer_weights.shape\n",
    "            layer_weights = layer_weights.reshape(size[0], size[1], size[2] * size[3])\n",
    "            tensors.append(layer_weights)\n",
    "        else:\n",
    "            extract_layers(child, tensors=tensors)\n",
    "\n",
    "    return tensors\n",
    "\n",
    "\n",
    "tensors = extract_layers(gan.netG)\n",
    "print(len(tensors))\n",
    "for tensor in tensors: print(tensor.shape)\n",
    "\n",
    "tensors = [tensors[3]]"
   ],
   "id": "46db559eb51c2b3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorch_GAN_zoo_hub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average network found !\n",
      "5\n",
      "torch.Size([120, 512, 16])\n",
      "torch.Size([512, 256, 16])\n",
      "torch.Size([256, 128, 16])\n",
      "torch.Size([128, 64, 16])\n",
      "torch.Size([64, 3, 16])\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# funcs",
   "id": "b262007c715feca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:00:51.911602Z",
     "start_time": "2025-02-13T15:00:51.877005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tucker_bounds_for_layer_for_nn(shape: tuple | list) -> list:\n",
    "    \"\"\"\n",
    "    Calculate the bounds for Tucker ranks of a tensor based on its shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : tuple[int, ...] | list[int]\n",
    "        The shape of the tensor as a list or tuple of integers.\n",
    "        Each element represents the size of the tensor along a corresponding dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int]]\n",
    "        A list of rank bounds for the Tucker decomposition.\n",
    "        Each element is a tuple (r_min, r_max), where:\n",
    "        - r_min is always 1 for all modes except the last.\n",
    "        - r_max is the upper bound for the Tucker rank along the corresponding mode.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> res = calculate_tucker_bounds_for_layer_for_nn((3, 4, 5))\n",
    "    [(1, 3), (1, 4), (5, 5)]\n",
    "\n",
    "    \"\"\"\n",
    "    return [(1, dim) for dim in shape[:-1]] + [(shape[-1], shape[-1])]"
   ],
   "id": "ca4221f4406e9d80",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:00:51.966053Z",
     "start_time": "2025-02-13T15:00:51.931377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compression_ratio_nn(tensor, ranks: list[int] | tuple[int, int]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the custom compression ratio of the layer of neural network after Tucker decomposition.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : np.ndarray\n",
    "        The original tensor.\n",
    "    ranks : list[int] | tuple[int, int]\n",
    "        The Tucker ranks for decomposition.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed compression ratio.\n",
    "\n",
    "    \"\"\"\n",
    "    size = tensor.shape\n",
    "    size1 = size[0] * ranks[0]\n",
    "    size2 = ranks[0] * ranks[1] * size[2] ** 2\n",
    "    size3 = size[1] * ranks[1]\n",
    "    return (size1 + size2 + size3) / (size[0] * size[1] * size[2] ** 2)"
   ],
   "id": "25a8019f67f21dd7",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate search area",
   "id": "fe740e7ae104c0af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:35:39.465995Z",
     "start_time": "2025-02-13T15:00:51.998879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_compression_ratio_for_graphs = 50.0\n",
    "frobenius_error_coef_for_graphs = 1.0\n",
    "compression_ratio_coef_for_graphs = 10.0\n",
    "\n",
    "search_area_tensors_results = {}\n",
    "\n",
    "total_iterations = 0\n",
    "rank_ranges_per_layer = []\n",
    "\n",
    "for tensor in tensors:\n",
    "    tensor_tucker_bounds = calculate_tucker_bounds_for_layer_for_nn(tensor.shape)\n",
    "    rank_ranges = [range(bound[0], bound[1] + 1) for bound in tensor_tucker_bounds]\n",
    "    rank_ranges_per_layer.append(rank_ranges)\n",
    "    total_iterations += np.prod([len(r) for r in rank_ranges])\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Processing All Layers\") as pbar:\n",
    "    for index, (tensor, rank_ranges) in enumerate(zip(tensors, rank_ranges_per_layer)):\n",
    "        tqdm_iterable = product(*rank_ranges)\n",
    "\n",
    "        search_area_tensors_results[index] = {}\n",
    "\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "\n",
    "            for rank_combination in tqdm_iterable:\n",
    "                test_rank = list(rank_combination)\n",
    "                internal_indices = test_rank[0:2]\n",
    "\n",
    "                try:\n",
    "                    method_result = tl.decomposition.tucker(tensor_cuda, rank=test_rank, **tucker_args)\n",
    "                    reconstructed_tensor = tl.tucker_to_tensor(method_result)\n",
    "\n",
    "                    target_compression_ratio = target_compression_ratio_for_graphs / 100\n",
    "\n",
    "                    frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "\n",
    "                    custom_compression_ratio = compression_ratio_nn(tensor=reconstructed_tensor, ranks=test_rank)\n",
    "                    custom_compression_penalty = (target_compression_ratio - custom_compression_ratio) ** 2\n",
    "\n",
    "                    compression_ratio = CompressionRatioTensorLyTuckerCalculator.calculate(tensor_cuda,\n",
    "                                                                                           method_result) / 100\n",
    "                    compression_penalty = (target_compression_ratio - compression_ratio) ** 2\n",
    "\n",
    "                    loss_function_result = (\n",
    "                            frobenius_error_coef_for_graphs * frobenius_error\n",
    "                            + compression_ratio_coef_for_graphs * compression_penalty\n",
    "                    )\n",
    "\n",
    "                    custom_loss_function_result = (\n",
    "                            frobenius_error_coef_for_graphs * frobenius_error\n",
    "                            + compression_ratio_coef_for_graphs * custom_compression_penalty\n",
    "                    )\n",
    "\n",
    "                    search_area_tensors_results[index][tuple(internal_indices)] = {\n",
    "                        \"rank\": test_rank,\n",
    "                        \"frobenius_error\": frobenius_error,\n",
    "                        \"compression_ratio\": compression_ratio,\n",
    "                        \"compression_penalty\": compression_penalty,\n",
    "                        \"loss_function_result\": loss_function_result,\n",
    "                        \"custom_compression_ratio\": custom_compression_ratio,\n",
    "                        \"custom_compression_penalty\": custom_compression_penalty,\n",
    "                        \"custom_loss_function_result\": custom_loss_function_result,\n",
    "                    }\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "                finally:\n",
    "                    torch.cuda.synchronize()\n",
    "                    del method_result, reconstructed_tensor\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "                # Обновляем общий tqdm после каждой итерации\n",
    "                pbar.update(1)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor_cuda\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ],
   "id": "4ea637205a9a0547",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing All Layers: 100%|██████████| 8192/8192 [34:47<00:00,  3.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graph of search areas",
   "id": "f31ae192a3f9827d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:35:40.158021Z",
     "start_time": "2025-02-13T15:35:39.634236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = [\"frobenius_error\", \"compression_ratio\", \"custom_compression_ratio\", \"compression_penalty\",\n",
    "           \"custom_compression_penalty\", \"loss_function_result\", \"custom_loss_function_result\"]\n",
    "\n",
    "for layer_index, search_area_tensor_results in search_area_tensors_results.items():\n",
    "\n",
    "    tensor_name = f\"conv_layer_{layer_index}\"\n",
    "\n",
    "    internal_indices = np.array(list(search_area_tensor_results.keys()))\n",
    "\n",
    "    metric_dict = {tuple(idx): search_area_tensor_results[idx] for idx in search_area_tensor_results}\n",
    "\n",
    "    figs = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        z_values = np.array([search_area_tensor_results[key].get(metric, np.nan) for key in search_area_tensor_results])\n",
    "        x_indices = internal_indices[:, 0]\n",
    "        y_indices = internal_indices[:, 1]\n",
    "\n",
    "        local_min_points = []\n",
    "\n",
    "        for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "            z = z_values[i]\n",
    "\n",
    "            neighbors = [\n",
    "                (x - 1, y), (x + 1, y),\n",
    "                (x, y - 1), (x, y + 1)\n",
    "            ]\n",
    "\n",
    "            is_local_min = all(\n",
    "                (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "                for neighbor in neighbors\n",
    "            )\n",
    "\n",
    "            if is_local_min:\n",
    "                local_min_points.append((x, y, z))\n",
    "\n",
    "        x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x_indices,\n",
    "            y=y_indices,\n",
    "            z=z_values,\n",
    "            mode=\"markers\",\n",
    "            marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "            name=metric\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x_min,\n",
    "            y=y_min,\n",
    "            z=z_min,\n",
    "            mode=\"markers+text\",\n",
    "            marker={\"size\": 6, \"color\": \"red\", \"symbol\": \"diamond\"},\n",
    "            text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "            textposition=\"top center\",\n",
    "            name=\"Local Minima\"\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()}\",\n",
    "            scene={\n",
    "                \"xaxis_title\": \"Rank Index 1\",\n",
    "                \"yaxis_title\": \"Rank Index 2\",\n",
    "                \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "                \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))}\n",
    "            },\n",
    "            margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "            template=\"plotly_white\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "        figs.append(fig)\n",
    "\n",
    "    html_str = \"\"\n",
    "    for fig in figs:\n",
    "        html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "    html_file = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Search area by some metrics</h1>\n",
    "    {html_str}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = f\"../.cache/data_analyze/optimization_algs_for_tucker_search_area_{tensor_name}.html\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "        f.write(html_file)"
   ],
   "id": "df0c742b0a160fab",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate optimal rank and path of it",
   "id": "6ef9708134e3c511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:35:40.218750Z",
     "start_time": "2025-02-13T15:35:40.190347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frobenius_error_coef_algs = 1.0\n",
    "compression_ratio_coef_algs = 10.0\n",
    "\n",
    "target_compression_ratio_algs = 50.0\n",
    "\n",
    "scipy_algs_tensors_results = {}"
   ],
   "id": "70b514112fa079c3",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:35:40.269774Z",
     "start_time": "2025-02-13T15:35:40.247182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_function(\n",
    "        rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        method_args: dict[str, str],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "):\n",
    "    try:\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "\n",
    "            method_result = tl.decomposition.tucker(tensor_cuda, rank=rank, **method_args)\n",
    "            reconstructed_tensor = tl.tucker_to_tensor(method_result)\n",
    "\n",
    "            target_compression_ratio /= 100\n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "            compression_ratio = CompressionRatioTensorLyTuckerCalculator.calculate(tensor_cuda, method_result) / 100\n",
    "            compression_penalty = (target_compression_ratio - compression_ratio) ** 2\n",
    "\n",
    "            loss_function_result = (\n",
    "                    frobenius_error_coef * frobenius_error\n",
    "                    + compression_ratio_coef * compression_penalty\n",
    "            )\n",
    "\n",
    "        return loss_function_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor, tensor_cuda, method_result, reconstructed_tensor, compression_ratio, compression_penalty\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "id": "34830a2f93e87721",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:35:40.329540Z",
     "start_time": "2025-02-13T15:35:40.306937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_loss_function(\n",
    "        rank: list,\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        method_args: dict[str, str],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "):\n",
    "    try:\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "\n",
    "            method_result = tl.decomposition.tucker(tensor_cuda, rank=rank, **method_args)\n",
    "            reconstructed_tensor = tl.tucker_to_tensor(method_result)\n",
    "\n",
    "            target_compression_ratio /= 100\n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "\n",
    "            custom_compression_ratio = compression_ratio_nn(tensor=reconstructed_tensor, ranks=test_rank)\n",
    "\n",
    "            custom_compression_penalty = (target_compression_ratio - custom_compression_ratio) ** 2\n",
    "\n",
    "            custom_loss_function_result = (\n",
    "                    frobenius_error_coef * frobenius_error\n",
    "                    + compression_ratio_coef * custom_compression_penalty\n",
    "            )\n",
    "\n",
    "        return custom_loss_function_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor, tensor_cuda, method_result, reconstructed_tensor, compression_ratio, compression_penalty\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "id": "388b4cc42f971c9d",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:35:40.387853Z",
     "start_time": "2025-02-13T15:35:40.357285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def global_optimize_rank(\n",
    "        tensor: np.ndarray,\n",
    "        target_compression_ratio: float,\n",
    "        method_args: dict[str, str],\n",
    "        frobenius_error_coef: float = 1.0,\n",
    "        compression_ratio_coef: float = 10.0,\n",
    "        optimization_method: str = \"differential_evolution\",\n",
    "        is_custom_loss_function: bool = False,\n",
    "):\n",
    "    def loss_wrapper(\n",
    "            free_rank: list,\n",
    "            tensor: np.ndarray,\n",
    "            target_compression_ratio: float,\n",
    "            frobenius_error_coef: float,\n",
    "            compression_ratio_coef: float,\n",
    "            method_args: dict[str, str],\n",
    "    ) -> float:\n",
    "        full_rank = list(np.clip(np.round(free_rank).astype(int), 1, None))\n",
    "        try:\n",
    "            loss = loss_function(\n",
    "                rank=full_rank,\n",
    "                tensor=tensor,\n",
    "                target_compression_ratio=target_compression_ratio,\n",
    "                method_args=method_args,\n",
    "                frobenius_error_coef=frobenius_error_coef,\n",
    "                compression_ratio_coef=compression_ratio_coef,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            loss = float(\"inf\")\n",
    "        return loss\n",
    "\n",
    "    def custom_loss_wrapper(\n",
    "            free_rank: list,\n",
    "            tensor: np.ndarray,\n",
    "            target_compression_ratio: float,\n",
    "            frobenius_error_coef: float,\n",
    "            compression_ratio_coef: float,\n",
    "            method_args: dict[str, str],\n",
    "    ) -> float:\n",
    "        full_rank = list(np.clip(np.round(free_rank).astype(int), 1, None))\n",
    "        try:\n",
    "            loss = custom_loss_function(\n",
    "                rank=full_rank,\n",
    "                tensor=tensor,\n",
    "                target_compression_ratio=target_compression_ratio,\n",
    "                method_args=method_args,\n",
    "                frobenius_error_coef=frobenius_error_coef,\n",
    "                compression_ratio_coef=compression_ratio_coef,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            loss = float(\"inf\")\n",
    "        return loss\n",
    "    \n",
    "    def calculate_tucker_bounds_for_layer_for_nn(shape: tuple | list) -> list:\n",
    "        \"\"\"\n",
    "        Calculate the bounds for Tucker ranks of a tensor based on its shape.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : tuple[int, ...] | list[int]\n",
    "            The shape of the tensor as a list or tuple of integers.\n",
    "            Each element represents the size of the tensor along a corresponding dimension.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        list[tuple[int, int]]\n",
    "            A list of rank bounds for the Tucker decomposition.\n",
    "            Each element is a tuple (r_min, r_max), where:\n",
    "            - r_min is always 1 for all modes except the last.\n",
    "            - r_max is the upper bound for the Tucker rank along the corresponding mode.\n",
    "    \n",
    "        Example\n",
    "        -------\n",
    "        >>> res = calculate_tucker_bounds_for_layer_for_nn((3, 4, 5))\n",
    "        [(1, 3), (1, 4), (5, 5)]\n",
    "    \n",
    "        \"\"\"\n",
    "        return [(1, dim) for dim in shape[:-1]] + [(shape[-1], shape[-1])]\n",
    "\n",
    "    def calculate_metrics(\n",
    "            tensor: np.ndarray,\n",
    "            rank: list,\n",
    "            method_args: dict[str, str],\n",
    "            target_compression_ratio_percent: float = 50.0,\n",
    "            frobenius_error_coef: float = 1.0,\n",
    "            compression_ratio_coef: float = 10.0,\n",
    "    ):\n",
    "        with tl.backend_context(\"pytorch\"):\n",
    "            tensor_cuda = tl.tensor(tensor).to(\"cuda\")\n",
    "\n",
    "            method_result = tl.decomposition.tucker(tensor_cuda, rank=rank, **method_args)\n",
    "            reconstructed_tensor = tl.tucker_to_tensor(method_result)\n",
    "\n",
    "            target_compression_ratio = target_compression_ratio_percent / 100\n",
    "\n",
    "            frobenius_error = (tl.norm(reconstructed_tensor - tensor_cuda) / tl.norm(tensor_cuda)).item()\n",
    "\n",
    "            custom_compression_ratio = compression_ratio_nn(tensor=reconstructed_tensor, ranks=rank)\n",
    "            custom_compression_penalty = (target_compression_ratio - custom_compression_ratio) ** 2\n",
    "\n",
    "            compression_ratio = CompressionRatioTensorLyTuckerCalculator.calculate(tensor_cuda, method_result) / 100\n",
    "            compression_penalty = (target_compression_ratio - compression_ratio) ** 2\n",
    "\n",
    "            loss_function_result = (\n",
    "                    frobenius_error_coef * frobenius_error\n",
    "                    + compression_ratio_coef * compression_penalty\n",
    "            )\n",
    "\n",
    "            custom_loss_function_result = (\n",
    "                    frobenius_error_coef * frobenius_error\n",
    "                    + compression_ratio_coef * compression_penalty\n",
    "            )\n",
    "\n",
    "            metrics = {\n",
    "                \"rank\": test_rank,\n",
    "                \"frobenius_error\": frobenius_error,\n",
    "                \"compression_ratio\": compression_ratio,\n",
    "                \"compression_penalty\": compression_penalty,\n",
    "                \"loss_function_result\": loss_function_result,\n",
    "                \"custom_compression_ratio\": custom_compression_ratio,\n",
    "                \"custom_compression_penalty\": custom_compression_penalty,\n",
    "                \"custom_loss_function_result\": custom_loss_function_result,\n",
    "            }\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        del tensor_cuda, tensor, method_result, reconstructed_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    class OptimizationLogger:\n",
    "        def __init__(\n",
    "                self,\n",
    "                tensor: np.ndarray,\n",
    "                method_args: dict[str, str],\n",
    "                target_compression_ratio: float = 50.0,\n",
    "                frobenius_error_coef: float = 1.0,\n",
    "                compression_ratio_coef: float = 10.0,\n",
    "        ):\n",
    "            self.logs = []\n",
    "            self.current_iteration = -1\n",
    "\n",
    "            self.tensor = tensor\n",
    "            self.method_args = method_args\n",
    "            self.target_compression_ratio = target_compression_ratio\n",
    "            self.frobenius_error_coef = frobenius_error_coef\n",
    "            self.compression_ratio_coef = compression_ratio_coef\n",
    "\n",
    "        def calculate_metrics(\n",
    "                self,\n",
    "                rank: list,\n",
    "        ) -> dict[str, float]:\n",
    "            return calculate_metrics(\n",
    "                tensor=self.tensor,\n",
    "                rank=rank,\n",
    "                method_args=self.method_args,\n",
    "                target_compression_ratio_percent=self.target_compression_ratio,\n",
    "                frobenius_error_coef=self.frobenius_error_coef,\n",
    "                compression_ratio_coef=self.compression_ratio_coef,\n",
    "            )\n",
    "\n",
    "        def callback(self, intermediate_result: OptimizeResult):\n",
    "            self.current_iteration += 1\n",
    "\n",
    "            rank = list(np.round(intermediate_result.x).astype(int))\n",
    "            metrics = self.calculate_metrics(rank=rank)\n",
    "\n",
    "            self.logs.append(\n",
    "                {\n",
    "                    \"step\": self.current_iteration,\n",
    "                    \"rank\": rank,\n",
    "                    \"metrics\": metrics,\n",
    "                    \"raw_results\": intermediate_result,\n",
    "                }\n",
    "            )\n",
    "            print(f\"\\n=== Iteration {self.current_iteration} complete ===\", f\"New rank estimate: {rank}\\n\", sep=\"\\n\")\n",
    "\n",
    "    optimization_logger = OptimizationLogger(\n",
    "        tensor=tensor,\n",
    "        method_args=method_args,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    loss_function_fixed = partial(\n",
    "        loss_wrapper,\n",
    "        tensor=tensor,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        method_args=method_args,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    ) if is_custom_loss_function is False else partial(\n",
    "        custom_loss_wrapper,\n",
    "        tensor=tensor,\n",
    "        target_compression_ratio=target_compression_ratio,\n",
    "        method_args=method_args,\n",
    "        frobenius_error_coef=frobenius_error_coef,\n",
    "        compression_ratio_coef=compression_ratio_coef,\n",
    "    )\n",
    "\n",
    "    # params\n",
    "    is_bounds_variable_usable = [\n",
    "        \"differential_evolution\",\n",
    "    ]\n",
    "\n",
    "    is_callback_variable_not_usable = []\n",
    "\n",
    "    free_bounds = calculate_tucker_bounds_for_layer_for_nn(\n",
    "        tensor.shape) if optimization_method in is_bounds_variable_usable else None\n",
    "\n",
    "    callback_param = (\n",
    "        optimization_logger.callback if optimization_method not in is_callback_variable_not_usable else None\n",
    "    )\n",
    "\n",
    "    if optimization_method == \"differential_evolution\":\n",
    "        optimization_kwargs_differential_evolution = {\n",
    "\n",
    "            \"func\": loss_function_fixed,\n",
    "            \"bounds\": free_bounds,\n",
    "\n",
    "            \"strategy\": \"best1bin\",\n",
    "            \"maxiter\": 50,\n",
    "            \"popsize\": 10,\n",
    "            \"tol\": 0.01,\n",
    "            \"atol\": 0.001,\n",
    "            \"mutation\": (0.3, 0.7),\n",
    "            \"recombination\": 0.9,\n",
    "            \"init\": \"latinhypercube\",\n",
    "            \"polish\": True,\n",
    "\n",
    "            \"workers\": 1,\n",
    "            \"updating\": \"immediate\",  # {‘immediate’ - when 1 worker, ‘deferred’ - when more than 1 worker}\n",
    "\n",
    "            \"callback\": callback_param,\n",
    "            \"disp\": True,\n",
    "        }\n",
    "\n",
    "        result = differential_evolution(**optimization_kwargs_differential_evolution)\n",
    "\n",
    "        optimal_rank = list(np.clip(np.round(result.x).astype(int), 1, None))\n",
    "        final_loss = result.fun\n",
    "\n",
    "    return optimal_rank, final_loss, result, optimization_logger.logs"
   ],
   "id": "dee28e66d02810f2",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:38:43.229042Z",
     "start_time": "2025-02-13T15:38:10.207677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method = \"differential_evolution\"\n",
    "\n",
    "for index, tensor in enumerate(tensors):\n",
    "\n",
    "    scipy_algs_tensors_results[index] = {}\n",
    "\n",
    "    print(\n",
    "        f\"Testing tensor: {index}\",\n",
    "        f\"Testing optimization method: {method}\",\n",
    "        f\"Tensor shape: {tensor.shape}\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    try:\n",
    "        # check optimizer method\n",
    "        start_time = time.perf_counter()\n",
    "        optimal_rank, final_loss, minimize_result_differential_evolution, iteration_logs_differential_evolution = global_optimize_rank(\n",
    "            tensor=tensor,\n",
    "            target_compression_ratio=target_compression_ratio_algs,\n",
    "            method_args=tucker_args,\n",
    "            optimization_method=method,\n",
    "            frobenius_error_coef=frobenius_error_coef_algs,\n",
    "            compression_ratio_coef=compression_ratio_coef_algs,\n",
    "        )\n",
    "        elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "        scipy_algs_tensors_results[index][method] = {\n",
    "            \"final_results\": minimize_result_differential_evolution,\n",
    "            \"steps_results\": iteration_logs_differential_evolution,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error with tensor {index} with method {method}: {e}\")"
   ],
   "id": "740f582e1e4a70da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tensor: 0\n",
      "Testing optimization method: differential_evolution\n",
      "Tensor shape: torch.Size([128, 64, 16])\n",
      "\n",
      "differential_evolution step 1: f(x)= 0.45152145624160767\n",
      "\n",
      "=== Iteration 0 complete ===\n",
      "New rank estimate: [80, 42, 16]\n",
      "\n",
      "differential_evolution step 2: f(x)= 0.44451943039894104\n",
      "\n",
      "=== Iteration 1 complete ===\n",
      "New rank estimate: [74, 46, 16]\n",
      "\n",
      "differential_evolution step 3: f(x)= 0.4444291889667511\n",
      "\n",
      "=== Iteration 2 complete ===\n",
      "New rank estimate: [78, 45, 16]\n",
      "\n",
      "differential_evolution step 4: f(x)= 0.4412423372268677\n",
      "\n",
      "=== Iteration 3 complete ===\n",
      "New rank estimate: [71, 50, 16]\n",
      "\n",
      "differential_evolution step 5: f(x)= 0.44120851159095764\n",
      "\n",
      "=== Iteration 4 complete ===\n",
      "New rank estimate: [72, 49, 16]\n",
      "\n",
      "Polishing solution with 'L-BFGS-B'\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:39:23.069575Z",
     "start_time": "2025-02-13T15:39:23.037466Z"
    }
   },
   "cell_type": "code",
   "source": "iteration_logs_differential_evolution[0]['metrics']",
   "id": "ead5680c470fa586",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank': [128, 64, 16],\n",
       " 'frobenius_error': 0.4503675103187561,\n",
       " 'compression_ratio': 0.5107421875,\n",
       " 'compression_penalty': 0.00011539459228515625,\n",
       " 'loss_function_result': 0.45152145624160767,\n",
       " 'custom_compression_ratio': 0.41632080078125,\n",
       " 'custom_compression_penalty': 0.007002208381891251,\n",
       " 'custom_loss_function_result': 0.45152145624160767}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:39:23.312766Z",
     "start_time": "2025-02-13T15:39:23.277Z"
    }
   },
   "cell_type": "code",
   "source": "iteration_logs_differential_evolution[1]['metrics']",
   "id": "2d8aab3b88c2f8e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank': [128, 64, 16],\n",
       " 'frobenius_error': 0.4430293142795563,\n",
       " 'compression_ratio': 0.51220703125,\n",
       " 'compression_penalty': 0.00014901161193847656,\n",
       " 'loss_function_result': 0.44451943039894104,\n",
       " 'custom_compression_ratio': 0.42144775390625,\n",
       " 'custom_compression_penalty': 0.006170455366373062,\n",
       " 'custom_loss_function_result': 0.44451943039894104}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:46:50.900951Z",
     "start_time": "2025-02-13T15:46:50.326939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metric_names = [\"frobenius_error\", \"compression_ratio\", \"custom_compression_ratio\", \"compression_penalty\",\n",
    "                \"custom_compression_penalty\", \"loss_function_result\", \"custom_loss_function_result\"]\n",
    "\n",
    "\n",
    "for layer_index, scipy_tensor_algs_results in scipy_algs_tensors_results.items():\n",
    "\n",
    "    tensor_name = f\"conv_layer_{layer_index}\"\n",
    "    internal_indices = np.array(list(search_area_tensors_results[layer_index].keys()))\n",
    "\n",
    "    for method_name, method_results in scipy_tensor_algs_results.items():\n",
    "        frobenius_error_from_method, compression_ratio_from_method, custom_compression_ratio_from_method, compression_penalty_from_method, custom_compression_penalty_from_method, loss_from_method, custom_loss_from_method = [], [], [], [], [], [], []\n",
    "        for method_steps_logs in method_results['steps_results']:\n",
    "            frobenius_error_from_method.append(method_steps_logs[\"metrics\"][\"frobenius_error\"])\n",
    "            compression_ratio_from_method.append(method_steps_logs[\"metrics\"][\"compression_ratio\"])\n",
    "            compression_penalty_from_method.append(method_steps_logs[\"metrics\"][\"compression_penalty\"])\n",
    "            loss_from_method.append(method_steps_logs[\"metrics\"][\"loss_function_result\"])\n",
    "            custom_compression_ratio_from_method.append(method_steps_logs[\"metrics\"][\"custom_compression_ratio\"])\n",
    "            custom_compression_penalty_from_method.append(method_steps_logs[\"metrics\"][\"custom_compression_penalty\"])\n",
    "            custom_loss_from_method.append(method_steps_logs[\"metrics\"][\"custom_loss_function_result\"])\n",
    "\n",
    "        figs = []\n",
    "\n",
    "        for metric, metric_data in zip(\n",
    "                metric_names,\n",
    "                [\n",
    "                    frobenius_error_from_method,\n",
    "                    compression_ratio_from_method,\n",
    "                    custom_compression_ratio_from_method,\n",
    "                    compression_penalty_from_method,\n",
    "                    custom_compression_penalty_from_method,\n",
    "                    loss_from_method,\n",
    "                    custom_loss_from_method,\n",
    "                ],\n",
    "                strict=False,\n",
    "        ):\n",
    "            z_values = np.array(\n",
    "                [search_area_tensors_results[layer_index][key].get(metric, np.nan) for key in\n",
    "                 search_area_tensors_results[layer_index]])\n",
    "            x_indices = internal_indices[:, 0]\n",
    "            y_indices = internal_indices[:, 1]\n",
    "\n",
    "            # Поиск локальных минимумов\n",
    "            local_min_points = []\n",
    "\n",
    "            metric_dict = {tuple(idx): search_area_tensors_results[layer_index][idx] for idx in\n",
    "                           search_area_tensors_results[layer_index]}\n",
    "\n",
    "            for i, (x, y) in enumerate(zip(x_indices, y_indices)):\n",
    "                z = z_values[i]\n",
    "\n",
    "                neighbors = [\n",
    "                    (x - 1, y), (x + 1, y),  # По оси X\n",
    "                    (x, y - 1), (x, y + 1)  # По оси Y\n",
    "                ]\n",
    "\n",
    "                is_local_min = all(\n",
    "                    (neighbor not in metric_dict or metric_dict[neighbor].get(metric, np.inf) >= z)\n",
    "                    for neighbor in neighbors\n",
    "                )\n",
    "\n",
    "                if is_local_min:\n",
    "                    local_min_points.append((x, y, z))\n",
    "\n",
    "            x_min, y_min, z_min = zip(*local_min_points) if local_min_points else ([], [], [])\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            # Основные точки\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=x_indices,\n",
    "                y=y_indices,\n",
    "                z=z_values,\n",
    "                mode=\"markers\",\n",
    "                marker={\"size\": 5, \"color\": z_values, \"colorscale\": \"Viridis\", \"opacity\": 0.8},\n",
    "            ))\n",
    "\n",
    "            path_x = []\n",
    "            path_y = []\n",
    "            path_z = []\n",
    "\n",
    "            for i, log in enumerate(method_results['steps_results']):\n",
    "                rank = log[\"rank\"]\n",
    "                if metric == \"frobenius_error\":\n",
    "                    z_value = frobenius_error_from_method[i]\n",
    "                elif metric == \"compression_ratio\":\n",
    "                    z_value = compression_ratio_from_method[i]\n",
    "                elif metric == \"compression_penalty\":\n",
    "                    z_value = compression_penalty_from_method[i]\n",
    "                elif metric == \"loss_function_result\":\n",
    "                    z_value = loss_from_method[i]\n",
    "                elif metric == \"custom_compression_ratio\":\n",
    "                    z_value = custom_compression_ratio_from_method[i]\n",
    "                elif metric == \"custom_compression_penalty\":\n",
    "                    z_value = custom_compression_penalty_from_method[i]\n",
    "                elif metric == \"custom_loss_function_result\":\n",
    "                    z_value = custom_loss_from_method[i]\n",
    "\n",
    "                path_x.append(rank[1])\n",
    "                path_y.append(rank[2])\n",
    "                path_z.append(z_value)\n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Scatter3d(\n",
    "                        x=[rank[1]],\n",
    "                        y=[rank[2]],\n",
    "                        z=[z_value],\n",
    "                        mode=\"markers\",\n",
    "                        marker={\n",
    "                            \"size\": 10 if i == 0 or i == len(method_results['steps_results']) - 1 else 5,\n",
    "                            \"color\": \"yellow\" if i == 0 or i == len(method_results['steps_results']) - 1 else \"red\",\n",
    "                            \"opacity\": 0.8,\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Добавляем локальные минимумы (выделенные точки)\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=x_min,\n",
    "                y=y_min,\n",
    "                z=z_min,\n",
    "                mode=\"markers+text\",\n",
    "                marker={\"size\": 8, \"color\": \"blue\", \"symbol\": \"diamond\"},\n",
    "                text=[f\"min: {val:.6f}\" for val in z_min],\n",
    "                textposition=\"top center\",\n",
    "            ))\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=path_x,\n",
    "                    y=path_y,\n",
    "                    z=path_z,\n",
    "                    mode=\"lines+markers\",\n",
    "                    marker={\"size\": 5, \"color\": \"red\", \"opacity\": 0.8},\n",
    "                    line={\"color\": \"red\", \"width\": 3},\n",
    "                )\n",
    "            )\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"Search area for example tensor {tensor_name} of {metric.replace('_', ' ').title()} with {method_name} alg path\",\n",
    "                scene={\n",
    "                    \"xaxis_title\": \"Rank Index 1\",\n",
    "                    \"yaxis_title\": \"Rank Index 2\",\n",
    "                    \"zaxis_title\": metric.replace(\"_\", \" \").title(),\n",
    "                    \"yaxis\": {\"tickmode\": \"array\", \"tickvals\": list(set(y_indices.astype(int)))},\n",
    "                },\n",
    "                margin={\"l\": 0, \"r\": 0, \"t\": 40, \"b\": 0},\n",
    "                template=\"plotly_white\",\n",
    "                showlegend=False,\n",
    "            )\n",
    "\n",
    "            figs.append(fig)\n",
    "\n",
    "        html_str = \"\"\n",
    "        for fig in figs:\n",
    "            html_str += go.Figure(fig).to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "        html_file = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h1>Search area by some metrics</h1>\n",
    "        {html_str}\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "\n",
    "        output_path = f\"../.cache/data_analyze/optimization_algs_for_tensor_train_search_area_{tensor_name}_with_{method_name}_alg.html\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:  # noqa: PTH123\n",
    "            f.write(html_file)"
   ],
   "id": "465c23604aa0295f",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:39:24.662385Z",
     "start_time": "2025-02-13T15:39:24.657763Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "827849b25a895d60",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
